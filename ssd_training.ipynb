{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# ---------- edit ---------- #\n",
    "print(torch.cuda.get_device_name(torch.device('cuda')))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "# -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from truth_voc import make_filepath_list, GetBBoxAndLabel, DataTransform, multiobject_collate_fn\n",
    "from truth_voc import PreprocessVOC2012\n",
    "\n",
    "# rootpath = '/home/masakibandai/object_detection/data/VOCdevkit/VOC2012/'\n",
    "rootpath = '/Users/ShimaSef/object_detection/data/VOCdevkit/VOC2012/'\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_filepath_list(rootpath)\n",
    "voc_classes = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "train_dataset = PreprocessVOC2012(\n",
    "    train_img_list,\n",
    "    train_anno_list,\n",
    "    phase='train',\n",
    "    transform=DataTransform(input_size, color_mean),\n",
    "    get_bbox_label=GetBBoxAndLabel(voc_classes)\n",
    ")\n",
    "\n",
    "val_dataset = PreprocessVOC2012(\n",
    "    val_img_list,\n",
    "    val_anno_list,\n",
    "    phase='val',\n",
    "    transform=DataTransform(input_size, color_mean),\n",
    "    get_bbox_label=GetBBoxAndLabel(voc_classes)\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=multiobject_collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=multiobject_collate_fn\n",
    ")\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SSD                                      [32, 3, 300, 300]         [32, 8732, 4]             --\n",
       "├─ModuleList: 1-3                        --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-1                       [32, 3, 300, 300]         [32, 64, 300, 300]        1,792\n",
       "│    └─ReLU: 2-2                         [32, 64, 300, 300]        [32, 64, 300, 300]        --\n",
       "│    └─Conv2d: 2-3                       [32, 64, 300, 300]        [32, 64, 300, 300]        36,928\n",
       "│    └─ReLU: 2-4                         [32, 64, 300, 300]        [32, 64, 300, 300]        --\n",
       "│    └─MaxPool2d: 2-5                    [32, 64, 300, 300]        [32, 64, 150, 150]        --\n",
       "│    └─Conv2d: 2-6                       [32, 64, 150, 150]        [32, 128, 150, 150]       73,856\n",
       "│    └─ReLU: 2-7                         [32, 128, 150, 150]       [32, 128, 150, 150]       --\n",
       "│    └─Conv2d: 2-8                       [32, 128, 150, 150]       [32, 128, 150, 150]       147,584\n",
       "│    └─ReLU: 2-9                         [32, 128, 150, 150]       [32, 128, 150, 150]       --\n",
       "│    └─MaxPool2d: 2-10                   [32, 128, 150, 150]       [32, 128, 75, 75]         --\n",
       "│    └─Conv2d: 2-11                      [32, 128, 75, 75]         [32, 256, 75, 75]         295,168\n",
       "│    └─ReLU: 2-12                        [32, 256, 75, 75]         [32, 256, 75, 75]         --\n",
       "│    └─Conv2d: 2-13                      [32, 256, 75, 75]         [32, 256, 75, 75]         590,080\n",
       "│    └─ReLU: 2-14                        [32, 256, 75, 75]         [32, 256, 75, 75]         --\n",
       "│    └─Conv2d: 2-15                      [32, 256, 75, 75]         [32, 256, 75, 75]         590,080\n",
       "│    └─ReLU: 2-16                        [32, 256, 75, 75]         [32, 256, 75, 75]         --\n",
       "│    └─MaxPool2d: 2-17                   [32, 256, 75, 75]         [32, 256, 38, 38]         --\n",
       "│    └─Conv2d: 2-18                      [32, 256, 38, 38]         [32, 512, 38, 38]         1,180,160\n",
       "│    └─ReLU: 2-19                        [32, 512, 38, 38]         [32, 512, 38, 38]         --\n",
       "│    └─Conv2d: 2-20                      [32, 512, 38, 38]         [32, 512, 38, 38]         2,359,808\n",
       "│    └─ReLU: 2-21                        [32, 512, 38, 38]         [32, 512, 38, 38]         --\n",
       "│    └─Conv2d: 2-22                      [32, 512, 38, 38]         [32, 512, 38, 38]         2,359,808\n",
       "│    └─ReLU: 2-23                        [32, 512, 38, 38]         [32, 512, 38, 38]         --\n",
       "├─L2Norm: 1-2                            [32, 512, 38, 38]         [32, 512, 38, 38]         512\n",
       "├─ModuleList: 1-3                        --                        --                        (recursive)\n",
       "│    └─MaxPool2d: 2-24                   [32, 512, 38, 38]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-25                      [32, 512, 19, 19]         [32, 512, 19, 19]         2,359,808\n",
       "│    └─ReLU: 2-26                        [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-27                      [32, 512, 19, 19]         [32, 512, 19, 19]         2,359,808\n",
       "│    └─ReLU: 2-28                        [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-29                      [32, 512, 19, 19]         [32, 512, 19, 19]         2,359,808\n",
       "│    └─ReLU: 2-30                        [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─MaxPool2d: 2-31                   [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-32                      [32, 512, 19, 19]         [32, 1024, 19, 19]        4,719,616\n",
       "│    └─ReLU: 2-33                        [32, 1024, 19, 19]        [32, 1024, 19, 19]        --\n",
       "│    └─Conv2d: 2-34                      [32, 1024, 19, 19]        [32, 1024, 19, 19]        1,049,600\n",
       "│    └─ReLU: 2-35                        [32, 1024, 19, 19]        [32, 1024, 19, 19]        --\n",
       "├─ModuleList: 1-4                        --                        --                        --\n",
       "│    └─Conv2d: 2-36                      [32, 1024, 19, 19]        [32, 256, 19, 19]         262,400\n",
       "│    └─Conv2d: 2-37                      [32, 256, 19, 19]         [32, 512, 10, 10]         1,180,160\n",
       "│    └─Conv2d: 2-38                      [32, 512, 10, 10]         [32, 128, 10, 10]         65,664\n",
       "│    └─Conv2d: 2-39                      [32, 128, 10, 10]         [32, 256, 5, 5]           295,168\n",
       "│    └─Conv2d: 2-40                      [32, 256, 5, 5]           [32, 128, 5, 5]           32,896\n",
       "│    └─Conv2d: 2-41                      [32, 128, 5, 5]           [32, 256, 3, 3]           295,168\n",
       "│    └─Conv2d: 2-42                      [32, 256, 3, 3]           [32, 128, 3, 3]           32,896\n",
       "│    └─Conv2d: 2-43                      [32, 128, 3, 3]           [32, 256, 1, 1]           295,168\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-44                      [32, 512, 38, 38]         [32, 16, 38, 38]          73,744\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-45                      [32, 512, 38, 38]         [32, 84, 38, 38]          387,156\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-46                      [32, 1024, 19, 19]        [32, 24, 19, 19]          221,208\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-47                      [32, 1024, 19, 19]        [32, 126, 19, 19]         1,161,342\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-48                      [32, 512, 10, 10]         [32, 24, 10, 10]          110,616\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-49                      [32, 512, 10, 10]         [32, 126, 10, 10]         580,734\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-50                      [32, 256, 5, 5]           [32, 24, 5, 5]            55,320\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-51                      [32, 256, 5, 5]           [32, 126, 5, 5]           290,430\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-52                      [32, 256, 3, 3]           [32, 16, 3, 3]            36,880\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-53                      [32, 256, 3, 3]           [32, 84, 3, 3]            193,620\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-54                      [32, 256, 1, 1]           [32, 16, 1, 1]            36,880\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-55                      [32, 256, 1, 1]           [32, 84, 1, 1]            193,620\n",
       "===================================================================================================================\n",
       "Total params: 26,285,486\n",
       "Trainable params: 26,285,486\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.00\n",
       "===================================================================================================================\n",
       "Input size (MB): 34.56\n",
       "Forward/backward pass size (MB): 6717.23\n",
       "Params size (MB): 105.14\n",
       "Estimated Total Size (MB): 6856.93\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from truth_ssd import SSD\n",
    "from torchinfo import summary\n",
    "\n",
    "ssd_cfg = {\n",
    "    'classes_num': 21,\n",
    "    'input_size': 300,\n",
    "    'dbox_num': [4, 6, 6, 6, 4, 4],\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "net = SSD(phase='train', cfg=ssd_cfg)\n",
    "# weightpath = '/home/masakibandai/object_detection/weights/vgg16_reducedfc.pth'\n",
    "weightpath = '/Users/ShimaSef/object_detection/weights/vgg16_reducedfc.pth'\n",
    "vgg_weights = torch.load(weightpath)\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "summary(\n",
    "    net,\n",
    "    input_size=(batch_size, 3, 300, 300),\n",
    "    col_names=['input_size', 'output_size', 'num_params']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from truth_ssd import MultiBoxLoss\n",
    "\n",
    "criterion = MultiBoxLoss(\n",
    "    jaccard_thresh=0.5,\n",
    "    neg_pos=3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ---------- edit ---------- #\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(),\n",
    "    lr=1e-3,\n",
    "    # momentum=0.9,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=0,\n",
    "    amsgrad=False\n",
    ")\n",
    "# -------------------------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def train(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    '''\n",
    "    Parameter:\n",
    "        net(object): SSD model\n",
    "        dataloaders_dict(dict of object): dataloader\n",
    "        criterion(object): loss function\n",
    "        optimizer(object): optimizer\n",
    "        num_epochs(object): num learning\n",
    "    '''\n",
    "    print(device)\n",
    "    # ---------edit--------- #\n",
    "    net.to(device)\n",
    "    # ---------------------- #\n",
    "    print('Start training with {}'.format(torch.cuda.get_device_name()))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                if ((epoch+1) % 10 == 0):\n",
    "                    net.eval()\n",
    "                    print('----------------------------------------------------------------------')\n",
    "                    print('(validation)')\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "                # ---------edit---------- #\n",
    "                # images.cuda()\n",
    "                # targets.cuda()\n",
    "                # ----------------------- #\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = net(images)\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('Step({}) loss: {:.4f} -- time: {:.4f} sec.'.format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        \n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "        t_epoch_finish = time.time()\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "        print('train_loss: {:.4f} - val_loss: {:.4f}'.format(epoch_train_loss, epoch_val_loss))\n",
    "        print('time: {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        print('time_left: {:.4f} min'.format((t_epoch_finish-t_epoch_start)*(num_epochs-epoch-1)/60))\n",
    "\n",
    "        t_epoch_start = time.time()\n",
    "        log_epoch = {\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': epoch_train_loss,\n",
    "            'val_loss': epoch_val_loss\n",
    "        }\n",
    "\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        # ---------- edit ---------- #\n",
    "        # csvpath = '/home/masakibandai/object_detection/epoch_loss.csv'\n",
    "        if epoch == 0:\n",
    "            csvidx = os.listdir('loss_csv')\n",
    "            if not os.path.exists('./loss_csv/epoch_loss_0.csv'):\n",
    "                csvpath = './loss_csv/epoch_loss_0.csv'\n",
    "            else:\n",
    "                csvidx = [int(os.path.splitext(i)[0].split('_')[2]) for i in csvidx]\n",
    "                csvpath = '/Users/ShimaSef/object_detection/loss_csv/epoch_loss_{}.csv'.format(max(csvidx)+1)\n",
    "        # -------------------------- #\n",
    "        df.to_csv(csvpath)\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        \n",
    "        # ---------- edit ---------- #\n",
    "        # statedictpath = '/home/masakibandai/object_detection/weights/ssd_weights'\n",
    "        if epoch == 0:\n",
    "            weightidx = os.listdir('weights')\n",
    "            if not os.path.exists('./weights/ssd_weights_0/'):\n",
    "                os.mkdir('./weights/ssd_weights_0/')\n",
    "                statedictpath = '/Users/ShimaSef/object_detection/weights/ssd_weights_0/ssd_weights_'\n",
    "            else:\n",
    "                weightidx = [int(f.split('_')[2]) for f in weightidx if os.path.isdir(os.path.join('weights', f))]\n",
    "                if not os.path.exists('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1)):\n",
    "                    os.mkdir('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1))\n",
    "                statedictpath = '/Users/ShimaSef/object_detection/weights/ssd_weights_{}/ssd_weights_'.format(max(weightidx)+1)\n",
    "        # -------------------------- #\n",
    "\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(\n",
    "                net.state_dict(),\n",
    "                 statedictpath + str(epoch+1) + '.pth'\n",
    "            )\n",
    "            print('--saved weights--')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Start training with NVIDIA GeForce RTX 4090\n",
      "----------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10) loss: 14.9023 -- time: 4.6263 sec.\n",
      "Step(20) loss: 11.4714 -- time: 4.4554 sec.\n",
      "Step(30) loss: 9.1572 -- time: 4.6299 sec.\n",
      "Step(40) loss: 8.5963 -- time: 4.6088 sec.\n",
      "Step(50) loss: 7.9663 -- time: 4.6342 sec.\n",
      "Step(60) loss: 7.5732 -- time: 4.4622 sec.\n",
      "Step(70) loss: 7.7741 -- time: 4.5741 sec.\n",
      "Step(80) loss: 7.5004 -- time: 4.5465 sec.\n",
      "Step(90) loss: 8.0714 -- time: 4.6330 sec.\n",
      "Step(100) loss: 7.7557 -- time: 4.6103 sec.\n",
      "Step(110) loss: 7.6680 -- time: 4.6165 sec.\n",
      "Step(120) loss: 7.5402 -- time: 4.4166 sec.\n",
      "Step(130) loss: 8.1026 -- time: 4.5062 sec.\n",
      "Step(140) loss: 7.5695 -- time: 4.4554 sec.\n",
      "Step(150) loss: 7.8504 -- time: 4.5902 sec.\n",
      "Step(160) loss: 7.6212 -- time: 4.6216 sec.\n",
      "Step(170) loss: 6.9395 -- time: 4.5911 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 3136.2513 - val_loss: 0.0000\n",
      "time: 83.3936 sec.\n",
      "time_left: 276.5889 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2/200\n",
      "----------------------------------------------------------------------\n",
      "Step(180) loss: 7.6029 -- time: 0.3642 sec.\n",
      "Step(190) loss: 7.4656 -- time: 4.5825 sec.\n",
      "Step(200) loss: 7.6343 -- time: 4.6872 sec.\n",
      "Step(210) loss: 7.1361 -- time: 4.7119 sec.\n",
      "Step(220) loss: 7.4842 -- time: 4.5907 sec.\n",
      "Step(230) loss: 7.8411 -- time: 4.4873 sec.\n",
      "Step(240) loss: 7.4636 -- time: 4.5410 sec.\n",
      "Step(250) loss: 7.7336 -- time: 4.6060 sec.\n",
      "Step(260) loss: 7.3911 -- time: 4.6509 sec.\n",
      "Step(270) loss: 7.4910 -- time: 4.6180 sec.\n",
      "Step(280) loss: 7.5752 -- time: 4.7660 sec.\n",
      "Step(290) loss: 7.5759 -- time: 4.4651 sec.\n",
      "Step(300) loss: 7.5684 -- time: 4.6333 sec.\n",
      "Step(310) loss: 6.9495 -- time: 4.6416 sec.\n",
      "Step(320) loss: 7.5756 -- time: 4.5807 sec.\n",
      "Step(330) loss: 7.8198 -- time: 4.3622 sec.\n",
      "Step(340) loss: 7.3891 -- time: 4.5190 sec.\n",
      "Step(350) loss: 7.4655 -- time: 4.4207 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1351.4934 - val_loss: 0.0000\n",
      "time: 83.5968 sec.\n",
      "time_left: 275.8693 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3/200\n",
      "----------------------------------------------------------------------\n",
      "Step(360) loss: 8.2629 -- time: 0.8902 sec.\n",
      "Step(370) loss: 7.7008 -- time: 4.4736 sec.\n",
      "Step(380) loss: 7.2828 -- time: 4.5352 sec.\n",
      "Step(390) loss: 7.5275 -- time: 4.6072 sec.\n",
      "Step(400) loss: 7.2783 -- time: 4.4866 sec.\n",
      "Step(410) loss: 8.2386 -- time: 4.5531 sec.\n",
      "Step(420) loss: 7.5030 -- time: 4.5827 sec.\n",
      "Step(430) loss: 7.1815 -- time: 4.3911 sec.\n",
      "Step(440) loss: 7.7073 -- time: 4.5365 sec.\n",
      "Step(450) loss: 7.2329 -- time: 4.5119 sec.\n",
      "Step(460) loss: 7.6834 -- time: 4.6740 sec.\n",
      "Step(470) loss: 7.6675 -- time: 4.5183 sec.\n",
      "Step(480) loss: 7.5598 -- time: 4.5983 sec.\n",
      "Step(490) loss: 7.5034 -- time: 4.5549 sec.\n",
      "Step(500) loss: 7.4802 -- time: 4.4175 sec.\n",
      "Step(510) loss: 7.0176 -- time: 4.5513 sec.\n",
      "Step(520) loss: 6.9669 -- time: 4.4566 sec.\n",
      "Step(530) loss: 6.9282 -- time: 4.4555 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1339.8018 - val_loss: 0.0000\n",
      "time: 82.9403 sec.\n",
      "time_left: 272.3206 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4/200\n",
      "----------------------------------------------------------------------\n",
      "Step(540) loss: 7.4469 -- time: 1.3651 sec.\n",
      "Step(550) loss: 7.5182 -- time: 4.4754 sec.\n",
      "Step(560) loss: 7.4349 -- time: 4.6945 sec.\n",
      "Step(570) loss: 7.2246 -- time: 4.5341 sec.\n",
      "Step(580) loss: 7.4842 -- time: 4.5687 sec.\n",
      "Step(590) loss: 7.0865 -- time: 4.5603 sec.\n",
      "Step(600) loss: 7.6349 -- time: 4.6257 sec.\n",
      "Step(610) loss: 7.6014 -- time: 4.5873 sec.\n",
      "Step(620) loss: 6.9544 -- time: 4.5029 sec.\n",
      "Step(630) loss: 7.4145 -- time: 4.7097 sec.\n",
      "Step(640) loss: 7.1994 -- time: 4.5576 sec.\n",
      "Step(650) loss: 7.0409 -- time: 4.7098 sec.\n",
      "Step(660) loss: 7.4550 -- time: 4.6761 sec.\n",
      "Step(670) loss: 7.2110 -- time: 4.9903 sec.\n",
      "Step(680) loss: 7.9219 -- time: 5.2470 sec.\n",
      "Step(690) loss: 7.5176 -- time: 5.1910 sec.\n",
      "Step(700) loss: 7.5369 -- time: 5.0727 sec.\n",
      "Step(710) loss: 7.4101 -- time: 5.1712 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1304.4491 - val_loss: 0.0000\n",
      "time: 87.1812 sec.\n",
      "time_left: 284.7918 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5/200\n",
      "----------------------------------------------------------------------\n",
      "Step(720) loss: 6.7890 -- time: 1.9092 sec.\n",
      "Step(730) loss: 7.4698 -- time: 5.1735 sec.\n",
      "Step(740) loss: 7.3396 -- time: 5.1521 sec.\n",
      "Step(750) loss: 6.9382 -- time: 5.2042 sec.\n",
      "Step(760) loss: 7.3970 -- time: 5.0768 sec.\n",
      "Step(770) loss: 7.3400 -- time: 4.6526 sec.\n",
      "Step(780) loss: 7.6519 -- time: 4.4301 sec.\n",
      "Step(790) loss: 7.1225 -- time: 4.6177 sec.\n",
      "Step(800) loss: 7.0630 -- time: 4.7008 sec.\n",
      "Step(810) loss: 6.9300 -- time: 4.4763 sec.\n",
      "Step(820) loss: 7.1641 -- time: 4.7463 sec.\n",
      "Step(830) loss: 6.9728 -- time: 4.6667 sec.\n",
      "Step(840) loss: 6.8681 -- time: 4.7123 sec.\n",
      "Step(850) loss: 7.3237 -- time: 4.5784 sec.\n",
      "Step(860) loss: 7.2262 -- time: 4.5225 sec.\n",
      "Step(870) loss: 7.1617 -- time: 4.6241 sec.\n",
      "Step(880) loss: 7.6096 -- time: 4.6840 sec.\n",
      "Step(890) loss: 7.1512 -- time: 4.6114 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1273.7739 - val_loss: 0.0000\n",
      "time: 86.7558 sec.\n",
      "time_left: 281.9562 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6/200\n",
      "----------------------------------------------------------------------\n",
      "Step(900) loss: 7.3002 -- time: 2.2239 sec.\n",
      "Step(910) loss: 7.7099 -- time: 4.6066 sec.\n",
      "Step(920) loss: 7.4300 -- time: 4.5225 sec.\n",
      "Step(930) loss: 6.8547 -- time: 4.6519 sec.\n",
      "Step(940) loss: 6.8556 -- time: 4.5766 sec.\n",
      "Step(950) loss: 6.7302 -- time: 4.5652 sec.\n",
      "Step(960) loss: 7.0946 -- time: 4.6766 sec.\n",
      "Step(970) loss: 6.7655 -- time: 4.6042 sec.\n",
      "Step(980) loss: 7.3950 -- time: 4.6331 sec.\n",
      "Step(990) loss: 6.2785 -- time: 4.4280 sec.\n",
      "Step(1000) loss: 7.1123 -- time: 4.4695 sec.\n",
      "Step(1010) loss: 7.0615 -- time: 4.5157 sec.\n",
      "Step(1020) loss: 6.9724 -- time: 4.6403 sec.\n",
      "Step(1030) loss: 7.0493 -- time: 4.5865 sec.\n",
      "Step(1040) loss: 7.6952 -- time: 4.6139 sec.\n",
      "Step(1050) loss: 7.1661 -- time: 4.5505 sec.\n",
      "Step(1060) loss: 6.5663 -- time: 4.4329 sec.\n",
      "Step(1070) loss: 6.9277 -- time: 4.4812 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1253.1524 - val_loss: 0.0000\n",
      "time: 83.4599 sec.\n",
      "time_left: 269.8537 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7/200\n",
      "----------------------------------------------------------------------\n",
      "Step(1080) loss: 6.5549 -- time: 2.6808 sec.\n",
      "Step(1090) loss: 6.9312 -- time: 4.5494 sec.\n",
      "Step(1100) loss: 6.3818 -- time: 4.5213 sec.\n",
      "Step(1110) loss: 7.0775 -- time: 4.4593 sec.\n",
      "Step(1120) loss: 6.8759 -- time: 4.6212 sec.\n",
      "Step(1130) loss: 6.7044 -- time: 4.6044 sec.\n",
      "Step(1140) loss: 6.8395 -- time: 4.5017 sec.\n",
      "Step(1150) loss: 6.7936 -- time: 4.4953 sec.\n",
      "Step(1160) loss: 7.3515 -- time: 4.5054 sec.\n",
      "Step(1170) loss: 7.0992 -- time: 4.4508 sec.\n",
      "Step(1180) loss: 7.4995 -- time: 4.6469 sec.\n",
      "Step(1190) loss: 7.2035 -- time: 4.3122 sec.\n",
      "Step(1200) loss: 6.6138 -- time: 4.4133 sec.\n",
      "Step(1210) loss: 7.0874 -- time: 4.4293 sec.\n",
      "Step(1220) loss: 7.0945 -- time: 4.4278 sec.\n",
      "Step(1230) loss: 7.3944 -- time: 4.4968 sec.\n",
      "Step(1240) loss: 6.6340 -- time: 4.4099 sec.\n",
      "Step(1250) loss: 6.4762 -- time: 4.5093 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1242.6556 - val_loss: 0.0000\n",
      "time: 82.2606 sec.\n",
      "time_left: 264.6050 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8/200\n",
      "----------------------------------------------------------------------\n",
      "Step(1260) loss: 6.7257 -- time: 3.1800 sec.\n",
      "Step(1270) loss: 7.5463 -- time: 4.5939 sec.\n",
      "Step(1280) loss: 6.8583 -- time: 4.5040 sec.\n",
      "Step(1290) loss: 7.2724 -- time: 4.4083 sec.\n",
      "Step(1300) loss: 6.8329 -- time: 4.5746 sec.\n",
      "Step(1310) loss: 7.1337 -- time: 4.4618 sec.\n",
      "Step(1320) loss: 6.9966 -- time: 4.3686 sec.\n",
      "Step(1330) loss: 6.4674 -- time: 4.3286 sec.\n",
      "Step(1340) loss: 6.7880 -- time: 4.5509 sec.\n",
      "Step(1350) loss: 6.8124 -- time: 4.4448 sec.\n",
      "Step(1360) loss: 6.7525 -- time: 4.5811 sec.\n",
      "Step(1370) loss: 6.7137 -- time: 4.4905 sec.\n",
      "Step(1380) loss: 6.9513 -- time: 4.5175 sec.\n",
      "Step(1390) loss: 6.6335 -- time: 4.4672 sec.\n",
      "Step(1400) loss: 6.7385 -- time: 4.5136 sec.\n",
      "Step(1410) loss: 6.6879 -- time: 4.3763 sec.\n",
      "Step(1420) loss: 7.1294 -- time: 4.7644 sec.\n",
      "Step(1430) loss: 6.8663 -- time: 4.5358 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1226.0984 - val_loss: 0.0000\n",
      "time: 82.3642 sec.\n",
      "time_left: 263.5656 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 9/200\n",
      "----------------------------------------------------------------------\n",
      "Step(1440) loss: 6.6609 -- time: 3.5337 sec.\n",
      "Step(1450) loss: 6.4973 -- time: 4.5533 sec.\n",
      "Step(1460) loss: 6.9227 -- time: 4.4680 sec.\n",
      "Step(1470) loss: 6.8626 -- time: 4.4927 sec.\n",
      "Step(1480) loss: 7.0390 -- time: 4.6224 sec.\n",
      "Step(1490) loss: 6.4867 -- time: 4.5721 sec.\n",
      "Step(1500) loss: 7.2662 -- time: 4.6196 sec.\n",
      "Step(1510) loss: 6.6679 -- time: 4.5122 sec.\n",
      "Step(1520) loss: 6.8544 -- time: 4.5376 sec.\n",
      "Step(1530) loss: 6.6212 -- time: 4.5331 sec.\n",
      "Step(1540) loss: 6.3093 -- time: 4.4975 sec.\n",
      "Step(1550) loss: 6.7750 -- time: 4.3829 sec.\n",
      "Step(1560) loss: 6.8157 -- time: 4.5886 sec.\n",
      "Step(1570) loss: 7.0895 -- time: 4.5947 sec.\n",
      "Step(1580) loss: 7.0504 -- time: 4.5218 sec.\n",
      "Step(1590) loss: 6.9271 -- time: 4.4369 sec.\n",
      "Step(1600) loss: 6.7896 -- time: 4.3811 sec.\n",
      "Step(1610) loss: 6.7224 -- time: 4.4720 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1209.6313 - val_loss: 0.0000\n",
      "time: 82.5821 sec.\n",
      "time_left: 262.8864 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 10/200\n",
      "----------------------------------------------------------------------\n",
      "Step(1620) loss: 7.1211 -- time: 4.1546 sec.\n",
      "Step(1630) loss: 7.3002 -- time: 4.4671 sec.\n",
      "Step(1640) loss: 6.2692 -- time: 4.4294 sec.\n",
      "Step(1650) loss: 6.6967 -- time: 4.4407 sec.\n",
      "Step(1660) loss: 6.7579 -- time: 4.5122 sec.\n",
      "Step(1670) loss: 6.9331 -- time: 4.4957 sec.\n",
      "Step(1680) loss: 6.3032 -- time: 4.4207 sec.\n",
      "Step(1690) loss: 6.6817 -- time: 4.5413 sec.\n",
      "Step(1700) loss: 7.2936 -- time: 4.5428 sec.\n",
      "Step(1710) loss: 6.7847 -- time: 4.5400 sec.\n",
      "Step(1720) loss: 7.0066 -- time: 4.5688 sec.\n",
      "Step(1730) loss: 6.8145 -- time: 4.4711 sec.\n",
      "Step(1740) loss: 6.6400 -- time: 4.5754 sec.\n",
      "Step(1750) loss: 6.4699 -- time: 4.5761 sec.\n",
      "Step(1760) loss: 6.1900 -- time: 4.4768 sec.\n",
      "Step(1770) loss: 6.8223 -- time: 4.7167 sec.\n",
      "Step(1780) loss: 6.8736 -- time: 4.4426 sec.\n",
      "Step(1790) loss: 6.5135 -- time: 4.2591 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1201.5218 - val_loss: 1206.4608\n",
      "time: 118.9418 sec.\n",
      "time_left: 376.6489 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 11/200\n",
      "----------------------------------------------------------------------\n",
      "Step(1800) loss: 6.4690 -- time: 4.4750 sec.\n",
      "Step(1810) loss: 6.7435 -- time: 4.4644 sec.\n",
      "Step(1820) loss: 6.7309 -- time: 4.5717 sec.\n",
      "Step(1830) loss: 6.4346 -- time: 4.5055 sec.\n",
      "Step(1840) loss: 6.8409 -- time: 4.5219 sec.\n",
      "Step(1850) loss: 6.5457 -- time: 4.5776 sec.\n",
      "Step(1860) loss: 6.8011 -- time: 4.5185 sec.\n",
      "Step(1870) loss: 6.6870 -- time: 4.5393 sec.\n",
      "Step(1880) loss: 6.3457 -- time: 4.4594 sec.\n",
      "Step(1890) loss: 6.9667 -- time: 4.4804 sec.\n",
      "Step(1900) loss: 6.6452 -- time: 4.5064 sec.\n",
      "Step(1910) loss: 6.8462 -- time: 4.5015 sec.\n",
      "Step(1920) loss: 6.4645 -- time: 4.2757 sec.\n",
      "Step(1930) loss: 6.9240 -- time: 4.4415 sec.\n",
      "Step(1940) loss: 6.3979 -- time: 4.5390 sec.\n",
      "Step(1950) loss: 6.5838 -- time: 4.5800 sec.\n",
      "Step(1960) loss: 6.6022 -- time: 4.4835 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1184.3498 - val_loss: 0.0000\n",
      "time: 82.2941 sec.\n",
      "time_left: 259.2265 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 12/200\n",
      "----------------------------------------------------------------------\n",
      "Step(1970) loss: 6.4146 -- time: 0.3413 sec.\n",
      "Step(1980) loss: 6.7071 -- time: 4.5434 sec.\n",
      "Step(1990) loss: 6.3435 -- time: 4.5967 sec.\n",
      "Step(2000) loss: 6.4045 -- time: 4.5841 sec.\n",
      "Step(2010) loss: 6.4656 -- time: 4.5069 sec.\n",
      "Step(2020) loss: 6.1804 -- time: 4.4730 sec.\n",
      "Step(2030) loss: 6.8913 -- time: 4.7027 sec.\n",
      "Step(2040) loss: 6.2270 -- time: 4.6280 sec.\n",
      "Step(2050) loss: 7.0448 -- time: 4.6379 sec.\n",
      "Step(2060) loss: 6.4547 -- time: 4.4912 sec.\n",
      "Step(2070) loss: 7.1754 -- time: 4.6344 sec.\n",
      "Step(2080) loss: 7.2115 -- time: 4.5279 sec.\n",
      "Step(2090) loss: 6.0802 -- time: 4.5960 sec.\n",
      "Step(2100) loss: 6.8431 -- time: 4.5508 sec.\n",
      "Step(2110) loss: 6.6837 -- time: 4.5028 sec.\n",
      "Step(2120) loss: 6.3053 -- time: 4.3788 sec.\n",
      "Step(2130) loss: 6.1832 -- time: 4.4699 sec.\n",
      "Step(2140) loss: 6.5725 -- time: 4.5562 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1172.6975 - val_loss: 0.0000\n",
      "time: 83.2198 sec.\n",
      "time_left: 260.7552 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 13/200\n",
      "----------------------------------------------------------------------\n",
      "Step(2150) loss: 6.2957 -- time: 0.8238 sec.\n",
      "Step(2160) loss: 6.2203 -- time: 4.5207 sec.\n",
      "Step(2170) loss: 6.4312 -- time: 4.5667 sec.\n",
      "Step(2180) loss: 7.1683 -- time: 4.5095 sec.\n",
      "Step(2190) loss: 6.5537 -- time: 4.5031 sec.\n",
      "Step(2200) loss: 6.9288 -- time: 4.5291 sec.\n",
      "Step(2210) loss: 6.2796 -- time: 4.4176 sec.\n",
      "Step(2220) loss: 6.5696 -- time: 4.4721 sec.\n",
      "Step(2230) loss: 6.8956 -- time: 4.5808 sec.\n",
      "Step(2240) loss: 6.6460 -- time: 4.4866 sec.\n",
      "Step(2250) loss: 6.6006 -- time: 4.4019 sec.\n",
      "Step(2260) loss: 6.3736 -- time: 4.5682 sec.\n",
      "Step(2270) loss: 6.6474 -- time: 4.4732 sec.\n",
      "Step(2280) loss: 5.8573 -- time: 4.6328 sec.\n",
      "Step(2290) loss: 6.6417 -- time: 4.4287 sec.\n",
      "Step(2300) loss: 6.7653 -- time: 4.4905 sec.\n",
      "Step(2310) loss: 6.4160 -- time: 4.5086 sec.\n",
      "Step(2320) loss: 6.7597 -- time: 4.4725 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1170.7665 - val_loss: 0.0000\n",
      "time: 82.3748 sec.\n",
      "time_left: 256.7349 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 14/200\n",
      "----------------------------------------------------------------------\n",
      "Step(2330) loss: 6.5020 -- time: 1.2526 sec.\n",
      "Step(2340) loss: 6.5326 -- time: 4.4977 sec.\n",
      "Step(2350) loss: 6.3442 -- time: 4.5862 sec.\n",
      "Step(2360) loss: 6.6509 -- time: 4.4690 sec.\n",
      "Step(2370) loss: 6.4050 -- time: 4.4330 sec.\n",
      "Step(2380) loss: 6.3525 -- time: 4.3721 sec.\n",
      "Step(2390) loss: 6.1201 -- time: 4.4191 sec.\n",
      "Step(2400) loss: 6.4373 -- time: 4.5073 sec.\n",
      "Step(2410) loss: 5.7168 -- time: 4.4564 sec.\n",
      "Step(2420) loss: 6.5152 -- time: 4.4812 sec.\n",
      "Step(2430) loss: 6.8499 -- time: 4.4301 sec.\n",
      "Step(2440) loss: 6.4176 -- time: 4.5559 sec.\n",
      "Step(2450) loss: 6.4659 -- time: 4.4621 sec.\n",
      "Step(2460) loss: 6.0069 -- time: 4.6835 sec.\n",
      "Step(2470) loss: 6.5179 -- time: 4.3945 sec.\n",
      "Step(2480) loss: 6.6452 -- time: 4.5121 sec.\n",
      "Step(2490) loss: 6.5195 -- time: 4.5886 sec.\n",
      "Step(2500) loss: 6.3280 -- time: 4.5649 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1151.7465 - val_loss: 0.0000\n",
      "time: 82.1920 sec.\n",
      "time_left: 254.7953 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 15/200\n",
      "----------------------------------------------------------------------\n",
      "Step(2510) loss: 6.7228 -- time: 1.7816 sec.\n",
      "Step(2520) loss: 6.4383 -- time: 4.5958 sec.\n",
      "Step(2530) loss: 6.3320 -- time: 4.4375 sec.\n",
      "Step(2540) loss: 6.3239 -- time: 4.5293 sec.\n",
      "Step(2550) loss: 5.8575 -- time: 4.4386 sec.\n",
      "Step(2560) loss: 6.4144 -- time: 4.4851 sec.\n",
      "Step(2570) loss: 6.2382 -- time: 4.5960 sec.\n",
      "Step(2580) loss: 6.3134 -- time: 4.4226 sec.\n",
      "Step(2590) loss: 6.5048 -- time: 4.5939 sec.\n",
      "Step(2600) loss: 6.8004 -- time: 4.5421 sec.\n",
      "Step(2610) loss: 6.6685 -- time: 4.5129 sec.\n",
      "Step(2620) loss: 6.6339 -- time: 4.4333 sec.\n",
      "Step(2630) loss: 6.5093 -- time: 4.5732 sec.\n",
      "Step(2640) loss: 6.3906 -- time: 4.6963 sec.\n",
      "Step(2650) loss: 6.5593 -- time: 4.5527 sec.\n",
      "Step(2660) loss: 6.7804 -- time: 4.3619 sec.\n",
      "Step(2670) loss: 6.2331 -- time: 4.5775 sec.\n",
      "Step(2680) loss: 6.1666 -- time: 4.5802 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1139.0471 - val_loss: 0.0000\n",
      "time: 82.8937 sec.\n",
      "time_left: 255.5890 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 16/200\n",
      "----------------------------------------------------------------------\n",
      "Step(2690) loss: 6.2140 -- time: 2.2448 sec.\n",
      "Step(2700) loss: 6.9100 -- time: 4.5603 sec.\n",
      "Step(2710) loss: 6.1650 -- time: 4.3216 sec.\n",
      "Step(2720) loss: 6.1304 -- time: 4.5703 sec.\n",
      "Step(2730) loss: 5.6557 -- time: 4.3347 sec.\n",
      "Step(2740) loss: 6.3239 -- time: 4.4713 sec.\n",
      "Step(2750) loss: 6.1676 -- time: 4.5849 sec.\n",
      "Step(2760) loss: 5.6170 -- time: 4.5482 sec.\n",
      "Step(2770) loss: 6.4157 -- time: 4.5927 sec.\n",
      "Step(2780) loss: 6.1407 -- time: 4.4808 sec.\n",
      "Step(2790) loss: 6.9205 -- time: 4.5770 sec.\n",
      "Step(2800) loss: 7.3564 -- time: 4.4177 sec.\n",
      "Step(2810) loss: 5.9120 -- time: 4.3942 sec.\n",
      "Step(2820) loss: 6.6584 -- time: 4.5804 sec.\n",
      "Step(2830) loss: 6.2311 -- time: 4.4788 sec.\n",
      "Step(2840) loss: 6.1817 -- time: 4.5110 sec.\n",
      "Step(2850) loss: 6.3876 -- time: 4.4808 sec.\n",
      "Step(2860) loss: 6.0616 -- time: 4.4352 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1134.3589 - val_loss: 0.0000\n",
      "time: 82.2277 sec.\n",
      "time_left: 252.1649 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 17/200\n",
      "----------------------------------------------------------------------\n",
      "Step(2870) loss: 5.7791 -- time: 2.6122 sec.\n",
      "Step(2880) loss: 6.5548 -- time: 4.4927 sec.\n",
      "Step(2890) loss: 6.6373 -- time: 4.5448 sec.\n",
      "Step(2900) loss: 6.3925 -- time: 4.5868 sec.\n",
      "Step(2910) loss: 7.1156 -- time: 4.5842 sec.\n",
      "Step(2920) loss: 6.1548 -- time: 4.5560 sec.\n",
      "Step(2930) loss: 6.3844 -- time: 4.4179 sec.\n",
      "Step(2940) loss: 6.7715 -- time: 4.5492 sec.\n",
      "Step(2950) loss: 6.0593 -- time: 4.5402 sec.\n",
      "Step(2960) loss: 6.1635 -- time: 4.4652 sec.\n",
      "Step(2970) loss: 6.2350 -- time: 4.5495 sec.\n",
      "Step(2980) loss: 5.7012 -- time: 4.5075 sec.\n",
      "Step(2990) loss: 6.4627 -- time: 4.5412 sec.\n",
      "Step(3000) loss: 6.6331 -- time: 4.5986 sec.\n",
      "Step(3010) loss: 6.6539 -- time: 4.5965 sec.\n",
      "Step(3020) loss: 6.5128 -- time: 4.5162 sec.\n",
      "Step(3030) loss: 6.7024 -- time: 4.4774 sec.\n",
      "Step(3040) loss: 6.5121 -- time: 4.5241 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1135.8210 - val_loss: 0.0000\n",
      "time: 82.8195 sec.\n",
      "time_left: 252.5994 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 18/200\n",
      "----------------------------------------------------------------------\n",
      "Step(3050) loss: 6.2469 -- time: 2.9977 sec.\n",
      "Step(3060) loss: 6.3923 -- time: 4.6498 sec.\n",
      "Step(3070) loss: 6.4275 -- time: 4.6531 sec.\n",
      "Step(3080) loss: 6.2139 -- time: 4.6024 sec.\n",
      "Step(3090) loss: 6.0345 -- time: 4.3892 sec.\n",
      "Step(3100) loss: 6.0327 -- time: 4.5291 sec.\n",
      "Step(3110) loss: 6.1828 -- time: 4.5487 sec.\n",
      "Step(3120) loss: 6.1196 -- time: 4.5700 sec.\n",
      "Step(3130) loss: 6.3969 -- time: 4.5135 sec.\n",
      "Step(3140) loss: 5.9208 -- time: 4.4841 sec.\n",
      "Step(3150) loss: 5.9184 -- time: 4.5471 sec.\n",
      "Step(3160) loss: 6.1901 -- time: 4.4980 sec.\n",
      "Step(3170) loss: 6.7474 -- time: 4.5941 sec.\n",
      "Step(3180) loss: 6.0518 -- time: 4.5463 sec.\n",
      "Step(3190) loss: 6.5087 -- time: 4.5609 sec.\n",
      "Step(3200) loss: 6.4341 -- time: 4.6389 sec.\n",
      "Step(3210) loss: 6.3620 -- time: 4.5505 sec.\n",
      "Step(3220) loss: 6.2527 -- time: 4.5599 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1112.0703 - val_loss: 0.0000\n",
      "time: 83.1831 sec.\n",
      "time_left: 252.3220 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 19/200\n",
      "----------------------------------------------------------------------\n",
      "Step(3230) loss: 6.9143 -- time: 3.6310 sec.\n",
      "Step(3240) loss: 6.4469 -- time: 4.6480 sec.\n",
      "Step(3250) loss: 6.0263 -- time: 4.5659 sec.\n",
      "Step(3260) loss: 6.1434 -- time: 4.5396 sec.\n",
      "Step(3270) loss: 6.0955 -- time: 4.5864 sec.\n",
      "Step(3280) loss: 6.3721 -- time: 4.4929 sec.\n",
      "Step(3290) loss: 6.3989 -- time: 4.4656 sec.\n",
      "Step(3300) loss: 5.9524 -- time: 4.5867 sec.\n",
      "Step(3310) loss: 6.6647 -- time: 4.6311 sec.\n",
      "Step(3320) loss: 5.9510 -- time: 4.4819 sec.\n",
      "Step(3330) loss: 5.9974 -- time: 4.4014 sec.\n",
      "Step(3340) loss: 6.2332 -- time: 4.5653 sec.\n",
      "Step(3350) loss: 6.0265 -- time: 4.5123 sec.\n",
      "Step(3360) loss: 5.7814 -- time: 4.5674 sec.\n",
      "Step(3370) loss: 6.1981 -- time: 4.4347 sec.\n",
      "Step(3380) loss: 6.2951 -- time: 4.5170 sec.\n",
      "Step(3390) loss: 6.1348 -- time: 4.6025 sec.\n",
      "Step(3400) loss: 6.6232 -- time: 4.5912 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1107.2120 - val_loss: 0.0000\n",
      "time: 83.1063 sec.\n",
      "time_left: 250.7039 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 20/200\n",
      "----------------------------------------------------------------------\n",
      "Step(3410) loss: 6.4255 -- time: 4.1164 sec.\n",
      "Step(3420) loss: 6.2422 -- time: 4.6568 sec.\n",
      "Step(3430) loss: 6.3455 -- time: 4.5755 sec.\n",
      "Step(3440) loss: 6.0543 -- time: 4.5852 sec.\n",
      "Step(3450) loss: 6.3762 -- time: 4.5868 sec.\n",
      "Step(3460) loss: 5.8659 -- time: 4.5367 sec.\n",
      "Step(3470) loss: 6.0154 -- time: 4.6234 sec.\n",
      "Step(3480) loss: 6.4592 -- time: 4.5467 sec.\n",
      "Step(3490) loss: 6.1901 -- time: 4.5836 sec.\n",
      "Step(3500) loss: 6.1012 -- time: 4.6048 sec.\n",
      "Step(3510) loss: 5.8886 -- time: 4.4626 sec.\n",
      "Step(3520) loss: 5.8402 -- time: 4.4917 sec.\n",
      "Step(3530) loss: 6.0212 -- time: 4.5549 sec.\n",
      "Step(3540) loss: 6.1783 -- time: 4.5835 sec.\n",
      "Step(3550) loss: 6.3193 -- time: 4.5121 sec.\n",
      "Step(3560) loss: 5.8066 -- time: 4.4408 sec.\n",
      "Step(3570) loss: 6.0232 -- time: 4.5778 sec.\n",
      "Step(3580) loss: 5.4855 -- time: 4.4137 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1100.8553 - val_loss: 1128.5772\n",
      "time: 120.2931 sec.\n",
      "time_left: 360.8792 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 21/200\n",
      "----------------------------------------------------------------------\n",
      "Step(3590) loss: 5.4060 -- time: 4.5612 sec.\n",
      "Step(3600) loss: 5.5743 -- time: 4.4531 sec.\n",
      "Step(3610) loss: 5.8876 -- time: 4.6329 sec.\n",
      "Step(3620) loss: 5.9248 -- time: 4.5247 sec.\n",
      "Step(3630) loss: 6.2789 -- time: 4.6781 sec.\n",
      "Step(3640) loss: 5.6754 -- time: 4.4556 sec.\n",
      "Step(3650) loss: 6.4717 -- time: 4.6088 sec.\n",
      "Step(3660) loss: 5.5152 -- time: 4.4580 sec.\n",
      "Step(3670) loss: 6.1397 -- time: 4.4691 sec.\n",
      "Step(3680) loss: 6.3074 -- time: 4.3836 sec.\n",
      "Step(3690) loss: 5.8627 -- time: 4.6065 sec.\n",
      "Step(3700) loss: 6.0796 -- time: 4.6086 sec.\n",
      "Step(3710) loss: 5.9445 -- time: 4.6168 sec.\n",
      "Step(3720) loss: 6.2697 -- time: 4.4672 sec.\n",
      "Step(3730) loss: 6.0034 -- time: 4.4311 sec.\n",
      "Step(3740) loss: 6.3390 -- time: 4.5798 sec.\n",
      "Step(3750) loss: 6.3502 -- time: 4.6229 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1086.3759 - val_loss: 0.0000\n",
      "time: 83.2106 sec.\n",
      "time_left: 248.2449 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 22/200\n",
      "----------------------------------------------------------------------\n",
      "Step(3760) loss: 6.1825 -- time: 0.3277 sec.\n",
      "Step(3770) loss: 6.0677 -- time: 4.7204 sec.\n",
      "Step(3780) loss: 5.9234 -- time: 4.4975 sec.\n",
      "Step(3790) loss: 5.8192 -- time: 4.5187 sec.\n",
      "Step(3800) loss: 6.0771 -- time: 4.6347 sec.\n",
      "Step(3810) loss: 5.9488 -- time: 4.6680 sec.\n",
      "Step(3820) loss: 6.1154 -- time: 4.5620 sec.\n",
      "Step(3830) loss: 6.1115 -- time: 4.4634 sec.\n",
      "Step(3840) loss: 6.3891 -- time: 4.5402 sec.\n",
      "Step(3850) loss: 5.9407 -- time: 4.5711 sec.\n",
      "Step(3860) loss: 6.4289 -- time: 4.5362 sec.\n",
      "Step(3870) loss: 6.8435 -- time: 4.6601 sec.\n",
      "Step(3880) loss: 6.2719 -- time: 4.5045 sec.\n",
      "Step(3890) loss: 5.8856 -- time: 4.6157 sec.\n",
      "Step(3900) loss: 5.6244 -- time: 4.3748 sec.\n",
      "Step(3910) loss: 6.2697 -- time: 4.6097 sec.\n",
      "Step(3920) loss: 5.8225 -- time: 4.5354 sec.\n",
      "Step(3930) loss: 5.9200 -- time: 4.6371 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1087.1411 - val_loss: 0.0000\n",
      "time: 83.5110 sec.\n",
      "time_left: 247.7493 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 23/200\n",
      "----------------------------------------------------------------------\n",
      "Step(3940) loss: 5.8159 -- time: 0.7854 sec.\n",
      "Step(3950) loss: 6.0878 -- time: 4.4373 sec.\n",
      "Step(3960) loss: 5.9415 -- time: 4.6342 sec.\n",
      "Step(3970) loss: 6.2995 -- time: 4.5191 sec.\n",
      "Step(3980) loss: 5.9999 -- time: 4.5669 sec.\n",
      "Step(3990) loss: 5.8167 -- time: 4.6339 sec.\n",
      "Step(4000) loss: 5.7591 -- time: 4.3950 sec.\n",
      "Step(4010) loss: 6.3867 -- time: 4.7390 sec.\n",
      "Step(4020) loss: 5.9001 -- time: 4.5184 sec.\n",
      "Step(4030) loss: 5.9196 -- time: 4.7393 sec.\n",
      "Step(4040) loss: 5.8815 -- time: 4.5019 sec.\n",
      "Step(4050) loss: 6.3068 -- time: 4.7130 sec.\n",
      "Step(4060) loss: 5.5325 -- time: 4.5646 sec.\n",
      "Step(4070) loss: 6.1089 -- time: 4.6680 sec.\n",
      "Step(4080) loss: 6.2692 -- time: 4.5937 sec.\n",
      "Step(4090) loss: 5.7054 -- time: 4.7084 sec.\n",
      "Step(4100) loss: 5.3280 -- time: 4.6563 sec.\n",
      "Step(4110) loss: 6.0884 -- time: 4.6070 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1078.6970 - val_loss: 0.0000\n",
      "time: 84.1432 sec.\n",
      "time_left: 248.2225 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 24/200\n",
      "----------------------------------------------------------------------\n",
      "Step(4120) loss: 5.8484 -- time: 1.2543 sec.\n",
      "Step(4130) loss: 5.9790 -- time: 4.5927 sec.\n",
      "Step(4140) loss: 6.3520 -- time: 4.6913 sec.\n",
      "Step(4150) loss: 6.0059 -- time: 4.4476 sec.\n",
      "Step(4160) loss: 6.0470 -- time: 4.5914 sec.\n",
      "Step(4170) loss: 6.0617 -- time: 4.6558 sec.\n",
      "Step(4180) loss: 5.9464 -- time: 4.3656 sec.\n",
      "Step(4190) loss: 6.1162 -- time: 4.6936 sec.\n",
      "Step(4200) loss: 6.6682 -- time: 4.6668 sec.\n",
      "Step(4210) loss: 5.6941 -- time: 4.5550 sec.\n",
      "Step(4220) loss: 5.7764 -- time: 4.7070 sec.\n",
      "Step(4230) loss: 5.8591 -- time: 4.4403 sec.\n",
      "Step(4240) loss: 6.0897 -- time: 4.5769 sec.\n",
      "Step(4250) loss: 6.5003 -- time: 4.5390 sec.\n",
      "Step(4260) loss: 5.7030 -- time: 4.5354 sec.\n",
      "Step(4270) loss: 5.5889 -- time: 4.5096 sec.\n",
      "Step(4280) loss: 5.6330 -- time: 4.6409 sec.\n",
      "Step(4290) loss: 5.8589 -- time: 4.5691 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1072.4909 - val_loss: 0.0000\n",
      "time: 83.7251 sec.\n",
      "time_left: 245.5936 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 25/200\n",
      "----------------------------------------------------------------------\n",
      "Step(4300) loss: 5.6511 -- time: 1.7408 sec.\n",
      "Step(4310) loss: 5.4498 -- time: 4.5842 sec.\n",
      "Step(4320) loss: 5.6499 -- time: 4.4814 sec.\n",
      "Step(4330) loss: 5.7077 -- time: 4.6786 sec.\n",
      "Step(4340) loss: 6.1257 -- time: 4.5193 sec.\n",
      "Step(4350) loss: 5.9809 -- time: 4.6566 sec.\n",
      "Step(4360) loss: 5.8026 -- time: 4.5931 sec.\n",
      "Step(4370) loss: 6.0078 -- time: 4.5943 sec.\n",
      "Step(4380) loss: 5.8037 -- time: 4.5623 sec.\n",
      "Step(4390) loss: 5.3341 -- time: 4.5591 sec.\n",
      "Step(4400) loss: 5.8637 -- time: 4.6472 sec.\n",
      "Step(4410) loss: 5.7133 -- time: 4.6814 sec.\n",
      "Step(4420) loss: 5.6215 -- time: 4.5882 sec.\n",
      "Step(4430) loss: 5.8824 -- time: 4.5825 sec.\n",
      "Step(4440) loss: 6.6333 -- time: 4.5533 sec.\n",
      "Step(4450) loss: 6.1429 -- time: 4.6311 sec.\n",
      "Step(4460) loss: 6.0568 -- time: 4.6194 sec.\n",
      "Step(4470) loss: 6.7124 -- time: 4.4022 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1065.8822 - val_loss: 0.0000\n",
      "time: 83.8192 sec.\n",
      "time_left: 244.4728 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 26/200\n",
      "----------------------------------------------------------------------\n",
      "Step(4480) loss: 6.0868 -- time: 2.2265 sec.\n",
      "Step(4490) loss: 6.2272 -- time: 4.6657 sec.\n",
      "Step(4500) loss: 5.7803 -- time: 4.5229 sec.\n",
      "Step(4510) loss: 5.7741 -- time: 4.4780 sec.\n",
      "Step(4520) loss: 5.7548 -- time: 4.6028 sec.\n",
      "Step(4530) loss: 6.0412 -- time: 4.6440 sec.\n",
      "Step(4540) loss: 5.7519 -- time: 4.6258 sec.\n",
      "Step(4550) loss: 5.9169 -- time: 4.7431 sec.\n",
      "Step(4560) loss: 6.5065 -- time: 4.6505 sec.\n",
      "Step(4570) loss: 5.7193 -- time: 4.6845 sec.\n",
      "Step(4580) loss: 5.3270 -- time: 4.4875 sec.\n",
      "Step(4590) loss: 5.8514 -- time: 4.7610 sec.\n",
      "Step(4600) loss: 5.8843 -- time: 4.5695 sec.\n",
      "Step(4610) loss: 5.5873 -- time: 4.6763 sec.\n",
      "Step(4620) loss: 5.3832 -- time: 4.5372 sec.\n",
      "Step(4630) loss: 6.3121 -- time: 4.6104 sec.\n",
      "Step(4640) loss: 6.4615 -- time: 4.5455 sec.\n",
      "Step(4650) loss: 6.2170 -- time: 4.6550 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1063.6556 - val_loss: 0.0000\n",
      "time: 84.3133 sec.\n",
      "time_left: 244.5085 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 27/200\n",
      "----------------------------------------------------------------------\n",
      "Step(4660) loss: 6.0720 -- time: 2.5687 sec.\n",
      "Step(4670) loss: 6.0910 -- time: 4.6276 sec.\n",
      "Step(4680) loss: 6.1483 -- time: 4.5529 sec.\n",
      "Step(4690) loss: 5.6682 -- time: 4.5317 sec.\n",
      "Step(4700) loss: 5.8449 -- time: 4.5801 sec.\n",
      "Step(4710) loss: 5.8182 -- time: 4.7010 sec.\n",
      "Step(4720) loss: 5.7195 -- time: 4.6472 sec.\n",
      "Step(4730) loss: 5.9272 -- time: 4.6191 sec.\n",
      "Step(4740) loss: 6.3243 -- time: 4.6433 sec.\n",
      "Step(4750) loss: 5.3549 -- time: 4.5679 sec.\n",
      "Step(4760) loss: 5.7037 -- time: 4.6845 sec.\n",
      "Step(4770) loss: 5.9314 -- time: 4.5840 sec.\n",
      "Step(4780) loss: 5.9017 -- time: 4.6694 sec.\n",
      "Step(4790) loss: 6.4103 -- time: 4.6190 sec.\n",
      "Step(4800) loss: 5.4039 -- time: 4.6701 sec.\n",
      "Step(4810) loss: 5.8133 -- time: 4.6388 sec.\n",
      "Step(4820) loss: 5.9773 -- time: 4.4931 sec.\n",
      "Step(4830) loss: 5.8098 -- time: 4.5960 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1053.7702 - val_loss: 0.0000\n",
      "time: 84.1911 sec.\n",
      "time_left: 242.7510 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 28/200\n",
      "----------------------------------------------------------------------\n",
      "Step(4840) loss: 5.5960 -- time: 3.2974 sec.\n",
      "Step(4850) loss: 6.4351 -- time: 4.5297 sec.\n",
      "Step(4860) loss: 5.8473 -- time: 4.6014 sec.\n",
      "Step(4870) loss: 6.0268 -- time: 4.5493 sec.\n",
      "Step(4880) loss: 5.8112 -- time: 4.6643 sec.\n",
      "Step(4890) loss: 5.6735 -- time: 4.4847 sec.\n",
      "Step(4900) loss: 5.7116 -- time: 4.6507 sec.\n",
      "Step(4910) loss: 5.2537 -- time: 4.6339 sec.\n",
      "Step(4920) loss: 5.7522 -- time: 4.5710 sec.\n",
      "Step(4930) loss: 5.9977 -- time: 4.5576 sec.\n",
      "Step(4940) loss: 5.9589 -- time: 4.7080 sec.\n",
      "Step(4950) loss: 5.9840 -- time: 4.6327 sec.\n",
      "Step(4960) loss: 5.6311 -- time: 4.6049 sec.\n",
      "Step(4970) loss: 5.7280 -- time: 4.5086 sec.\n",
      "Step(4980) loss: 5.9449 -- time: 4.7229 sec.\n",
      "Step(4990) loss: 5.6986 -- time: 4.5356 sec.\n",
      "Step(5000) loss: 5.8808 -- time: 4.6563 sec.\n",
      "Step(5010) loss: 5.7499 -- time: 4.6314 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1054.3833 - val_loss: 0.0000\n",
      "time: 84.2934 sec.\n",
      "time_left: 241.6410 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 29/200\n",
      "----------------------------------------------------------------------\n",
      "Step(5020) loss: 5.5439 -- time: 3.5747 sec.\n",
      "Step(5030) loss: 5.7232 -- time: 4.5844 sec.\n",
      "Step(5040) loss: 6.1033 -- time: 4.5264 sec.\n",
      "Step(5050) loss: 6.0968 -- time: 4.4988 sec.\n",
      "Step(5060) loss: 5.8651 -- time: 4.6676 sec.\n",
      "Step(5070) loss: 5.8343 -- time: 4.6081 sec.\n",
      "Step(5080) loss: 5.9057 -- time: 4.5370 sec.\n",
      "Step(5090) loss: 5.7463 -- time: 4.5527 sec.\n",
      "Step(5100) loss: 5.4842 -- time: 4.5742 sec.\n",
      "Step(5110) loss: 5.5171 -- time: 4.5963 sec.\n",
      "Step(5120) loss: 5.7755 -- time: 4.6793 sec.\n",
      "Step(5130) loss: 6.0129 -- time: 4.5887 sec.\n",
      "Step(5140) loss: 5.5265 -- time: 4.6334 sec.\n",
      "Step(5150) loss: 6.4750 -- time: 4.4462 sec.\n",
      "Step(5160) loss: 5.9196 -- time: 4.5633 sec.\n",
      "Step(5170) loss: 5.5065 -- time: 4.4996 sec.\n",
      "Step(5180) loss: 5.5703 -- time: 4.6071 sec.\n",
      "Step(5190) loss: 6.0244 -- time: 4.5686 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1042.1555 - val_loss: 0.0000\n",
      "time: 83.5991 sec.\n",
      "time_left: 238.2573 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 30/200\n",
      "----------------------------------------------------------------------\n",
      "Step(5200) loss: 6.1819 -- time: 4.1453 sec.\n",
      "Step(5210) loss: 6.0358 -- time: 4.6501 sec.\n",
      "Step(5220) loss: 5.3638 -- time: 4.5337 sec.\n",
      "Step(5230) loss: 5.9192 -- time: 4.6233 sec.\n",
      "Step(5240) loss: 6.0572 -- time: 4.5711 sec.\n",
      "Step(5250) loss: 6.1021 -- time: 4.4456 sec.\n",
      "Step(5260) loss: 5.6861 -- time: 4.5268 sec.\n",
      "Step(5270) loss: 6.5874 -- time: 4.5197 sec.\n",
      "Step(5280) loss: 5.5123 -- time: 4.6474 sec.\n",
      "Step(5290) loss: 5.7362 -- time: 4.7356 sec.\n",
      "Step(5300) loss: 6.1596 -- time: 4.6250 sec.\n",
      "Step(5310) loss: 5.8468 -- time: 4.6892 sec.\n",
      "Step(5320) loss: 5.7689 -- time: 4.6629 sec.\n",
      "Step(5330) loss: 5.5038 -- time: 4.6277 sec.\n",
      "Step(5340) loss: 5.4254 -- time: 4.5923 sec.\n",
      "Step(5350) loss: 5.7248 -- time: 4.5800 sec.\n",
      "Step(5360) loss: 5.8259 -- time: 4.5788 sec.\n",
      "Step(5370) loss: 5.6164 -- time: 4.4328 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1043.4650 - val_loss: 1061.8149\n",
      "time: 120.9803 sec.\n",
      "time_left: 342.7776 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 31/200\n",
      "----------------------------------------------------------------------\n",
      "Step(5380) loss: 6.1724 -- time: 4.6949 sec.\n",
      "Step(5390) loss: 5.7314 -- time: 4.6752 sec.\n",
      "Step(5400) loss: 6.0144 -- time: 4.5894 sec.\n",
      "Step(5410) loss: 5.7448 -- time: 4.6622 sec.\n",
      "Step(5420) loss: 5.7845 -- time: 4.5949 sec.\n",
      "Step(5430) loss: 5.9244 -- time: 4.5466 sec.\n",
      "Step(5440) loss: 5.5325 -- time: 4.7020 sec.\n",
      "Step(5450) loss: 5.9029 -- time: 4.5520 sec.\n",
      "Step(5460) loss: 5.5538 -- time: 4.6745 sec.\n",
      "Step(5470) loss: 6.0850 -- time: 4.6792 sec.\n",
      "Step(5480) loss: 6.0904 -- time: 4.8321 sec.\n",
      "Step(5490) loss: 5.2767 -- time: 4.5561 sec.\n",
      "Step(5500) loss: 6.4195 -- time: 4.5248 sec.\n",
      "Step(5510) loss: 5.7273 -- time: 4.4931 sec.\n",
      "Step(5520) loss: 5.5458 -- time: 4.6865 sec.\n",
      "Step(5530) loss: 5.9281 -- time: 4.5787 sec.\n",
      "Step(5540) loss: 5.3810 -- time: 4.4821 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1039.3048 - val_loss: 0.0000\n",
      "time: 84.4741 sec.\n",
      "time_left: 237.9354 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 32/200\n",
      "----------------------------------------------------------------------\n",
      "Step(5550) loss: 5.7197 -- time: 0.3768 sec.\n",
      "Step(5560) loss: 5.5048 -- time: 4.7048 sec.\n",
      "Step(5570) loss: 5.8089 -- time: 4.6147 sec.\n",
      "Step(5580) loss: 5.7352 -- time: 4.6963 sec.\n",
      "Step(5590) loss: 6.2229 -- time: 4.6751 sec.\n",
      "Step(5600) loss: 6.1450 -- time: 4.5737 sec.\n",
      "Step(5610) loss: 5.6905 -- time: 4.7381 sec.\n",
      "Step(5620) loss: 5.7741 -- time: 4.6922 sec.\n",
      "Step(5630) loss: 5.7478 -- time: 4.6597 sec.\n",
      "Step(5640) loss: 6.2087 -- time: 4.5653 sec.\n",
      "Step(5650) loss: 5.7290 -- time: 4.7182 sec.\n",
      "Step(5660) loss: 6.1969 -- time: 4.6378 sec.\n",
      "Step(5670) loss: 5.6059 -- time: 4.6039 sec.\n",
      "Step(5680) loss: 5.6477 -- time: 4.5801 sec.\n",
      "Step(5690) loss: 5.5450 -- time: 4.5029 sec.\n",
      "Step(5700) loss: 5.1928 -- time: 4.7220 sec.\n",
      "Step(5710) loss: 6.0904 -- time: 4.7462 sec.\n",
      "Step(5720) loss: 6.3129 -- time: 4.6273 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1031.5846 - val_loss: 0.0000\n",
      "time: 85.1171 sec.\n",
      "time_left: 238.3278 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 33/200\n",
      "----------------------------------------------------------------------\n",
      "Step(5730) loss: 6.1083 -- time: 0.7838 sec.\n",
      "Step(5740) loss: 5.8255 -- time: 4.6294 sec.\n",
      "Step(5750) loss: 5.3903 -- time: 4.6119 sec.\n",
      "Step(5760) loss: 5.2803 -- time: 4.5993 sec.\n",
      "Step(5770) loss: 5.5751 -- time: 4.6957 sec.\n",
      "Step(5780) loss: 5.6999 -- time: 4.5975 sec.\n",
      "Step(5790) loss: 5.6636 -- time: 4.4739 sec.\n",
      "Step(5800) loss: 6.2424 -- time: 4.6290 sec.\n",
      "Step(5810) loss: 5.5888 -- time: 4.5386 sec.\n",
      "Step(5820) loss: 5.5253 -- time: 4.7883 sec.\n",
      "Step(5830) loss: 5.1306 -- time: 4.5837 sec.\n",
      "Step(5840) loss: 5.9766 -- time: 4.5980 sec.\n",
      "Step(5850) loss: 5.6417 -- time: 4.5881 sec.\n",
      "Step(5860) loss: 5.3388 -- time: 4.6007 sec.\n",
      "Step(5870) loss: 5.7856 -- time: 4.6804 sec.\n",
      "Step(5880) loss: 5.5834 -- time: 4.6740 sec.\n",
      "Step(5890) loss: 5.7148 -- time: 4.6406 sec.\n",
      "Step(5900) loss: 5.8474 -- time: 4.6134 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1022.8526 - val_loss: 0.0000\n",
      "time: 84.4125 sec.\n",
      "time_left: 234.9482 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 34/200\n",
      "----------------------------------------------------------------------\n",
      "Step(5910) loss: 5.0551 -- time: 1.3351 sec.\n",
      "Step(5920) loss: 5.5648 -- time: 4.7247 sec.\n",
      "Step(5930) loss: 5.8761 -- time: 4.5859 sec.\n",
      "Step(5940) loss: 5.6259 -- time: 4.5817 sec.\n",
      "Step(5950) loss: 6.1922 -- time: 4.6739 sec.\n",
      "Step(5960) loss: 5.8148 -- time: 4.5834 sec.\n",
      "Step(5970) loss: 5.8754 -- time: 4.6244 sec.\n",
      "Step(5980) loss: 5.4434 -- time: 4.5838 sec.\n",
      "Step(5990) loss: 5.7304 -- time: 4.6170 sec.\n",
      "Step(6000) loss: 6.1154 -- time: 4.7314 sec.\n",
      "Step(6010) loss: 6.2647 -- time: 4.8190 sec.\n",
      "Step(6020) loss: 5.5527 -- time: 4.6797 sec.\n",
      "Step(6030) loss: 6.3613 -- time: 4.6189 sec.\n",
      "Step(6040) loss: 5.6410 -- time: 4.6826 sec.\n",
      "Step(6050) loss: 5.6292 -- time: 4.6702 sec.\n",
      "Step(6060) loss: 5.8993 -- time: 4.6407 sec.\n",
      "Step(6070) loss: 6.0714 -- time: 4.7937 sec.\n",
      "Step(6080) loss: 5.8743 -- time: 4.6980 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1022.1364 - val_loss: 0.0000\n",
      "time: 85.3078 sec.\n",
      "time_left: 236.0183 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 35/200\n",
      "----------------------------------------------------------------------\n",
      "Step(6090) loss: 5.5901 -- time: 1.8206 sec.\n",
      "Step(6100) loss: 5.8785 -- time: 4.6733 sec.\n",
      "Step(6110) loss: 5.7156 -- time: 4.6024 sec.\n",
      "Step(6120) loss: 6.4607 -- time: 4.7079 sec.\n",
      "Step(6130) loss: 6.3360 -- time: 4.7410 sec.\n",
      "Step(6140) loss: 5.4567 -- time: 4.6317 sec.\n",
      "Step(6150) loss: 5.5901 -- time: 4.7604 sec.\n",
      "Step(6160) loss: 6.0482 -- time: 4.7367 sec.\n",
      "Step(6170) loss: 6.0056 -- time: 4.6629 sec.\n",
      "Step(6180) loss: 5.9998 -- time: 4.7242 sec.\n",
      "Step(6190) loss: 5.5445 -- time: 4.6123 sec.\n",
      "Step(6200) loss: 5.6238 -- time: 4.7392 sec.\n",
      "Step(6210) loss: 5.3385 -- time: 4.6549 sec.\n",
      "Step(6220) loss: 6.2503 -- time: 4.7183 sec.\n",
      "Step(6230) loss: 5.6917 -- time: 4.6994 sec.\n",
      "Step(6240) loss: 5.8025 -- time: 4.6528 sec.\n",
      "Step(6250) loss: 5.2854 -- time: 4.5970 sec.\n",
      "Step(6260) loss: 6.2814 -- time: 4.5845 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1018.9198 - val_loss: 0.0000\n",
      "time: 85.5453 sec.\n",
      "time_left: 235.2495 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 36/200\n",
      "----------------------------------------------------------------------\n",
      "Step(6270) loss: 5.5001 -- time: 2.2619 sec.\n",
      "Step(6280) loss: 5.4050 -- time: 4.7114 sec.\n",
      "Step(6290) loss: 6.1841 -- time: 4.8214 sec.\n",
      "Step(6300) loss: 5.2203 -- time: 4.7386 sec.\n",
      "Step(6310) loss: 5.8698 -- time: 4.7334 sec.\n",
      "Step(6320) loss: 6.0117 -- time: 4.5609 sec.\n",
      "Step(6330) loss: 5.2438 -- time: 4.7044 sec.\n",
      "Step(6340) loss: 5.4226 -- time: 4.6775 sec.\n",
      "Step(6350) loss: 5.7832 -- time: 4.5619 sec.\n",
      "Step(6360) loss: 5.3945 -- time: 4.7191 sec.\n",
      "Step(6370) loss: 5.5313 -- time: 4.4674 sec.\n",
      "Step(6380) loss: 5.3991 -- time: 4.5892 sec.\n",
      "Step(6390) loss: 5.7479 -- time: 4.6312 sec.\n",
      "Step(6400) loss: 6.0657 -- time: 4.6179 sec.\n",
      "Step(6410) loss: 5.5625 -- time: 4.4585 sec.\n",
      "Step(6420) loss: 5.8887 -- time: 4.5422 sec.\n",
      "Step(6430) loss: 5.6415 -- time: 4.5545 sec.\n",
      "Step(6440) loss: 5.7690 -- time: 4.7328 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1013.2252 - val_loss: 0.0000\n",
      "time: 84.8196 sec.\n",
      "time_left: 231.8402 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 37/200\n",
      "----------------------------------------------------------------------\n",
      "Step(6450) loss: 6.3011 -- time: 2.6246 sec.\n",
      "Step(6460) loss: 6.2195 -- time: 4.6272 sec.\n",
      "Step(6470) loss: 5.2835 -- time: 4.5505 sec.\n",
      "Step(6480) loss: 5.4049 -- time: 4.4020 sec.\n",
      "Step(6490) loss: 5.7005 -- time: 4.5553 sec.\n",
      "Step(6500) loss: 6.1438 -- time: 4.5504 sec.\n",
      "Step(6510) loss: 5.4747 -- time: 4.5057 sec.\n",
      "Step(6520) loss: 5.8836 -- time: 4.4229 sec.\n",
      "Step(6530) loss: 6.0969 -- time: 4.5168 sec.\n",
      "Step(6540) loss: 6.0529 -- time: 4.6108 sec.\n",
      "Step(6550) loss: 5.5583 -- time: 4.5527 sec.\n",
      "Step(6560) loss: 5.1547 -- time: 4.6598 sec.\n",
      "Step(6570) loss: 6.0928 -- time: 4.6031 sec.\n",
      "Step(6580) loss: 5.8827 -- time: 4.6916 sec.\n",
      "Step(6590) loss: 5.8926 -- time: 4.4975 sec.\n",
      "Step(6600) loss: 5.3839 -- time: 4.5395 sec.\n",
      "Step(6610) loss: 5.5851 -- time: 4.5065 sec.\n",
      "Step(6620) loss: 5.0083 -- time: 4.6432 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1016.9025 - val_loss: 0.0000\n",
      "time: 83.2814 sec.\n",
      "time_left: 226.2478 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 38/200\n",
      "----------------------------------------------------------------------\n",
      "Step(6630) loss: 5.3126 -- time: 3.2057 sec.\n",
      "Step(6640) loss: 5.6258 -- time: 4.6008 sec.\n",
      "Step(6650) loss: 5.5769 -- time: 4.5455 sec.\n",
      "Step(6660) loss: 5.6947 -- time: 4.6046 sec.\n",
      "Step(6670) loss: 5.5887 -- time: 4.6457 sec.\n",
      "Step(6680) loss: 5.8019 -- time: 4.6006 sec.\n",
      "Step(6690) loss: 5.5227 -- time: 4.6775 sec.\n",
      "Step(6700) loss: 5.3495 -- time: 4.5827 sec.\n",
      "Step(6710) loss: 6.0532 -- time: 4.6535 sec.\n",
      "Step(6720) loss: 5.8051 -- time: 4.5654 sec.\n",
      "Step(6730) loss: 5.7307 -- time: 4.5812 sec.\n",
      "Step(6740) loss: 5.8491 -- time: 4.5459 sec.\n",
      "Step(6750) loss: 5.4952 -- time: 4.5698 sec.\n",
      "Step(6760) loss: 5.3106 -- time: 4.6685 sec.\n",
      "Step(6770) loss: 5.0634 -- time: 4.5425 sec.\n",
      "Step(6780) loss: 5.8639 -- time: 4.6911 sec.\n",
      "Step(6790) loss: 6.3505 -- time: 4.6192 sec.\n",
      "Step(6800) loss: 5.2551 -- time: 4.5837 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1005.8708 - val_loss: 0.0000\n",
      "time: 84.2466 sec.\n",
      "time_left: 227.4658 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 39/200\n",
      "----------------------------------------------------------------------\n",
      "Step(6810) loss: 5.9067 -- time: 3.7007 sec.\n",
      "Step(6820) loss: 5.7760 -- time: 4.5967 sec.\n",
      "Step(6830) loss: 5.1827 -- time: 4.5417 sec.\n",
      "Step(6840) loss: 6.1451 -- time: 4.6196 sec.\n",
      "Step(6850) loss: 6.2746 -- time: 4.6377 sec.\n",
      "Step(6860) loss: 5.6825 -- time: 4.5778 sec.\n",
      "Step(6870) loss: 5.7078 -- time: 4.5071 sec.\n",
      "Step(6880) loss: 6.0573 -- time: 4.5487 sec.\n",
      "Step(6890) loss: 5.8984 -- time: 4.6603 sec.\n",
      "Step(6900) loss: 5.6626 -- time: 4.7156 sec.\n",
      "Step(6910) loss: 5.2943 -- time: 4.5706 sec.\n",
      "Step(6920) loss: 5.0098 -- time: 4.6165 sec.\n",
      "Step(6930) loss: 5.5803 -- time: 4.5872 sec.\n",
      "Step(6940) loss: 5.6424 -- time: 4.6155 sec.\n",
      "Step(6950) loss: 5.5620 -- time: 4.6587 sec.\n",
      "Step(6960) loss: 6.0185 -- time: 4.6113 sec.\n",
      "Step(6970) loss: 5.5093 -- time: 4.6728 sec.\n",
      "Step(6980) loss: 5.7103 -- time: 4.4534 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1014.1777 - val_loss: 0.0000\n",
      "time: 84.1609 sec.\n",
      "time_left: 225.8319 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 40/200\n",
      "----------------------------------------------------------------------\n",
      "Step(6990) loss: 5.1377 -- time: 4.1091 sec.\n",
      "Step(7000) loss: 5.3290 -- time: 4.6490 sec.\n",
      "Step(7010) loss: 5.1705 -- time: 4.4985 sec.\n",
      "Step(7020) loss: 5.5112 -- time: 4.5843 sec.\n",
      "Step(7030) loss: 5.7620 -- time: 4.6209 sec.\n",
      "Step(7040) loss: 5.5869 -- time: 4.5248 sec.\n",
      "Step(7050) loss: 5.5395 -- time: 4.6325 sec.\n",
      "Step(7060) loss: 5.6342 -- time: 4.7273 sec.\n",
      "Step(7070) loss: 5.7949 -- time: 4.5941 sec.\n",
      "Step(7080) loss: 5.9476 -- time: 4.5197 sec.\n",
      "Step(7090) loss: 5.5079 -- time: 4.5928 sec.\n",
      "Step(7100) loss: 5.5772 -- time: 4.6180 sec.\n",
      "Step(7110) loss: 5.5038 -- time: 4.6836 sec.\n",
      "Step(7120) loss: 5.6899 -- time: 4.5633 sec.\n",
      "Step(7130) loss: 5.5056 -- time: 4.6271 sec.\n",
      "Step(7140) loss: 5.5607 -- time: 4.5432 sec.\n",
      "Step(7150) loss: 5.3706 -- time: 4.5551 sec.\n",
      "Step(7160) loss: 5.7454 -- time: 4.4452 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1000.4013 - val_loss: 1017.5751\n",
      "time: 121.0474 sec.\n",
      "time_left: 322.7931 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 41/200\n",
      "----------------------------------------------------------------------\n",
      "Step(7170) loss: 5.2924 -- time: 4.6122 sec.\n",
      "Step(7180) loss: 5.3611 -- time: 4.6361 sec.\n",
      "Step(7190) loss: 5.0219 -- time: 4.6507 sec.\n",
      "Step(7200) loss: 5.2014 -- time: 4.6655 sec.\n",
      "Step(7210) loss: 5.9144 -- time: 4.5296 sec.\n",
      "Step(7220) loss: 5.7717 -- time: 4.4878 sec.\n",
      "Step(7230) loss: 5.7734 -- time: 4.5677 sec.\n",
      "Step(7240) loss: 5.1856 -- time: 4.5513 sec.\n",
      "Step(7250) loss: 4.8155 -- time: 4.4750 sec.\n",
      "Step(7260) loss: 5.9209 -- time: 4.5845 sec.\n",
      "Step(7270) loss: 5.8703 -- time: 4.5430 sec.\n",
      "Step(7280) loss: 5.3587 -- time: 4.6641 sec.\n",
      "Step(7290) loss: 6.0746 -- time: 4.5869 sec.\n",
      "Step(7300) loss: 5.4947 -- time: 4.7201 sec.\n",
      "Step(7310) loss: 5.2435 -- time: 4.6364 sec.\n",
      "Step(7320) loss: 5.5128 -- time: 4.6266 sec.\n",
      "Step(7330) loss: 5.5929 -- time: 4.6207 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1002.3125 - val_loss: 0.0000\n",
      "time: 84.1225 sec.\n",
      "time_left: 222.9246 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 42/200\n",
      "----------------------------------------------------------------------\n",
      "Step(7340) loss: 5.7449 -- time: 0.3645 sec.\n",
      "Step(7350) loss: 4.9630 -- time: 4.5305 sec.\n",
      "Step(7360) loss: 5.4832 -- time: 4.5589 sec.\n",
      "Step(7370) loss: 5.3963 -- time: 4.6105 sec.\n",
      "Step(7380) loss: 5.0911 -- time: 4.5682 sec.\n",
      "Step(7390) loss: 5.5282 -- time: 4.6412 sec.\n",
      "Step(7400) loss: 5.6219 -- time: 4.6270 sec.\n",
      "Step(7410) loss: 5.4960 -- time: 4.6334 sec.\n",
      "Step(7420) loss: 5.4334 -- time: 4.4486 sec.\n",
      "Step(7430) loss: 5.7316 -- time: 4.6669 sec.\n",
      "Step(7440) loss: 5.8758 -- time: 4.4654 sec.\n",
      "Step(7450) loss: 5.8735 -- time: 4.6413 sec.\n",
      "Step(7460) loss: 5.9050 -- time: 4.7124 sec.\n",
      "Step(7470) loss: 5.9987 -- time: 4.6081 sec.\n",
      "Step(7480) loss: 5.9215 -- time: 4.5631 sec.\n",
      "Step(7490) loss: 5.6237 -- time: 4.5028 sec.\n",
      "Step(7500) loss: 5.3721 -- time: 4.5867 sec.\n",
      "Step(7510) loss: 5.6979 -- time: 4.6405 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 993.4685 - val_loss: 0.0000\n",
      "time: 83.8783 sec.\n",
      "time_left: 220.8794 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 43/200\n",
      "----------------------------------------------------------------------\n",
      "Step(7520) loss: 5.6367 -- time: 0.8482 sec.\n",
      "Step(7530) loss: 5.5184 -- time: 4.5935 sec.\n",
      "Step(7540) loss: 5.5979 -- time: 4.5600 sec.\n",
      "Step(7550) loss: 5.0626 -- time: 4.5535 sec.\n",
      "Step(7560) loss: 5.5557 -- time: 4.6491 sec.\n",
      "Step(7570) loss: 5.9151 -- time: 4.5430 sec.\n",
      "Step(7580) loss: 6.0600 -- time: 4.5707 sec.\n",
      "Step(7590) loss: 5.4208 -- time: 4.5252 sec.\n",
      "Step(7600) loss: 5.9495 -- time: 4.5739 sec.\n",
      "Step(7610) loss: 5.6277 -- time: 4.6335 sec.\n",
      "Step(7620) loss: 5.6947 -- time: 4.5735 sec.\n",
      "Step(7630) loss: 6.1076 -- time: 4.4786 sec.\n",
      "Step(7640) loss: 5.4030 -- time: 4.6065 sec.\n",
      "Step(7650) loss: 5.8311 -- time: 4.5279 sec.\n",
      "Step(7660) loss: 5.6859 -- time: 4.6276 sec.\n",
      "Step(7670) loss: 5.4334 -- time: 4.7563 sec.\n",
      "Step(7680) loss: 5.8360 -- time: 4.6065 sec.\n",
      "Step(7690) loss: 4.8291 -- time: 4.6101 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 998.9580 - val_loss: 0.0000\n",
      "time: 84.0783 sec.\n",
      "time_left: 220.0048 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 44/200\n",
      "----------------------------------------------------------------------\n",
      "Step(7700) loss: 5.4761 -- time: 1.2979 sec.\n",
      "Step(7710) loss: 5.7039 -- time: 4.5316 sec.\n",
      "Step(7720) loss: 5.7835 -- time: 4.4613 sec.\n",
      "Step(7730) loss: 5.4357 -- time: 4.6419 sec.\n",
      "Step(7740) loss: 5.9922 -- time: 4.6338 sec.\n",
      "Step(7750) loss: 5.5757 -- time: 4.6829 sec.\n",
      "Step(7760) loss: 5.5422 -- time: 4.7638 sec.\n",
      "Step(7770) loss: 5.4986 -- time: 4.5798 sec.\n",
      "Step(7780) loss: 5.7566 -- time: 4.6072 sec.\n",
      "Step(7790) loss: 5.7561 -- time: 4.5666 sec.\n",
      "Step(7800) loss: 5.7555 -- time: 4.6005 sec.\n",
      "Step(7810) loss: 5.8219 -- time: 4.6705 sec.\n",
      "Step(7820) loss: 5.5577 -- time: 4.5745 sec.\n",
      "Step(7830) loss: 5.0209 -- time: 4.5368 sec.\n",
      "Step(7840) loss: 5.6882 -- time: 4.4193 sec.\n",
      "Step(7850) loss: 5.4845 -- time: 4.6423 sec.\n",
      "Step(7860) loss: 5.6972 -- time: 4.5933 sec.\n",
      "Step(7870) loss: 5.3267 -- time: 4.5394 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 989.2288 - val_loss: 0.0000\n",
      "time: 84.0262 sec.\n",
      "time_left: 218.4680 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 45/200\n",
      "----------------------------------------------------------------------\n",
      "Step(7880) loss: 5.7193 -- time: 1.8028 sec.\n",
      "Step(7890) loss: 5.6054 -- time: 4.5032 sec.\n",
      "Step(7900) loss: 5.2740 -- time: 4.7154 sec.\n",
      "Step(7910) loss: 5.6347 -- time: 4.4358 sec.\n",
      "Step(7920) loss: 5.4937 -- time: 4.6716 sec.\n",
      "Step(7930) loss: 5.7245 -- time: 4.5574 sec.\n",
      "Step(7940) loss: 5.2145 -- time: 4.6130 sec.\n",
      "Step(7950) loss: 5.8212 -- time: 4.8409 sec.\n",
      "Step(7960) loss: 5.5152 -- time: 4.5736 sec.\n",
      "Step(7970) loss: 5.6864 -- time: 4.6033 sec.\n",
      "Step(7980) loss: 5.5963 -- time: 4.6680 sec.\n",
      "Step(7990) loss: 5.3855 -- time: 4.5908 sec.\n",
      "Step(8000) loss: 5.7910 -- time: 4.5342 sec.\n",
      "Step(8010) loss: 5.7817 -- time: 4.6775 sec.\n",
      "Step(8020) loss: 5.7229 -- time: 4.6791 sec.\n",
      "Step(8030) loss: 5.6809 -- time: 4.6451 sec.\n",
      "Step(8040) loss: 5.1645 -- time: 4.6748 sec.\n",
      "Step(8050) loss: 5.7570 -- time: 4.5904 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 989.2403 - val_loss: 0.0000\n",
      "time: 84.5972 sec.\n",
      "time_left: 218.5427 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 46/200\n",
      "----------------------------------------------------------------------\n",
      "Step(8060) loss: 6.0381 -- time: 2.2758 sec.\n",
      "Step(8070) loss: 4.6623 -- time: 4.6631 sec.\n",
      "Step(8080) loss: 5.0894 -- time: 4.6772 sec.\n",
      "Step(8090) loss: 5.6302 -- time: 4.5467 sec.\n",
      "Step(8100) loss: 5.6796 -- time: 4.6087 sec.\n",
      "Step(8110) loss: 5.8455 -- time: 4.6473 sec.\n",
      "Step(8120) loss: 5.3906 -- time: 4.5290 sec.\n",
      "Step(8130) loss: 5.4243 -- time: 4.6482 sec.\n",
      "Step(8140) loss: 5.8081 -- time: 4.5947 sec.\n",
      "Step(8150) loss: 5.6666 -- time: 4.5930 sec.\n",
      "Step(8160) loss: 5.8799 -- time: 4.5512 sec.\n",
      "Step(8170) loss: 5.2648 -- time: 4.5693 sec.\n",
      "Step(8180) loss: 5.6339 -- time: 4.4172 sec.\n",
      "Step(8190) loss: 5.2959 -- time: 4.6163 sec.\n",
      "Step(8200) loss: 6.1784 -- time: 4.5139 sec.\n",
      "Step(8210) loss: 6.0717 -- time: 4.5347 sec.\n",
      "Step(8220) loss: 5.7879 -- time: 4.7202 sec.\n",
      "Step(8230) loss: 5.7269 -- time: 4.6569 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 988.8422 - val_loss: 0.0000\n",
      "time: 84.1054 sec.\n",
      "time_left: 215.8706 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 47/200\n",
      "----------------------------------------------------------------------\n",
      "Step(8240) loss: 5.7083 -- time: 2.7317 sec.\n",
      "Step(8250) loss: 5.3958 -- time: 4.5563 sec.\n",
      "Step(8260) loss: 5.5665 -- time: 4.4974 sec.\n",
      "Step(8270) loss: 5.6279 -- time: 4.6284 sec.\n",
      "Step(8280) loss: 5.9615 -- time: 4.6900 sec.\n",
      "Step(8290) loss: 5.6136 -- time: 4.7184 sec.\n",
      "Step(8300) loss: 5.5912 -- time: 4.6774 sec.\n",
      "Step(8310) loss: 5.2215 -- time: 4.5326 sec.\n",
      "Step(8320) loss: 5.5656 -- time: 4.6315 sec.\n",
      "Step(8330) loss: 5.1897 -- time: 4.5329 sec.\n",
      "Step(8340) loss: 5.7902 -- time: 4.5903 sec.\n",
      "Step(8350) loss: 5.6632 -- time: 4.6082 sec.\n",
      "Step(8360) loss: 5.5994 -- time: 4.5527 sec.\n",
      "Step(8370) loss: 5.5628 -- time: 4.5182 sec.\n",
      "Step(8380) loss: 5.5486 -- time: 4.6956 sec.\n",
      "Step(8390) loss: 5.7137 -- time: 4.4836 sec.\n",
      "Step(8400) loss: 5.2088 -- time: 4.5872 sec.\n",
      "Step(8410) loss: 5.1325 -- time: 4.6173 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 988.5847 - val_loss: 0.0000\n",
      "time: 84.0502 sec.\n",
      "time_left: 214.3281 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 48/200\n",
      "----------------------------------------------------------------------\n",
      "Step(8420) loss: 5.1674 -- time: 3.1543 sec.\n",
      "Step(8430) loss: 5.8769 -- time: 4.5334 sec.\n",
      "Step(8440) loss: 5.2824 -- time: 4.4453 sec.\n",
      "Step(8450) loss: 5.2667 -- time: 4.6002 sec.\n",
      "Step(8460) loss: 5.6792 -- time: 4.5381 sec.\n",
      "Step(8470) loss: 5.3794 -- time: 4.7033 sec.\n",
      "Step(8480) loss: 5.3017 -- time: 4.5474 sec.\n",
      "Step(8490) loss: 5.1174 -- time: 4.6417 sec.\n",
      "Step(8500) loss: 5.3621 -- time: 4.6471 sec.\n",
      "Step(8510) loss: 5.2693 -- time: 4.5945 sec.\n",
      "Step(8520) loss: 5.2966 -- time: 4.5350 sec.\n",
      "Step(8530) loss: 5.3972 -- time: 4.5771 sec.\n",
      "Step(8540) loss: 5.6731 -- time: 4.5274 sec.\n",
      "Step(8550) loss: 5.7663 -- time: 4.6018 sec.\n",
      "Step(8560) loss: 5.3989 -- time: 4.5420 sec.\n",
      "Step(8570) loss: 5.1814 -- time: 4.4876 sec.\n",
      "Step(8580) loss: 5.2559 -- time: 4.7749 sec.\n",
      "Step(8590) loss: 5.2690 -- time: 4.6725 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 989.3874 - val_loss: 0.0000\n",
      "time: 83.8942 sec.\n",
      "time_left: 212.5319 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 49/200\n",
      "----------------------------------------------------------------------\n",
      "Step(8600) loss: 5.5778 -- time: 3.6791 sec.\n",
      "Step(8610) loss: 4.8997 -- time: 4.4837 sec.\n",
      "Step(8620) loss: 6.0888 -- time: 4.6005 sec.\n",
      "Step(8630) loss: 5.5414 -- time: 4.5544 sec.\n",
      "Step(8640) loss: 5.6260 -- time: 4.5117 sec.\n",
      "Step(8650) loss: 5.3338 -- time: 4.5859 sec.\n",
      "Step(8660) loss: 5.4417 -- time: 4.6087 sec.\n",
      "Step(8670) loss: 5.4507 -- time: 4.5552 sec.\n",
      "Step(8680) loss: 5.5138 -- time: 4.5783 sec.\n",
      "Step(8690) loss: 5.7677 -- time: 4.5246 sec.\n",
      "Step(8700) loss: 5.5884 -- time: 4.5928 sec.\n",
      "Step(8710) loss: 5.2382 -- time: 4.5218 sec.\n",
      "Step(8720) loss: 5.1973 -- time: 4.6736 sec.\n",
      "Step(8730) loss: 5.1995 -- time: 4.5010 sec.\n",
      "Step(8740) loss: 5.5865 -- time: 4.7577 sec.\n",
      "Step(8750) loss: 5.7397 -- time: 4.6158 sec.\n",
      "Step(8760) loss: 5.5275 -- time: 4.5414 sec.\n",
      "Step(8770) loss: 5.7854 -- time: 4.5696 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 987.3195 - val_loss: 0.0000\n",
      "time: 83.7876 sec.\n",
      "time_left: 210.8655 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 50/200\n",
      "----------------------------------------------------------------------\n",
      "Step(8780) loss: 5.6164 -- time: 4.1555 sec.\n",
      "Step(8790) loss: 5.0698 -- time: 4.5917 sec.\n",
      "Step(8800) loss: 5.5732 -- time: 4.6151 sec.\n",
      "Step(8810) loss: 5.7541 -- time: 4.5458 sec.\n",
      "Step(8820) loss: 5.0745 -- time: 4.5561 sec.\n",
      "Step(8830) loss: 5.1934 -- time: 4.5410 sec.\n",
      "Step(8840) loss: 5.4107 -- time: 4.5962 sec.\n",
      "Step(8850) loss: 4.9305 -- time: 4.6213 sec.\n",
      "Step(8860) loss: 5.3194 -- time: 4.6240 sec.\n",
      "Step(8870) loss: 5.4002 -- time: 4.6518 sec.\n",
      "Step(8880) loss: 4.8757 -- time: 4.6212 sec.\n",
      "Step(8890) loss: 5.7704 -- time: 4.6119 sec.\n",
      "Step(8900) loss: 5.6401 -- time: 4.6360 sec.\n",
      "Step(8910) loss: 5.9431 -- time: 4.6471 sec.\n",
      "Step(8920) loss: 5.2233 -- time: 4.5989 sec.\n",
      "Step(8930) loss: 5.5718 -- time: 4.5529 sec.\n",
      "Step(8940) loss: 5.3362 -- time: 4.5353 sec.\n",
      "Step(8950) loss: 5.8098 -- time: 4.4155 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 978.8995 - val_loss: 1003.1167\n",
      "time: 121.1570 sec.\n",
      "time_left: 302.8925 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 51/200\n",
      "----------------------------------------------------------------------\n",
      "Step(8960) loss: 5.6882 -- time: 4.6777 sec.\n",
      "Step(8970) loss: 5.7154 -- time: 4.5556 sec.\n",
      "Step(8980) loss: 5.2492 -- time: 4.5264 sec.\n",
      "Step(8990) loss: 5.5927 -- time: 4.5779 sec.\n",
      "Step(9000) loss: 5.5575 -- time: 4.6841 sec.\n",
      "Step(9010) loss: 5.4406 -- time: 4.4649 sec.\n",
      "Step(9020) loss: 5.2319 -- time: 4.5273 sec.\n",
      "Step(9030) loss: 5.9715 -- time: 4.5370 sec.\n",
      "Step(9040) loss: 5.4458 -- time: 4.5457 sec.\n",
      "Step(9050) loss: 5.4966 -- time: 4.6104 sec.\n",
      "Step(9060) loss: 5.1637 -- time: 4.6215 sec.\n",
      "Step(9070) loss: 5.2585 -- time: 4.7692 sec.\n",
      "Step(9080) loss: 5.6202 -- time: 4.4963 sec.\n",
      "Step(9090) loss: 5.3682 -- time: 4.5724 sec.\n",
      "Step(9100) loss: 5.4660 -- time: 4.5485 sec.\n",
      "Step(9110) loss: 5.2872 -- time: 4.6063 sec.\n",
      "Step(9120) loss: 5.5058 -- time: 4.4152 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 979.1769 - val_loss: 0.0000\n",
      "time: 83.7405 sec.\n",
      "time_left: 207.9556 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 52/200\n",
      "----------------------------------------------------------------------\n",
      "Step(9130) loss: 5.3589 -- time: 0.3513 sec.\n",
      "Step(9140) loss: 5.5893 -- time: 4.4662 sec.\n",
      "Step(9150) loss: 5.6803 -- time: 4.4942 sec.\n",
      "Step(9160) loss: 5.5604 -- time: 4.3534 sec.\n",
      "Step(9170) loss: 5.8977 -- time: 4.5187 sec.\n",
      "Step(9180) loss: 5.3179 -- time: 4.6252 sec.\n",
      "Step(9190) loss: 5.0343 -- time: 4.5842 sec.\n",
      "Step(9200) loss: 5.3094 -- time: 4.6390 sec.\n",
      "Step(9210) loss: 5.5868 -- time: 4.4188 sec.\n",
      "Step(9220) loss: 5.9768 -- time: 4.4163 sec.\n",
      "Step(9230) loss: 5.8893 -- time: 4.5199 sec.\n",
      "Step(9240) loss: 5.9890 -- time: 4.3871 sec.\n",
      "Step(9250) loss: 5.4886 -- time: 4.4966 sec.\n",
      "Step(9260) loss: 5.3078 -- time: 4.5098 sec.\n",
      "Step(9270) loss: 5.7108 -- time: 4.3967 sec.\n",
      "Step(9280) loss: 5.5041 -- time: 4.4620 sec.\n",
      "Step(9290) loss: 4.8135 -- time: 4.4497 sec.\n",
      "Step(9300) loss: 5.4540 -- time: 4.4883 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 982.5380 - val_loss: 0.0000\n",
      "time: 81.8899 sec.\n",
      "time_left: 201.9950 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 53/200\n",
      "----------------------------------------------------------------------\n",
      "Step(9310) loss: 5.2223 -- time: 1.2299 sec.\n",
      "Step(9320) loss: 5.6623 -- time: 4.6777 sec.\n",
      "Step(9330) loss: 5.6386 -- time: 4.6356 sec.\n",
      "Step(9340) loss: 5.6380 -- time: 4.5670 sec.\n",
      "Step(9350) loss: 5.1137 -- time: 4.5697 sec.\n",
      "Step(9360) loss: 5.1997 -- time: 4.4838 sec.\n",
      "Step(9370) loss: 5.4973 -- time: 4.5804 sec.\n",
      "Step(9380) loss: 5.3351 -- time: 4.4985 sec.\n",
      "Step(9390) loss: 5.9923 -- time: 4.5549 sec.\n",
      "Step(9400) loss: 5.3224 -- time: 4.7503 sec.\n",
      "Step(9410) loss: 5.3509 -- time: 4.5064 sec.\n",
      "Step(9420) loss: 5.8448 -- time: 4.3627 sec.\n",
      "Step(9430) loss: 5.6243 -- time: 4.4180 sec.\n",
      "Step(9440) loss: 6.5380 -- time: 4.4570 sec.\n",
      "Step(9450) loss: 5.9130 -- time: 4.4409 sec.\n",
      "Step(9460) loss: 5.0164 -- time: 4.4749 sec.\n",
      "Step(9470) loss: 5.0334 -- time: 4.5622 sec.\n",
      "Step(9480) loss: 5.1609 -- time: 4.3395 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 978.7060 - val_loss: 0.0000\n",
      "time: 83.1388 sec.\n",
      "time_left: 203.6901 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 54/200\n",
      "----------------------------------------------------------------------\n",
      "Step(9490) loss: 5.4157 -- time: 1.3389 sec.\n",
      "Step(9500) loss: 5.2353 -- time: 4.5413 sec.\n",
      "Step(9510) loss: 5.0105 -- time: 4.5159 sec.\n",
      "Step(9520) loss: 5.3495 -- time: 4.4971 sec.\n",
      "Step(9530) loss: 5.2216 -- time: 4.3417 sec.\n",
      "Step(9540) loss: 5.1685 -- time: 4.3525 sec.\n",
      "Step(9550) loss: 5.3276 -- time: 4.5015 sec.\n",
      "Step(9560) loss: 5.2460 -- time: 4.5196 sec.\n",
      "Step(9570) loss: 5.5346 -- time: 4.5812 sec.\n",
      "Step(9580) loss: 5.6640 -- time: 4.4880 sec.\n",
      "Step(9590) loss: 5.4580 -- time: 4.5825 sec.\n",
      "Step(9600) loss: 5.6911 -- time: 4.3910 sec.\n",
      "Step(9610) loss: 5.9771 -- time: 4.5404 sec.\n",
      "Step(9620) loss: 4.8791 -- time: 4.5275 sec.\n",
      "Step(9630) loss: 5.5730 -- time: 4.4406 sec.\n",
      "Step(9640) loss: 5.2774 -- time: 4.5689 sec.\n",
      "Step(9650) loss: 5.3453 -- time: 4.5435 sec.\n",
      "Step(9660) loss: 5.4694 -- time: 4.5547 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 974.0604 - val_loss: 0.0000\n",
      "time: 82.3404 sec.\n",
      "time_left: 200.3616 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 55/200\n",
      "----------------------------------------------------------------------\n",
      "Step(9670) loss: 5.5094 -- time: 1.8042 sec.\n",
      "Step(9680) loss: 5.5733 -- time: 4.4343 sec.\n",
      "Step(9690) loss: 6.0127 -- time: 4.4737 sec.\n",
      "Step(9700) loss: 5.8621 -- time: 4.3724 sec.\n",
      "Step(9710) loss: 5.7598 -- time: 4.5403 sec.\n",
      "Step(9720) loss: 5.9545 -- time: 4.4491 sec.\n",
      "Step(9730) loss: 5.4786 -- time: 4.4375 sec.\n",
      "Step(9740) loss: 5.4404 -- time: 4.5477 sec.\n",
      "Step(9750) loss: 5.1081 -- time: 4.4878 sec.\n",
      "Step(9760) loss: 5.5834 -- time: 4.4823 sec.\n",
      "Step(9770) loss: 5.7760 -- time: 4.4439 sec.\n",
      "Step(9780) loss: 5.5487 -- time: 4.4650 sec.\n",
      "Step(9790) loss: 5.4007 -- time: 4.4460 sec.\n",
      "Step(9800) loss: 5.9208 -- time: 4.4855 sec.\n",
      "Step(9810) loss: 6.0226 -- time: 4.5584 sec.\n",
      "Step(9820) loss: 4.7893 -- time: 4.3918 sec.\n",
      "Step(9830) loss: 5.3844 -- time: 4.5402 sec.\n",
      "Step(9840) loss: 5.0352 -- time: 4.4441 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 982.8160 - val_loss: 0.0000\n",
      "time: 81.9116 sec.\n",
      "time_left: 197.9530 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 56/200\n",
      "----------------------------------------------------------------------\n",
      "Step(9850) loss: 5.2076 -- time: 2.2195 sec.\n",
      "Step(9860) loss: 5.3975 -- time: 4.3208 sec.\n",
      "Step(9870) loss: 5.3301 -- time: 4.4257 sec.\n",
      "Step(9880) loss: 5.5321 -- time: 4.4449 sec.\n",
      "Step(9890) loss: 5.4299 -- time: 4.3848 sec.\n",
      "Step(9900) loss: 5.6369 -- time: 4.4971 sec.\n",
      "Step(9910) loss: 5.0523 -- time: 4.3589 sec.\n",
      "Step(9920) loss: 5.8301 -- time: 4.4506 sec.\n",
      "Step(9930) loss: 4.7581 -- time: 4.4102 sec.\n",
      "Step(9940) loss: 5.4457 -- time: 4.5978 sec.\n",
      "Step(9950) loss: 5.5598 -- time: 4.5548 sec.\n",
      "Step(9960) loss: 5.6736 -- time: 4.5317 sec.\n",
      "Step(9970) loss: 5.0397 -- time: 4.4807 sec.\n",
      "Step(9980) loss: 5.2734 -- time: 4.6548 sec.\n",
      "Step(9990) loss: 5.3305 -- time: 4.5821 sec.\n",
      "Step(10000) loss: 5.2929 -- time: 4.5622 sec.\n",
      "Step(10010) loss: 5.7928 -- time: 4.4727 sec.\n",
      "Step(10020) loss: 5.3661 -- time: 4.4092 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 972.8855 - val_loss: 0.0000\n",
      "time: 81.9580 sec.\n",
      "time_left: 196.6993 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 57/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10030) loss: 6.0015 -- time: 2.6519 sec.\n",
      "Step(10040) loss: 6.2962 -- time: 4.4396 sec.\n",
      "Step(10050) loss: 4.8847 -- time: 4.5447 sec.\n",
      "Step(10060) loss: 4.8421 -- time: 4.4877 sec.\n",
      "Step(10070) loss: 5.1529 -- time: 4.4690 sec.\n",
      "Step(10080) loss: 5.0316 -- time: 4.3747 sec.\n",
      "Step(10090) loss: 5.3870 -- time: 4.5261 sec.\n",
      "Step(10100) loss: 5.2145 -- time: 4.4075 sec.\n",
      "Step(10110) loss: 5.0904 -- time: 4.4205 sec.\n",
      "Step(10120) loss: 5.3633 -- time: 4.5872 sec.\n",
      "Step(10130) loss: 5.6484 -- time: 4.6749 sec.\n",
      "Step(10140) loss: 5.5764 -- time: 4.3741 sec.\n",
      "Step(10150) loss: 5.1444 -- time: 4.4458 sec.\n",
      "Step(10160) loss: 5.6990 -- time: 4.5311 sec.\n",
      "Step(10170) loss: 5.4672 -- time: 4.4691 sec.\n",
      "Step(10180) loss: 5.2962 -- time: 4.6327 sec.\n",
      "Step(10190) loss: 4.9577 -- time: 4.4278 sec.\n",
      "Step(10200) loss: 5.0724 -- time: 4.4135 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 973.8593 - val_loss: 0.0000\n",
      "time: 82.0453 sec.\n",
      "time_left: 195.5412 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 58/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10210) loss: 5.1755 -- time: 3.1154 sec.\n",
      "Step(10220) loss: 5.3194 -- time: 4.5396 sec.\n",
      "Step(10230) loss: 5.8518 -- time: 4.5037 sec.\n",
      "Step(10240) loss: 5.4445 -- time: 4.6515 sec.\n",
      "Step(10250) loss: 5.5057 -- time: 4.5431 sec.\n",
      "Step(10260) loss: 4.8859 -- time: 4.5799 sec.\n",
      "Step(10270) loss: 5.5582 -- time: 4.4797 sec.\n",
      "Step(10280) loss: 5.2924 -- time: 4.5662 sec.\n",
      "Step(10290) loss: 5.5203 -- time: 4.3923 sec.\n",
      "Step(10300) loss: 4.8586 -- time: 4.5744 sec.\n",
      "Step(10310) loss: 4.7864 -- time: 4.4203 sec.\n",
      "Step(10320) loss: 5.3922 -- time: 4.4854 sec.\n",
      "Step(10330) loss: 5.0625 -- time: 4.4343 sec.\n",
      "Step(10340) loss: 5.8914 -- time: 4.4762 sec.\n",
      "Step(10350) loss: 4.9334 -- time: 4.5527 sec.\n",
      "Step(10360) loss: 5.1900 -- time: 4.5519 sec.\n",
      "Step(10370) loss: 6.3428 -- time: 4.5377 sec.\n",
      "Step(10380) loss: 5.3195 -- time: 4.4814 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 968.4520 - val_loss: 0.0000\n",
      "time: 82.5483 sec.\n",
      "time_left: 195.3642 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 59/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10390) loss: 5.6158 -- time: 3.5430 sec.\n",
      "Step(10400) loss: 5.3021 -- time: 4.4980 sec.\n",
      "Step(10410) loss: 5.8904 -- time: 4.3730 sec.\n",
      "Step(10420) loss: 4.9698 -- time: 4.6009 sec.\n",
      "Step(10430) loss: 5.7515 -- time: 4.5572 sec.\n",
      "Step(10440) loss: 5.8973 -- time: 4.5481 sec.\n",
      "Step(10450) loss: 6.0005 -- time: 4.5651 sec.\n",
      "Step(10460) loss: 5.5985 -- time: 4.5284 sec.\n",
      "Step(10470) loss: 5.3993 -- time: 4.3951 sec.\n",
      "Step(10480) loss: 5.5686 -- time: 4.4738 sec.\n",
      "Step(10490) loss: 6.0233 -- time: 4.3549 sec.\n",
      "Step(10500) loss: 5.2880 -- time: 4.5244 sec.\n",
      "Step(10510) loss: 5.4199 -- time: 4.4566 sec.\n",
      "Step(10520) loss: 5.3849 -- time: 4.4951 sec.\n",
      "Step(10530) loss: 5.0866 -- time: 4.6349 sec.\n",
      "Step(10540) loss: 5.4519 -- time: 4.4781 sec.\n",
      "Step(10550) loss: 5.3513 -- time: 4.5159 sec.\n",
      "Step(10560) loss: 5.0038 -- time: 4.5085 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 972.6746 - val_loss: 0.0000\n",
      "time: 82.2957 sec.\n",
      "time_left: 193.3949 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 60/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10570) loss: 5.1458 -- time: 3.9883 sec.\n",
      "Step(10580) loss: 5.3627 -- time: 4.4055 sec.\n",
      "Step(10590) loss: 5.3354 -- time: 4.6362 sec.\n",
      "Step(10600) loss: 5.7821 -- time: 4.5513 sec.\n",
      "Step(10610) loss: 5.5032 -- time: 4.6126 sec.\n",
      "Step(10620) loss: 5.8889 -- time: 4.4405 sec.\n",
      "Step(10630) loss: 5.1926 -- time: 4.5041 sec.\n",
      "Step(10640) loss: 4.9091 -- time: 4.5129 sec.\n",
      "Step(10650) loss: 5.3726 -- time: 4.3525 sec.\n",
      "Step(10660) loss: 4.9910 -- time: 4.5244 sec.\n",
      "Step(10670) loss: 5.6791 -- time: 4.6268 sec.\n",
      "Step(10680) loss: 5.3317 -- time: 4.4757 sec.\n",
      "Step(10690) loss: 5.0874 -- time: 4.6719 sec.\n",
      "Step(10700) loss: 5.2194 -- time: 4.5444 sec.\n",
      "Step(10710) loss: 5.4634 -- time: 4.4835 sec.\n",
      "Step(10720) loss: 5.3826 -- time: 4.4623 sec.\n",
      "Step(10730) loss: 5.1000 -- time: 4.5503 sec.\n",
      "Step(10740) loss: 6.9575 -- time: 4.3928 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 974.4060 - val_loss: 1022.4282\n",
      "time: 118.8080 sec.\n",
      "time_left: 277.2187 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 61/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10750) loss: 5.4298 -- time: 4.5102 sec.\n",
      "Step(10760) loss: 5.3436 -- time: 4.4347 sec.\n",
      "Step(10770) loss: 5.7771 -- time: 4.4383 sec.\n",
      "Step(10780) loss: 5.8887 -- time: 4.4969 sec.\n",
      "Step(10790) loss: 5.8706 -- time: 4.5185 sec.\n",
      "Step(10800) loss: 5.8681 -- time: 4.4152 sec.\n",
      "Step(10810) loss: 5.4447 -- time: 4.5503 sec.\n",
      "Step(10820) loss: 5.5908 -- time: 4.4568 sec.\n",
      "Step(10830) loss: 5.3270 -- time: 4.2958 sec.\n",
      "Step(10840) loss: 5.4086 -- time: 4.4877 sec.\n",
      "Step(10850) loss: 5.4432 -- time: 4.4711 sec.\n",
      "Step(10860) loss: 5.3873 -- time: 4.4854 sec.\n",
      "Step(10870) loss: 5.5209 -- time: 4.5396 sec.\n",
      "Step(10880) loss: 5.2832 -- time: 4.4807 sec.\n",
      "Step(10890) loss: 5.5351 -- time: 4.5227 sec.\n",
      "Step(10900) loss: 5.2178 -- time: 4.4482 sec.\n",
      "Step(10910) loss: 5.5784 -- time: 4.4566 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 967.3269 - val_loss: 0.0000\n",
      "time: 81.8256 sec.\n",
      "time_left: 189.5627 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 62/200\n",
      "----------------------------------------------------------------------\n",
      "Step(10920) loss: 5.9099 -- time: 0.4106 sec.\n",
      "Step(10930) loss: 5.8542 -- time: 4.4693 sec.\n",
      "Step(10940) loss: 4.8965 -- time: 4.5384 sec.\n",
      "Step(10950) loss: 5.0650 -- time: 4.3061 sec.\n",
      "Step(10960) loss: 5.5053 -- time: 4.4857 sec.\n",
      "Step(10970) loss: 5.0906 -- time: 4.6617 sec.\n",
      "Step(10980) loss: 5.0635 -- time: 4.4482 sec.\n",
      "Step(10990) loss: 5.2845 -- time: 4.5663 sec.\n",
      "Step(11000) loss: 5.5704 -- time: 4.4402 sec.\n",
      "Step(11010) loss: 5.4674 -- time: 4.4910 sec.\n",
      "Step(11020) loss: 5.0585 -- time: 4.5817 sec.\n",
      "Step(11030) loss: 5.1558 -- time: 4.4540 sec.\n",
      "Step(11040) loss: 5.2261 -- time: 4.4677 sec.\n",
      "Step(11050) loss: 5.2599 -- time: 4.4322 sec.\n",
      "Step(11060) loss: 5.6309 -- time: 4.4653 sec.\n",
      "Step(11070) loss: 5.3324 -- time: 4.5122 sec.\n",
      "Step(11080) loss: 5.4543 -- time: 4.3582 sec.\n",
      "Step(11090) loss: 5.2288 -- time: 4.6327 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 964.9399 - val_loss: 0.0000\n",
      "time: 82.3325 sec.\n",
      "time_left: 189.3648 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 63/200\n",
      "----------------------------------------------------------------------\n",
      "Step(11100) loss: 5.4252 -- time: 0.7233 sec.\n",
      "Step(11110) loss: 5.2499 -- time: 4.4954 sec.\n",
      "Step(11120) loss: 5.6294 -- time: 4.4938 sec.\n",
      "Step(11130) loss: 5.7692 -- time: 4.4510 sec.\n",
      "Step(11140) loss: 5.2304 -- time: 4.4664 sec.\n",
      "Step(11150) loss: 5.1249 -- time: 4.6701 sec.\n",
      "Step(11160) loss: 5.0753 -- time: 4.3552 sec.\n",
      "Step(11170) loss: 5.3748 -- time: 4.5417 sec.\n",
      "Step(11180) loss: 5.1097 -- time: 4.5497 sec.\n",
      "Step(11190) loss: 5.5250 -- time: 4.5345 sec.\n",
      "Step(11200) loss: 5.2485 -- time: 4.6085 sec.\n",
      "Step(11210) loss: 5.4712 -- time: 4.5689 sec.\n",
      "Step(11220) loss: 5.1986 -- time: 4.5020 sec.\n",
      "Step(11230) loss: 5.2235 -- time: 4.5094 sec.\n",
      "Step(11240) loss: 5.6028 -- time: 4.6507 sec.\n",
      "Step(11250) loss: 5.0465 -- time: 4.5508 sec.\n",
      "Step(11260) loss: 5.3855 -- time: 4.3968 sec.\n",
      "Step(11270) loss: 5.8084 -- time: 4.5515 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 963.2220 - val_loss: 0.0000\n",
      "time: 82.6867 sec.\n",
      "time_left: 188.8012 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 64/200\n",
      "----------------------------------------------------------------------\n",
      "Step(11280) loss: 5.2782 -- time: 1.2952 sec.\n",
      "Step(11290) loss: 5.4820 -- time: 4.3565 sec.\n",
      "Step(11300) loss: 5.7443 -- time: 4.3885 sec.\n",
      "Step(11310) loss: 5.6635 -- time: 4.7246 sec.\n",
      "Step(11320) loss: 5.2924 -- time: 4.4531 sec.\n",
      "Step(11330) loss: 5.1004 -- time: 4.5531 sec.\n",
      "Step(11340) loss: 5.3694 -- time: 4.4007 sec.\n",
      "Step(11350) loss: 5.7369 -- time: 4.4899 sec.\n",
      "Step(11360) loss: 5.5034 -- time: 4.5920 sec.\n",
      "Step(11370) loss: 5.4007 -- time: 4.6330 sec.\n",
      "Step(11380) loss: 5.5122 -- time: 4.4557 sec.\n",
      "Step(11390) loss: 5.0948 -- time: 4.4862 sec.\n",
      "Step(11400) loss: 5.2924 -- time: 4.4108 sec.\n",
      "Step(11410) loss: 5.0212 -- time: 4.3439 sec.\n",
      "Step(11420) loss: 5.0821 -- time: 4.3938 sec.\n",
      "Step(11430) loss: 5.3896 -- time: 4.5226 sec.\n",
      "Step(11440) loss: 5.7467 -- time: 4.6071 sec.\n",
      "Step(11450) loss: 5.0690 -- time: 4.3898 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 956.3903 - val_loss: 0.0000\n",
      "time: 81.9780 sec.\n",
      "time_left: 185.8168 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 65/200\n",
      "----------------------------------------------------------------------\n",
      "Step(11460) loss: 5.3880 -- time: 1.8622 sec.\n",
      "Step(11470) loss: 4.9771 -- time: 4.5057 sec.\n",
      "Step(11480) loss: 5.2834 -- time: 4.5122 sec.\n",
      "Step(11490) loss: 6.1120 -- time: 4.4314 sec.\n",
      "Step(11500) loss: 5.4048 -- time: 4.4761 sec.\n",
      "Step(11510) loss: 5.2277 -- time: 4.6676 sec.\n",
      "Step(11520) loss: 5.1337 -- time: 4.4281 sec.\n",
      "Step(11530) loss: 5.4407 -- time: 4.4512 sec.\n",
      "Step(11540) loss: 5.1653 -- time: 4.5791 sec.\n",
      "Step(11550) loss: 5.7924 -- time: 4.6345 sec.\n",
      "Step(11560) loss: 5.4362 -- time: 4.5782 sec.\n",
      "Step(11570) loss: 4.8728 -- time: 4.4612 sec.\n",
      "Step(11580) loss: 5.6343 -- time: 4.3279 sec.\n",
      "Step(11590) loss: 5.5869 -- time: 4.5015 sec.\n",
      "Step(11600) loss: 5.6343 -- time: 4.7012 sec.\n",
      "Step(11610) loss: 5.1781 -- time: 4.3464 sec.\n",
      "Step(11620) loss: 5.5016 -- time: 4.6110 sec.\n",
      "Step(11630) loss: 5.1352 -- time: 4.5105 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 960.7312 - val_loss: 0.0000\n",
      "time: 82.6433 sec.\n",
      "time_left: 185.9474 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 66/200\n",
      "----------------------------------------------------------------------\n",
      "Step(11640) loss: 5.2337 -- time: 2.1985 sec.\n",
      "Step(11650) loss: 5.2297 -- time: 4.6042 sec.\n",
      "Step(11660) loss: 5.6538 -- time: 4.4312 sec.\n",
      "Step(11670) loss: 5.1355 -- time: 4.5212 sec.\n",
      "Step(11680) loss: 5.4448 -- time: 4.3565 sec.\n",
      "Step(11690) loss: 5.3020 -- time: 4.4913 sec.\n",
      "Step(11700) loss: 5.6075 -- time: 4.5526 sec.\n",
      "Step(11710) loss: 5.7889 -- time: 4.5333 sec.\n",
      "Step(11720) loss: 5.3562 -- time: 4.4025 sec.\n",
      "Step(11730) loss: 5.5434 -- time: 4.4616 sec.\n",
      "Step(11740) loss: 5.5642 -- time: 4.5445 sec.\n",
      "Step(11750) loss: 5.1485 -- time: 4.4233 sec.\n",
      "Step(11760) loss: 5.8690 -- time: 4.6494 sec.\n",
      "Step(11770) loss: 5.3169 -- time: 4.5798 sec.\n",
      "Step(11780) loss: 4.8742 -- time: 4.6007 sec.\n",
      "Step(11790) loss: 5.6615 -- time: 4.5478 sec.\n",
      "Step(11800) loss: 5.2248 -- time: 4.5149 sec.\n",
      "Step(11810) loss: 5.4737 -- time: 4.5224 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 959.4677 - val_loss: 0.0000\n",
      "time: 82.5286 sec.\n",
      "time_left: 184.3140 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 67/200\n",
      "----------------------------------------------------------------------\n",
      "Step(11820) loss: 5.2406 -- time: 2.7344 sec.\n",
      "Step(11830) loss: 4.9652 -- time: 4.3597 sec.\n",
      "Step(11840) loss: 5.3423 -- time: 4.4580 sec.\n",
      "Step(11850) loss: 5.3067 -- time: 4.4261 sec.\n",
      "Step(11860) loss: 5.4577 -- time: 4.5247 sec.\n",
      "Step(11870) loss: 5.8229 -- time: 4.4853 sec.\n",
      "Step(11880) loss: 5.7824 -- time: 4.4471 sec.\n",
      "Step(11890) loss: 5.5335 -- time: 4.5200 sec.\n",
      "Step(11900) loss: 5.2904 -- time: 4.6612 sec.\n",
      "Step(11910) loss: 5.1843 -- time: 4.5531 sec.\n",
      "Step(11920) loss: 5.7451 -- time: 4.4697 sec.\n",
      "Step(11930) loss: 5.1952 -- time: 4.6979 sec.\n",
      "Step(11940) loss: 5.5960 -- time: 4.7082 sec.\n",
      "Step(11950) loss: 5.4698 -- time: 4.4500 sec.\n",
      "Step(11960) loss: 5.4545 -- time: 4.4297 sec.\n",
      "Step(11970) loss: 4.8563 -- time: 4.3826 sec.\n",
      "Step(11980) loss: 5.3835 -- time: 4.5729 sec.\n",
      "Step(11990) loss: 5.0572 -- time: 4.5890 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.8399 - val_loss: 0.0000\n",
      "time: 82.6730 sec.\n",
      "time_left: 183.2584 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 68/200\n",
      "----------------------------------------------------------------------\n",
      "Step(12000) loss: 5.5206 -- time: 3.0722 sec.\n",
      "Step(12010) loss: 5.1554 -- time: 4.4589 sec.\n",
      "Step(12020) loss: 5.5730 -- time: 4.4723 sec.\n",
      "Step(12030) loss: 5.6036 -- time: 4.5111 sec.\n",
      "Step(12040) loss: 5.0154 -- time: 4.5949 sec.\n",
      "Step(12050) loss: 5.1759 -- time: 4.4636 sec.\n",
      "Step(12060) loss: 5.1130 -- time: 4.4233 sec.\n",
      "Step(12070) loss: 5.5211 -- time: 4.5092 sec.\n",
      "Step(12080) loss: 4.9564 -- time: 4.5155 sec.\n",
      "Step(12090) loss: 5.2478 -- time: 4.5166 sec.\n",
      "Step(12100) loss: 4.9422 -- time: 4.4746 sec.\n",
      "Step(12110) loss: 5.0043 -- time: 4.4553 sec.\n",
      "Step(12120) loss: 5.3634 -- time: 4.5237 sec.\n",
      "Step(12130) loss: 5.6227 -- time: 4.4392 sec.\n",
      "Step(12140) loss: 5.1058 -- time: 4.5097 sec.\n",
      "Step(12150) loss: 5.2138 -- time: 4.5871 sec.\n",
      "Step(12160) loss: 5.8457 -- time: 4.5157 sec.\n",
      "Step(12170) loss: 6.2159 -- time: 4.5009 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 965.7270 - val_loss: 0.0000\n",
      "time: 82.2144 sec.\n",
      "time_left: 180.8717 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 69/200\n",
      "----------------------------------------------------------------------\n",
      "Step(12180) loss: 5.5291 -- time: 3.5234 sec.\n",
      "Step(12190) loss: 5.6935 -- time: 4.4107 sec.\n",
      "Step(12200) loss: 5.6763 -- time: 4.4612 sec.\n",
      "Step(12210) loss: 5.4463 -- time: 4.4803 sec.\n",
      "Step(12220) loss: 5.3360 -- time: 4.3684 sec.\n",
      "Step(12230) loss: 5.4725 -- time: 4.4152 sec.\n",
      "Step(12240) loss: 5.1442 -- time: 4.4890 sec.\n",
      "Step(12250) loss: 5.4662 -- time: 4.3890 sec.\n",
      "Step(12260) loss: 5.7428 -- time: 4.4293 sec.\n",
      "Step(12270) loss: 5.4334 -- time: 4.4691 sec.\n",
      "Step(12280) loss: 5.4197 -- time: 4.4789 sec.\n",
      "Step(12290) loss: 5.4521 -- time: 4.5479 sec.\n",
      "Step(12300) loss: 5.6563 -- time: 4.4855 sec.\n",
      "Step(12310) loss: 5.0150 -- time: 4.6329 sec.\n",
      "Step(12320) loss: 5.0008 -- time: 4.4615 sec.\n",
      "Step(12330) loss: 5.5302 -- time: 4.4419 sec.\n",
      "Step(12340) loss: 4.6745 -- time: 4.5386 sec.\n",
      "Step(12350) loss: 4.8351 -- time: 4.5186 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 963.3262 - val_loss: 0.0000\n",
      "time: 81.7802 sec.\n",
      "time_left: 178.5534 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 70/200\n",
      "----------------------------------------------------------------------\n",
      "Step(12360) loss: 5.4924 -- time: 3.9321 sec.\n",
      "Step(12370) loss: 5.3048 -- time: 4.4386 sec.\n",
      "Step(12380) loss: 5.2376 -- time: 4.4689 sec.\n",
      "Step(12390) loss: 5.9230 -- time: 4.5576 sec.\n",
      "Step(12400) loss: 5.5501 -- time: 4.4036 sec.\n",
      "Step(12410) loss: 5.6281 -- time: 4.5415 sec.\n",
      "Step(12420) loss: 5.9800 -- time: 4.5420 sec.\n",
      "Step(12430) loss: 5.1084 -- time: 4.4368 sec.\n",
      "Step(12440) loss: 6.2793 -- time: 4.5379 sec.\n",
      "Step(12450) loss: 5.6428 -- time: 4.4630 sec.\n",
      "Step(12460) loss: 5.1850 -- time: 4.5015 sec.\n",
      "Step(12470) loss: 5.2247 -- time: 4.5158 sec.\n",
      "Step(12480) loss: 5.4261 -- time: 4.4938 sec.\n",
      "Step(12490) loss: 6.2497 -- time: 4.5585 sec.\n",
      "Step(12500) loss: 6.1041 -- time: 4.5460 sec.\n",
      "Step(12510) loss: 5.2891 -- time: 4.5806 sec.\n",
      "Step(12520) loss: 5.1906 -- time: 4.5295 sec.\n",
      "Step(12530) loss: 4.8343 -- time: 4.3596 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 976.1883 - val_loss: 978.5123\n",
      "time: 119.0535 sec.\n",
      "time_left: 257.9493 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 71/200\n",
      "----------------------------------------------------------------------\n",
      "Step(12540) loss: 4.9759 -- time: 4.7463 sec.\n",
      "Step(12550) loss: 5.1575 -- time: 4.8608 sec.\n",
      "Step(12560) loss: 5.3208 -- time: 4.6998 sec.\n",
      "Step(12570) loss: 4.8967 -- time: 4.6623 sec.\n",
      "Step(12580) loss: 5.1363 -- time: 4.6996 sec.\n",
      "Step(12590) loss: 5.4810 -- time: 4.7220 sec.\n",
      "Step(12600) loss: 5.3180 -- time: 4.7291 sec.\n",
      "Step(12610) loss: 5.6935 -- time: 4.8265 sec.\n",
      "Step(12620) loss: 5.0765 -- time: 4.7523 sec.\n",
      "Step(12630) loss: 5.5050 -- time: 4.6853 sec.\n",
      "Step(12640) loss: 5.9153 -- time: 4.6524 sec.\n",
      "Step(12650) loss: 5.6499 -- time: 4.6554 sec.\n",
      "Step(12660) loss: 5.2122 -- time: 4.7114 sec.\n",
      "Step(12670) loss: 5.3164 -- time: 4.5887 sec.\n",
      "Step(12680) loss: 5.1123 -- time: 4.7388 sec.\n",
      "Step(12690) loss: 5.3546 -- time: 4.6658 sec.\n",
      "Step(12700) loss: 5.3951 -- time: 4.6664 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 957.0306 - val_loss: 0.0000\n",
      "time: 86.0590 sec.\n",
      "time_left: 185.0268 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 72/200\n",
      "----------------------------------------------------------------------\n",
      "Step(12710) loss: 5.5213 -- time: 0.3596 sec.\n",
      "Step(12720) loss: 5.4852 -- time: 4.7258 sec.\n",
      "Step(12730) loss: 5.7707 -- time: 4.8229 sec.\n",
      "Step(12740) loss: 5.5711 -- time: 4.7926 sec.\n",
      "Step(12750) loss: 5.2428 -- time: 4.5115 sec.\n",
      "Step(12760) loss: 5.4202 -- time: 4.7931 sec.\n",
      "Step(12770) loss: 5.3677 -- time: 4.7323 sec.\n",
      "Step(12780) loss: 4.9795 -- time: 4.7508 sec.\n",
      "Step(12790) loss: 5.7124 -- time: 4.6637 sec.\n",
      "Step(12800) loss: 5.5934 -- time: 4.6909 sec.\n",
      "Step(12810) loss: 5.3800 -- time: 4.6843 sec.\n",
      "Step(12820) loss: 4.8315 -- time: 4.7435 sec.\n",
      "Step(12830) loss: 5.3599 -- time: 4.7158 sec.\n",
      "Step(12840) loss: 5.2933 -- time: 4.7264 sec.\n",
      "Step(12850) loss: 5.1765 -- time: 4.6842 sec.\n",
      "Step(12860) loss: 4.4168 -- time: 4.6849 sec.\n",
      "Step(12870) loss: 5.1125 -- time: 4.6176 sec.\n",
      "Step(12880) loss: 5.3992 -- time: 4.5667 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.4687 - val_loss: 0.0000\n",
      "time: 85.8758 sec.\n",
      "time_left: 183.2018 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 73/200\n",
      "----------------------------------------------------------------------\n",
      "Step(12890) loss: 5.2309 -- time: 0.8603 sec.\n",
      "Step(12900) loss: 4.9800 -- time: 4.4406 sec.\n",
      "Step(12910) loss: 5.2125 -- time: 4.5996 sec.\n",
      "Step(12920) loss: 4.7609 -- time: 4.4519 sec.\n",
      "Step(12930) loss: 5.7100 -- time: 4.4397 sec.\n",
      "Step(12940) loss: 5.3834 -- time: 4.5673 sec.\n",
      "Step(12950) loss: 5.1180 -- time: 4.6017 sec.\n",
      "Step(12960) loss: 5.0003 -- time: 4.5226 sec.\n",
      "Step(12970) loss: 5.1303 -- time: 4.4592 sec.\n",
      "Step(12980) loss: 5.1064 -- time: 4.5673 sec.\n",
      "Step(12990) loss: 4.7096 -- time: 4.5307 sec.\n",
      "Step(13000) loss: 5.4948 -- time: 4.5587 sec.\n",
      "Step(13010) loss: 5.2252 -- time: 4.5721 sec.\n",
      "Step(13020) loss: 6.0362 -- time: 4.6202 sec.\n",
      "Step(13030) loss: 5.3287 -- time: 4.5134 sec.\n",
      "Step(13040) loss: 5.1119 -- time: 4.6378 sec.\n",
      "Step(13050) loss: 5.2425 -- time: 4.5266 sec.\n",
      "Step(13060) loss: 5.2892 -- time: 4.5930 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 956.8536 - val_loss: 0.0000\n",
      "time: 83.1406 sec.\n",
      "time_left: 175.9810 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 74/200\n",
      "----------------------------------------------------------------------\n",
      "Step(13070) loss: 5.2857 -- time: 1.2572 sec.\n",
      "Step(13080) loss: 5.2337 -- time: 4.5584 sec.\n",
      "Step(13090) loss: 4.7438 -- time: 4.3940 sec.\n",
      "Step(13100) loss: 5.2914 -- time: 4.6164 sec.\n",
      "Step(13110) loss: 5.5592 -- time: 4.5639 sec.\n",
      "Step(13120) loss: 5.1388 -- time: 4.5173 sec.\n",
      "Step(13130) loss: 5.2966 -- time: 4.4424 sec.\n",
      "Step(13140) loss: 5.3972 -- time: 4.7153 sec.\n",
      "Step(13150) loss: 5.1817 -- time: 4.6432 sec.\n",
      "Step(13160) loss: 5.0983 -- time: 4.4183 sec.\n",
      "Step(13170) loss: 5.2528 -- time: 4.4963 sec.\n",
      "Step(13180) loss: 4.5570 -- time: 4.5375 sec.\n",
      "Step(13190) loss: 5.4640 -- time: 4.4529 sec.\n",
      "Step(13200) loss: 5.0893 -- time: 4.5197 sec.\n",
      "Step(13210) loss: 5.3828 -- time: 4.5947 sec.\n",
      "Step(13220) loss: 4.9299 -- time: 4.5225 sec.\n",
      "Step(13230) loss: 5.7755 -- time: 4.5430 sec.\n",
      "Step(13240) loss: 5.3971 -- time: 4.7378 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 951.8271 - val_loss: 0.0000\n",
      "time: 83.1631 sec.\n",
      "time_left: 174.6425 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 75/200\n",
      "----------------------------------------------------------------------\n",
      "Step(13250) loss: 5.3346 -- time: 1.7788 sec.\n",
      "Step(13260) loss: 5.4571 -- time: 4.5715 sec.\n",
      "Step(13270) loss: 5.1454 -- time: 4.7083 sec.\n",
      "Step(13280) loss: 5.4566 -- time: 4.5470 sec.\n",
      "Step(13290) loss: 5.8527 -- time: 4.5730 sec.\n",
      "Step(13300) loss: 5.3528 -- time: 4.4602 sec.\n",
      "Step(13310) loss: 4.7596 -- time: 4.5925 sec.\n",
      "Step(13320) loss: 5.5129 -- time: 4.5544 sec.\n",
      "Step(13330) loss: 5.7321 -- time: 4.6281 sec.\n",
      "Step(13340) loss: 5.4014 -- time: 4.5469 sec.\n",
      "Step(13350) loss: 5.4319 -- time: 4.5297 sec.\n",
      "Step(13360) loss: 5.4482 -- time: 4.6010 sec.\n",
      "Step(13370) loss: 4.6082 -- time: 4.5102 sec.\n",
      "Step(13380) loss: 5.3716 -- time: 4.5700 sec.\n",
      "Step(13390) loss: 5.5426 -- time: 4.5885 sec.\n",
      "Step(13400) loss: 4.8630 -- time: 4.6423 sec.\n",
      "Step(13410) loss: 5.4344 -- time: 4.5207 sec.\n",
      "Step(13420) loss: 5.5267 -- time: 4.5314 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.6632 - val_loss: 0.0000\n",
      "time: 83.6605 sec.\n",
      "time_left: 174.2928 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 76/200\n",
      "----------------------------------------------------------------------\n",
      "Step(13430) loss: 5.3017 -- time: 2.2440 sec.\n",
      "Step(13440) loss: 4.8412 -- time: 4.6266 sec.\n",
      "Step(13450) loss: 4.8763 -- time: 4.6035 sec.\n",
      "Step(13460) loss: 5.5553 -- time: 4.4650 sec.\n",
      "Step(13470) loss: 5.3655 -- time: 4.5296 sec.\n",
      "Step(13480) loss: 4.9893 -- time: 4.5836 sec.\n",
      "Step(13490) loss: 5.4141 -- time: 4.6139 sec.\n",
      "Step(13500) loss: 5.0830 -- time: 4.4985 sec.\n",
      "Step(13510) loss: 5.0922 -- time: 4.4644 sec.\n",
      "Step(13520) loss: 5.1751 -- time: 4.5995 sec.\n",
      "Step(13530) loss: 5.2166 -- time: 4.5738 sec.\n",
      "Step(13540) loss: 5.9252 -- time: 4.5729 sec.\n",
      "Step(13550) loss: 5.2328 -- time: 4.4575 sec.\n",
      "Step(13560) loss: 5.1825 -- time: 4.6509 sec.\n",
      "Step(13570) loss: 5.4684 -- time: 4.5486 sec.\n",
      "Step(13580) loss: 5.1219 -- time: 4.5246 sec.\n",
      "Step(13590) loss: 4.6490 -- time: 4.6499 sec.\n",
      "Step(13600) loss: 5.9600 -- time: 4.5644 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 959.9997 - val_loss: 0.0000\n",
      "time: 83.4156 sec.\n",
      "time_left: 172.3922 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 77/200\n",
      "----------------------------------------------------------------------\n",
      "Step(13610) loss: 5.3892 -- time: 2.6913 sec.\n",
      "Step(13620) loss: 5.1935 -- time: 4.5209 sec.\n",
      "Step(13630) loss: 5.7496 -- time: 4.6262 sec.\n",
      "Step(13640) loss: 5.0631 -- time: 4.6547 sec.\n",
      "Step(13650) loss: 5.6313 -- time: 4.4801 sec.\n",
      "Step(13660) loss: 5.4470 -- time: 4.6420 sec.\n",
      "Step(13670) loss: 5.4043 -- time: 4.4910 sec.\n",
      "Step(13680) loss: 5.6618 -- time: 4.5520 sec.\n",
      "Step(13690) loss: 4.9971 -- time: 4.5512 sec.\n",
      "Step(13700) loss: 5.7376 -- time: 4.7382 sec.\n",
      "Step(13710) loss: 5.4458 -- time: 4.5826 sec.\n",
      "Step(13720) loss: 5.1767 -- time: 4.6077 sec.\n",
      "Step(13730) loss: 5.5845 -- time: 4.4198 sec.\n",
      "Step(13740) loss: 5.4102 -- time: 4.7332 sec.\n",
      "Step(13750) loss: 5.4321 -- time: 4.5647 sec.\n",
      "Step(13760) loss: 5.0948 -- time: 4.5340 sec.\n",
      "Step(13770) loss: 5.4580 -- time: 4.7655 sec.\n",
      "Step(13780) loss: 5.2749 -- time: 4.5983 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.9508 - val_loss: 0.0000\n",
      "time: 84.0006 sec.\n",
      "time_left: 172.2012 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 78/200\n",
      "----------------------------------------------------------------------\n",
      "Step(13790) loss: 5.3431 -- time: 3.1167 sec.\n",
      "Step(13800) loss: 5.6567 -- time: 4.4620 sec.\n",
      "Step(13810) loss: 5.6910 -- time: 4.6415 sec.\n",
      "Step(13820) loss: 4.8198 -- time: 4.5782 sec.\n",
      "Step(13830) loss: 5.2194 -- time: 4.6038 sec.\n",
      "Step(13840) loss: 4.9801 -- time: 4.5437 sec.\n",
      "Step(13850) loss: 5.6401 -- time: 4.6597 sec.\n",
      "Step(13860) loss: 4.6583 -- time: 4.6231 sec.\n",
      "Step(13870) loss: 5.2344 -- time: 4.7349 sec.\n",
      "Step(13880) loss: 5.2471 -- time: 4.4726 sec.\n",
      "Step(13890) loss: 4.9162 -- time: 4.6402 sec.\n",
      "Step(13900) loss: 5.5292 -- time: 4.4575 sec.\n",
      "Step(13910) loss: 5.3908 -- time: 4.6115 sec.\n",
      "Step(13920) loss: 5.4918 -- time: 4.5049 sec.\n",
      "Step(13930) loss: 5.3831 -- time: 4.6155 sec.\n",
      "Step(13940) loss: 5.4725 -- time: 4.6713 sec.\n",
      "Step(13950) loss: 5.3217 -- time: 4.6014 sec.\n",
      "Step(13960) loss: 5.0867 -- time: 4.5228 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 961.4453 - val_loss: 0.0000\n",
      "time: 83.8669 sec.\n",
      "time_left: 170.5294 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 79/200\n",
      "----------------------------------------------------------------------\n",
      "Step(13970) loss: 5.2593 -- time: 3.5173 sec.\n",
      "Step(13980) loss: 5.3045 -- time: 4.5321 sec.\n",
      "Step(13990) loss: 5.4971 -- time: 4.4904 sec.\n",
      "Step(14000) loss: 5.7391 -- time: 4.6041 sec.\n",
      "Step(14010) loss: 4.5479 -- time: 4.4639 sec.\n",
      "Step(14020) loss: 5.3458 -- time: 4.6287 sec.\n",
      "Step(14030) loss: 5.3821 -- time: 4.3774 sec.\n",
      "Step(14040) loss: 5.4752 -- time: 4.5961 sec.\n",
      "Step(14050) loss: 5.0881 -- time: 4.5577 sec.\n",
      "Step(14060) loss: 4.5284 -- time: 4.7592 sec.\n",
      "Step(14070) loss: 5.7581 -- time: 4.5465 sec.\n",
      "Step(14080) loss: 5.2879 -- time: 4.5155 sec.\n",
      "Step(14090) loss: 4.9782 -- time: 4.4897 sec.\n",
      "Step(14100) loss: 5.5731 -- time: 4.5823 sec.\n",
      "Step(14110) loss: 5.0436 -- time: 4.6892 sec.\n",
      "Step(14120) loss: 5.7215 -- time: 4.6574 sec.\n",
      "Step(14130) loss: 5.4954 -- time: 4.6336 sec.\n",
      "Step(14140) loss: 5.2091 -- time: 4.7113 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 949.2925 - val_loss: 0.0000\n",
      "time: 83.6360 sec.\n",
      "time_left: 168.6659 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 80/200\n",
      "----------------------------------------------------------------------\n",
      "Step(14150) loss: 5.6519 -- time: 4.1586 sec.\n",
      "Step(14160) loss: 5.6114 -- time: 4.4172 sec.\n",
      "Step(14170) loss: 5.5459 -- time: 4.5916 sec.\n",
      "Step(14180) loss: 5.0693 -- time: 4.7191 sec.\n",
      "Step(14190) loss: 4.5643 -- time: 4.5911 sec.\n",
      "Step(14200) loss: 4.9324 -- time: 4.5272 sec.\n",
      "Step(14210) loss: 4.9275 -- time: 4.5246 sec.\n",
      "Step(14220) loss: 5.2639 -- time: 4.6312 sec.\n",
      "Step(14230) loss: 5.3463 -- time: 4.3663 sec.\n",
      "Step(14240) loss: 5.0140 -- time: 4.4352 sec.\n",
      "Step(14250) loss: 5.1814 -- time: 4.5885 sec.\n",
      "Step(14260) loss: 5.7808 -- time: 4.5391 sec.\n",
      "Step(14270) loss: 5.2827 -- time: 4.5158 sec.\n",
      "Step(14280) loss: 5.0807 -- time: 4.4949 sec.\n",
      "Step(14290) loss: 5.1501 -- time: 4.7341 sec.\n",
      "Step(14300) loss: 5.0422 -- time: 4.4067 sec.\n",
      "Step(14310) loss: 5.5955 -- time: 4.6551 sec.\n",
      "Step(14320) loss: 5.4374 -- time: 4.5091 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 946.6306 - val_loss: 973.6924\n",
      "time: 119.7719 sec.\n",
      "time_left: 239.5438 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 81/200\n",
      "----------------------------------------------------------------------\n",
      "Step(14330) loss: 5.4521 -- time: 4.8112 sec.\n",
      "Step(14340) loss: 5.7497 -- time: 4.4472 sec.\n",
      "Step(14350) loss: 5.4784 -- time: 4.6038 sec.\n",
      "Step(14360) loss: 5.0824 -- time: 4.5697 sec.\n",
      "Step(14370) loss: 5.3135 -- time: 4.4887 sec.\n",
      "Step(14380) loss: 5.1710 -- time: 4.6267 sec.\n",
      "Step(14390) loss: 5.0992 -- time: 4.5267 sec.\n",
      "Step(14400) loss: 5.4658 -- time: 4.4145 sec.\n",
      "Step(14410) loss: 4.9335 -- time: 4.5811 sec.\n",
      "Step(14420) loss: 5.2187 -- time: 4.5326 sec.\n",
      "Step(14430) loss: 5.1120 -- time: 4.5100 sec.\n",
      "Step(14440) loss: 5.4422 -- time: 4.5888 sec.\n",
      "Step(14450) loss: 5.5306 -- time: 4.5940 sec.\n",
      "Step(14460) loss: 4.8631 -- time: 4.6660 sec.\n",
      "Step(14470) loss: 5.3492 -- time: 4.6290 sec.\n",
      "Step(14480) loss: 5.0862 -- time: 4.6102 sec.\n",
      "Step(14490) loss: 5.0159 -- time: 4.4777 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 952.0357 - val_loss: 0.0000\n",
      "time: 83.7587 sec.\n",
      "time_left: 166.1214 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 82/200\n",
      "----------------------------------------------------------------------\n",
      "Step(14500) loss: 4.8287 -- time: 0.3476 sec.\n",
      "Step(14510) loss: 4.7959 -- time: 4.5813 sec.\n",
      "Step(14520) loss: 4.9117 -- time: 4.5263 sec.\n",
      "Step(14530) loss: 5.4665 -- time: 4.4807 sec.\n",
      "Step(14540) loss: 4.9619 -- time: 4.6832 sec.\n",
      "Step(14550) loss: 5.5328 -- time: 4.7521 sec.\n",
      "Step(14560) loss: 5.7659 -- time: 4.6458 sec.\n",
      "Step(14570) loss: 5.1496 -- time: 4.5884 sec.\n",
      "Step(14580) loss: 5.2940 -- time: 4.6928 sec.\n",
      "Step(14590) loss: 4.8224 -- time: 4.4501 sec.\n",
      "Step(14600) loss: 5.0061 -- time: 4.4931 sec.\n",
      "Step(14610) loss: 5.5915 -- time: 4.6062 sec.\n",
      "Step(14620) loss: 4.7948 -- time: 4.5622 sec.\n",
      "Step(14630) loss: 5.3881 -- time: 4.6826 sec.\n",
      "Step(14640) loss: 5.0488 -- time: 4.5400 sec.\n",
      "Step(14650) loss: 5.9538 -- time: 4.5804 sec.\n",
      "Step(14660) loss: 5.2835 -- time: 4.5411 sec.\n",
      "Step(14670) loss: 5.0434 -- time: 4.5117 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 957.7529 - val_loss: 0.0000\n",
      "time: 83.7740 sec.\n",
      "time_left: 164.7556 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 83/200\n",
      "----------------------------------------------------------------------\n",
      "Step(14680) loss: 5.1526 -- time: 0.8435 sec.\n",
      "Step(14690) loss: 4.7892 -- time: 4.5884 sec.\n",
      "Step(14700) loss: 4.9717 -- time: 4.5688 sec.\n",
      "Step(14710) loss: 5.0418 -- time: 4.5334 sec.\n",
      "Step(14720) loss: 5.1534 -- time: 4.6197 sec.\n",
      "Step(14730) loss: 5.3298 -- time: 4.6330 sec.\n",
      "Step(14740) loss: 5.3295 -- time: 4.7177 sec.\n",
      "Step(14750) loss: 5.0952 -- time: 4.5945 sec.\n",
      "Step(14760) loss: 5.0865 -- time: 4.6332 sec.\n",
      "Step(14770) loss: 4.6817 -- time: 4.4456 sec.\n",
      "Step(14780) loss: 5.0887 -- time: 4.6283 sec.\n",
      "Step(14790) loss: 4.8365 -- time: 4.6043 sec.\n",
      "Step(14800) loss: 5.1268 -- time: 4.4058 sec.\n",
      "Step(14810) loss: 5.7017 -- time: 4.5957 sec.\n",
      "Step(14820) loss: 5.6535 -- time: 4.5460 sec.\n",
      "Step(14830) loss: 4.7498 -- time: 4.5459 sec.\n",
      "Step(14840) loss: 5.5827 -- time: 4.6105 sec.\n",
      "Step(14850) loss: 5.0996 -- time: 4.4851 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 950.9381 - val_loss: 0.0000\n",
      "time: 83.6846 sec.\n",
      "time_left: 163.1850 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 84/200\n",
      "----------------------------------------------------------------------\n",
      "Step(14860) loss: 5.2401 -- time: 1.2732 sec.\n",
      "Step(14870) loss: 5.6065 -- time: 4.5206 sec.\n",
      "Step(14880) loss: 4.8202 -- time: 4.4736 sec.\n",
      "Step(14890) loss: 5.4776 -- time: 4.5892 sec.\n",
      "Step(14900) loss: 5.1684 -- time: 4.5306 sec.\n",
      "Step(14910) loss: 5.2492 -- time: 4.6057 sec.\n",
      "Step(14920) loss: 5.2973 -- time: 4.5672 sec.\n",
      "Step(14930) loss: 5.6356 -- time: 4.5598 sec.\n",
      "Step(14940) loss: 6.1377 -- time: 4.6095 sec.\n",
      "Step(14950) loss: 5.4626 -- time: 4.6266 sec.\n",
      "Step(14960) loss: 5.4009 -- time: 4.6552 sec.\n",
      "Step(14970) loss: 4.9921 -- time: 4.6464 sec.\n",
      "Step(14980) loss: 5.3040 -- time: 4.5831 sec.\n",
      "Step(14990) loss: 5.3044 -- time: 4.5393 sec.\n",
      "Step(15000) loss: 5.4585 -- time: 4.5033 sec.\n",
      "Step(15010) loss: 5.2480 -- time: 4.5488 sec.\n",
      "Step(15020) loss: 4.9316 -- time: 4.6181 sec.\n",
      "Step(15030) loss: 4.9328 -- time: 4.5626 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 944.7524 - val_loss: 0.0000\n",
      "time: 83.6030 sec.\n",
      "time_left: 161.6324 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 85/200\n",
      "----------------------------------------------------------------------\n",
      "Step(15040) loss: 5.3107 -- time: 1.7880 sec.\n",
      "Step(15050) loss: 4.8973 -- time: 4.4892 sec.\n",
      "Step(15060) loss: 5.2460 -- time: 4.5987 sec.\n",
      "Step(15070) loss: 5.3463 -- time: 4.4800 sec.\n",
      "Step(15080) loss: 6.0196 -- time: 4.6145 sec.\n",
      "Step(15090) loss: 5.6130 -- time: 4.5615 sec.\n",
      "Step(15100) loss: 5.0908 -- time: 4.5402 sec.\n",
      "Step(15110) loss: 5.7181 -- time: 4.3854 sec.\n",
      "Step(15120) loss: 4.7914 -- time: 4.5692 sec.\n",
      "Step(15130) loss: 5.8126 -- time: 4.5690 sec.\n",
      "Step(15140) loss: 5.3338 -- time: 4.6215 sec.\n",
      "Step(15150) loss: 5.8202 -- time: 4.3786 sec.\n",
      "Step(15160) loss: 5.5086 -- time: 4.5493 sec.\n",
      "Step(15170) loss: 4.9970 -- time: 4.5824 sec.\n",
      "Step(15180) loss: 5.3359 -- time: 4.7024 sec.\n",
      "Step(15190) loss: 5.4682 -- time: 4.5560 sec.\n",
      "Step(15200) loss: 5.1678 -- time: 4.5270 sec.\n",
      "Step(15210) loss: 5.2908 -- time: 4.6117 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 952.4707 - val_loss: 0.0000\n",
      "time: 83.2642 sec.\n",
      "time_left: 159.5898 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 86/200\n",
      "----------------------------------------------------------------------\n",
      "Step(15220) loss: 5.5902 -- time: 2.2318 sec.\n",
      "Step(15230) loss: 5.4952 -- time: 4.5287 sec.\n",
      "Step(15240) loss: 5.5191 -- time: 4.6604 sec.\n",
      "Step(15250) loss: 5.3706 -- time: 4.4902 sec.\n",
      "Step(15260) loss: 5.2149 -- time: 4.6228 sec.\n",
      "Step(15270) loss: 5.7049 -- time: 4.5177 sec.\n",
      "Step(15280) loss: 5.5331 -- time: 4.5227 sec.\n",
      "Step(15290) loss: 5.1136 -- time: 4.5909 sec.\n",
      "Step(15300) loss: 5.9717 -- time: 4.6129 sec.\n",
      "Step(15310) loss: 5.2777 -- time: 4.6332 sec.\n",
      "Step(15320) loss: 4.9838 -- time: 4.6530 sec.\n",
      "Step(15330) loss: 4.8985 -- time: 4.4259 sec.\n",
      "Step(15340) loss: 4.6940 -- time: 4.6224 sec.\n",
      "Step(15350) loss: 5.1543 -- time: 4.5947 sec.\n",
      "Step(15360) loss: 5.5071 -- time: 4.5928 sec.\n",
      "Step(15370) loss: 5.6152 -- time: 4.5714 sec.\n",
      "Step(15380) loss: 5.2719 -- time: 4.6109 sec.\n",
      "Step(15390) loss: 5.1867 -- time: 4.6149 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.3065 - val_loss: 0.0000\n",
      "time: 83.7398 sec.\n",
      "time_left: 159.1056 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 87/200\n",
      "----------------------------------------------------------------------\n",
      "Step(15400) loss: 5.3085 -- time: 2.6625 sec.\n",
      "Step(15410) loss: 5.2061 -- time: 4.5710 sec.\n",
      "Step(15420) loss: 5.3221 -- time: 4.4910 sec.\n",
      "Step(15430) loss: 4.9385 -- time: 4.6195 sec.\n",
      "Step(15440) loss: 5.6039 -- time: 4.5574 sec.\n",
      "Step(15450) loss: 5.5849 -- time: 4.5886 sec.\n",
      "Step(15460) loss: 5.4577 -- time: 4.6210 sec.\n",
      "Step(15470) loss: 5.7587 -- time: 4.4717 sec.\n",
      "Step(15480) loss: 5.6432 -- time: 4.5816 sec.\n",
      "Step(15490) loss: 5.3305 -- time: 4.6887 sec.\n",
      "Step(15500) loss: 5.2421 -- time: 4.5086 sec.\n",
      "Step(15510) loss: 5.2870 -- time: 4.6684 sec.\n",
      "Step(15520) loss: 5.1465 -- time: 4.5919 sec.\n",
      "Step(15530) loss: 5.1515 -- time: 4.6219 sec.\n",
      "Step(15540) loss: 4.8693 -- time: 4.6936 sec.\n",
      "Step(15550) loss: 5.3530 -- time: 4.5558 sec.\n",
      "Step(15560) loss: 5.5276 -- time: 4.4842 sec.\n",
      "Step(15570) loss: 5.1480 -- time: 4.6223 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 957.5572 - val_loss: 0.0000\n",
      "time: 83.7947 sec.\n",
      "time_left: 157.8133 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 88/200\n",
      "----------------------------------------------------------------------\n",
      "Step(15580) loss: 5.2398 -- time: 3.2219 sec.\n",
      "Step(15590) loss: 5.2974 -- time: 4.5814 sec.\n",
      "Step(15600) loss: 4.8011 -- time: 4.5521 sec.\n",
      "Step(15610) loss: 5.7860 -- time: 4.6112 sec.\n",
      "Step(15620) loss: 5.3945 -- time: 4.6164 sec.\n",
      "Step(15630) loss: 4.7672 -- time: 4.6635 sec.\n",
      "Step(15640) loss: 5.8092 -- time: 4.6348 sec.\n",
      "Step(15650) loss: 5.5385 -- time: 4.4670 sec.\n",
      "Step(15660) loss: 5.6372 -- time: 4.6262 sec.\n",
      "Step(15670) loss: 5.0899 -- time: 4.5697 sec.\n",
      "Step(15680) loss: 5.3806 -- time: 4.7466 sec.\n",
      "Step(15690) loss: 5.2401 -- time: 4.6246 sec.\n",
      "Step(15700) loss: 5.5315 -- time: 4.5169 sec.\n",
      "Step(15710) loss: 5.2663 -- time: 4.4729 sec.\n",
      "Step(15720) loss: 5.4795 -- time: 4.5909 sec.\n",
      "Step(15730) loss: 5.4011 -- time: 4.5633 sec.\n",
      "Step(15740) loss: 5.6064 -- time: 4.6051 sec.\n",
      "Step(15750) loss: 5.4607 -- time: 4.7727 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.9753 - val_loss: 0.0000\n",
      "time: 84.1624 sec.\n",
      "time_left: 157.1032 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 89/200\n",
      "----------------------------------------------------------------------\n",
      "Step(15760) loss: 5.7150 -- time: 3.6911 sec.\n",
      "Step(15770) loss: 5.1504 -- time: 4.6189 sec.\n",
      "Step(15780) loss: 5.5666 -- time: 4.6217 sec.\n",
      "Step(15790) loss: 5.0108 -- time: 4.5925 sec.\n",
      "Step(15800) loss: 5.2859 -- time: 4.7476 sec.\n",
      "Step(15810) loss: 5.6052 -- time: 4.5812 sec.\n",
      "Step(15820) loss: 5.2024 -- time: 4.6598 sec.\n",
      "Step(15830) loss: 5.5560 -- time: 4.6052 sec.\n",
      "Step(15840) loss: 6.1191 -- time: 4.5178 sec.\n",
      "Step(15850) loss: 5.8692 -- time: 4.6404 sec.\n",
      "Step(15860) loss: 5.5432 -- time: 4.6403 sec.\n",
      "Step(15870) loss: 5.3595 -- time: 4.6302 sec.\n",
      "Step(15880) loss: 5.4529 -- time: 4.5992 sec.\n",
      "Step(15890) loss: 5.8060 -- time: 4.5251 sec.\n",
      "Step(15900) loss: 5.2836 -- time: 4.5611 sec.\n",
      "Step(15910) loss: 5.4725 -- time: 4.6363 sec.\n",
      "Step(15920) loss: 5.7394 -- time: 4.5038 sec.\n",
      "Step(15930) loss: 5.7680 -- time: 4.6578 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 954.3035 - val_loss: 0.0000\n",
      "time: 84.3290 sec.\n",
      "time_left: 156.0086 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 90/200\n",
      "----------------------------------------------------------------------\n",
      "Step(15940) loss: 6.1077 -- time: 4.0918 sec.\n",
      "Step(15950) loss: 4.9647 -- time: 4.5848 sec.\n",
      "Step(15960) loss: 5.5940 -- time: 4.5560 sec.\n",
      "Step(15970) loss: 5.0006 -- time: 4.5975 sec.\n",
      "Step(15980) loss: 5.8823 -- time: 4.5984 sec.\n",
      "Step(15990) loss: 5.4781 -- time: 4.4641 sec.\n",
      "Step(16000) loss: 4.7765 -- time: 4.5457 sec.\n",
      "Step(16010) loss: 5.3421 -- time: 4.4827 sec.\n",
      "Step(16020) loss: 5.0501 -- time: 4.5962 sec.\n",
      "Step(16030) loss: 5.0332 -- time: 4.5417 sec.\n",
      "Step(16040) loss: 5.2241 -- time: 4.6005 sec.\n",
      "Step(16050) loss: 5.0585 -- time: 4.6779 sec.\n",
      "Step(16060) loss: 4.9093 -- time: 4.5299 sec.\n",
      "Step(16070) loss: 5.2732 -- time: 4.6978 sec.\n",
      "Step(16080) loss: 5.1227 -- time: 4.6781 sec.\n",
      "Step(16090) loss: 5.4580 -- time: 4.4756 sec.\n",
      "Step(16100) loss: 5.1259 -- time: 4.5827 sec.\n",
      "Step(16110) loss: 4.8111 -- time: 4.4807 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 946.3081 - val_loss: 960.5324\n",
      "time: 120.4520 sec.\n",
      "time_left: 220.8286 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 91/200\n",
      "----------------------------------------------------------------------\n",
      "Step(16120) loss: 5.0673 -- time: 4.5450 sec.\n",
      "Step(16130) loss: 4.9711 -- time: 4.6293 sec.\n",
      "Step(16140) loss: 5.2342 -- time: 4.4486 sec.\n",
      "Step(16150) loss: 4.8000 -- time: 4.4734 sec.\n",
      "Step(16160) loss: 5.3137 -- time: 4.3995 sec.\n",
      "Step(16170) loss: 5.3901 -- time: 4.6530 sec.\n",
      "Step(16180) loss: 4.6038 -- time: 4.4464 sec.\n",
      "Step(16190) loss: 5.2648 -- time: 4.5592 sec.\n",
      "Step(16200) loss: 5.4693 -- time: 4.4167 sec.\n",
      "Step(16210) loss: 4.8792 -- time: 4.7082 sec.\n",
      "Step(16220) loss: 5.3187 -- time: 4.5492 sec.\n",
      "Step(16230) loss: 4.9541 -- time: 4.5924 sec.\n",
      "Step(16240) loss: 5.0071 -- time: 4.6685 sec.\n",
      "Step(16250) loss: 5.2250 -- time: 4.5144 sec.\n",
      "Step(16260) loss: 5.3521 -- time: 4.6558 sec.\n",
      "Step(16270) loss: 5.3871 -- time: 4.5371 sec.\n",
      "Step(16280) loss: 5.8005 -- time: 4.4687 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 950.5068 - val_loss: 0.0000\n",
      "time: 83.2028 sec.\n",
      "time_left: 151.1517 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 92/200\n",
      "----------------------------------------------------------------------\n",
      "Step(16290) loss: 5.0083 -- time: 0.3525 sec.\n",
      "Step(16300) loss: 4.8351 -- time: 4.5246 sec.\n",
      "Step(16310) loss: 5.4148 -- time: 4.5836 sec.\n",
      "Step(16320) loss: 5.0712 -- time: 4.5174 sec.\n",
      "Step(16330) loss: 4.8641 -- time: 4.5069 sec.\n",
      "Step(16340) loss: 5.4463 -- time: 4.6676 sec.\n",
      "Step(16350) loss: 5.4990 -- time: 4.5800 sec.\n",
      "Step(16360) loss: 5.7793 -- time: 4.6516 sec.\n",
      "Step(16370) loss: 5.4627 -- time: 4.5079 sec.\n",
      "Step(16380) loss: 5.2791 -- time: 4.6760 sec.\n",
      "Step(16390) loss: 5.6641 -- time: 4.5854 sec.\n",
      "Step(16400) loss: 4.9923 -- time: 4.5368 sec.\n",
      "Step(16410) loss: 4.9473 -- time: 4.6300 sec.\n",
      "Step(16420) loss: 5.0133 -- time: 4.7004 sec.\n",
      "Step(16430) loss: 4.6294 -- time: 4.6348 sec.\n",
      "Step(16440) loss: 4.9214 -- time: 4.6125 sec.\n",
      "Step(16450) loss: 5.1722 -- time: 4.5877 sec.\n",
      "Step(16460) loss: 5.2757 -- time: 4.5652 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 944.0787 - val_loss: 0.0000\n",
      "time: 84.1086 sec.\n",
      "time_left: 151.3955 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 93/200\n",
      "----------------------------------------------------------------------\n",
      "Step(16470) loss: 5.7129 -- time: 0.8708 sec.\n",
      "Step(16480) loss: 5.1546 -- time: 4.6813 sec.\n",
      "Step(16490) loss: 5.2659 -- time: 4.6089 sec.\n",
      "Step(16500) loss: 5.0359 -- time: 4.5366 sec.\n",
      "Step(16510) loss: 5.6579 -- time: 4.6728 sec.\n",
      "Step(16520) loss: 5.3429 -- time: 4.6219 sec.\n",
      "Step(16530) loss: 5.0631 -- time: 4.5478 sec.\n",
      "Step(16540) loss: 5.2281 -- time: 4.5527 sec.\n",
      "Step(16550) loss: 5.8345 -- time: 4.7761 sec.\n",
      "Step(16560) loss: 4.9095 -- time: 4.6010 sec.\n",
      "Step(16570) loss: 5.5212 -- time: 4.6401 sec.\n",
      "Step(16580) loss: 5.2894 -- time: 4.6377 sec.\n",
      "Step(16590) loss: 5.5059 -- time: 4.6610 sec.\n",
      "Step(16600) loss: 5.4456 -- time: 4.6211 sec.\n",
      "Step(16610) loss: 5.5792 -- time: 4.6643 sec.\n",
      "Step(16620) loss: 4.9417 -- time: 4.5642 sec.\n",
      "Step(16630) loss: 4.7864 -- time: 4.5765 sec.\n",
      "Step(16640) loss: 5.4658 -- time: 4.5159 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 952.6937 - val_loss: 0.0000\n",
      "time: 84.4878 sec.\n",
      "time_left: 150.6700 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 94/200\n",
      "----------------------------------------------------------------------\n",
      "Step(16650) loss: 4.7908 -- time: 1.2745 sec.\n",
      "Step(16660) loss: 5.2740 -- time: 4.5930 sec.\n",
      "Step(16670) loss: 5.3821 -- time: 4.4418 sec.\n",
      "Step(16680) loss: 4.3328 -- time: 4.4984 sec.\n",
      "Step(16690) loss: 5.6800 -- time: 4.4475 sec.\n",
      "Step(16700) loss: 5.3781 -- time: 4.4714 sec.\n",
      "Step(16710) loss: 5.0368 -- time: 4.5702 sec.\n",
      "Step(16720) loss: 5.0050 -- time: 4.6280 sec.\n",
      "Step(16730) loss: 4.9067 -- time: 4.6961 sec.\n",
      "Step(16740) loss: 5.9038 -- time: 4.5505 sec.\n",
      "Step(16750) loss: 5.2355 -- time: 4.4694 sec.\n",
      "Step(16760) loss: 4.9576 -- time: 4.6247 sec.\n",
      "Step(16770) loss: 5.2581 -- time: 4.7939 sec.\n",
      "Step(16780) loss: 6.1737 -- time: 4.5776 sec.\n",
      "Step(16790) loss: 5.1475 -- time: 4.5829 sec.\n",
      "Step(16800) loss: 5.0521 -- time: 4.5656 sec.\n",
      "Step(16810) loss: 5.4160 -- time: 4.5133 sec.\n",
      "Step(16820) loss: 5.2222 -- time: 4.6716 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.2367 - val_loss: 0.0000\n",
      "time: 83.6109 sec.\n",
      "time_left: 147.7126 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 95/200\n",
      "----------------------------------------------------------------------\n",
      "Step(16830) loss: 5.8338 -- time: 1.7609 sec.\n",
      "Step(16840) loss: 4.9331 -- time: 4.4926 sec.\n",
      "Step(16850) loss: 5.6079 -- time: 4.4779 sec.\n",
      "Step(16860) loss: 5.4092 -- time: 4.6209 sec.\n",
      "Step(16870) loss: 5.5978 -- time: 4.5085 sec.\n",
      "Step(16880) loss: 5.3450 -- time: 4.6356 sec.\n",
      "Step(16890) loss: 5.2560 -- time: 4.4092 sec.\n",
      "Step(16900) loss: 5.1110 -- time: 4.4263 sec.\n",
      "Step(16910) loss: 5.9549 -- time: 4.5060 sec.\n",
      "Step(16920) loss: 5.3901 -- time: 4.5854 sec.\n",
      "Step(16930) loss: 5.3227 -- time: 4.4481 sec.\n",
      "Step(16940) loss: 5.0644 -- time: 4.7018 sec.\n",
      "Step(16950) loss: 4.9141 -- time: 4.6108 sec.\n",
      "Step(16960) loss: 5.5486 -- time: 4.6142 sec.\n",
      "Step(16970) loss: 4.7690 -- time: 4.6437 sec.\n",
      "Step(16980) loss: 5.4497 -- time: 4.7145 sec.\n",
      "Step(16990) loss: 5.1927 -- time: 4.5569 sec.\n",
      "Step(17000) loss: 5.4505 -- time: 4.5723 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 949.8879 - val_loss: 0.0000\n",
      "time: 83.4591 sec.\n",
      "time_left: 146.0534 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 96/200\n",
      "----------------------------------------------------------------------\n",
      "Step(17010) loss: 4.8472 -- time: 2.3058 sec.\n",
      "Step(17020) loss: 5.1004 -- time: 4.5000 sec.\n",
      "Step(17030) loss: 5.6681 -- time: 4.7700 sec.\n",
      "Step(17040) loss: 5.3705 -- time: 4.6363 sec.\n",
      "Step(17050) loss: 5.2927 -- time: 4.5704 sec.\n",
      "Step(17060) loss: 6.0526 -- time: 4.6925 sec.\n",
      "Step(17070) loss: 5.2689 -- time: 4.6442 sec.\n",
      "Step(17080) loss: 5.1305 -- time: 4.5497 sec.\n",
      "Step(17090) loss: 5.0878 -- time: 4.5917 sec.\n",
      "Step(17100) loss: 5.3470 -- time: 4.6469 sec.\n",
      "Step(17110) loss: 5.3123 -- time: 4.6138 sec.\n",
      "Step(17120) loss: 5.3827 -- time: 4.5986 sec.\n",
      "Step(17130) loss: 5.3730 -- time: 4.5206 sec.\n",
      "Step(17140) loss: 5.2212 -- time: 4.5052 sec.\n",
      "Step(17150) loss: 4.7071 -- time: 4.6685 sec.\n",
      "Step(17160) loss: 5.0992 -- time: 4.4954 sec.\n",
      "Step(17170) loss: 5.1484 -- time: 4.7475 sec.\n",
      "Step(17180) loss: 4.9980 -- time: 4.5744 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 955.2045 - val_loss: 0.0000\n",
      "time: 84.3189 sec.\n",
      "time_left: 146.1528 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 97/200\n",
      "----------------------------------------------------------------------\n",
      "Step(17190) loss: 5.2504 -- time: 2.8261 sec.\n",
      "Step(17200) loss: 5.8254 -- time: 4.6017 sec.\n",
      "Step(17210) loss: 5.6402 -- time: 4.4729 sec.\n",
      "Step(17220) loss: 5.0524 -- time: 4.6696 sec.\n",
      "Step(17230) loss: 5.3781 -- time: 4.4690 sec.\n",
      "Step(17240) loss: 5.5446 -- time: 4.5443 sec.\n",
      "Step(17250) loss: 5.3112 -- time: 4.5162 sec.\n",
      "Step(17260) loss: 5.5470 -- time: 4.5116 sec.\n",
      "Step(17270) loss: 5.3936 -- time: 4.6330 sec.\n",
      "Step(17280) loss: 5.5967 -- time: 4.5907 sec.\n",
      "Step(17290) loss: 5.0584 -- time: 4.4818 sec.\n",
      "Step(17300) loss: 5.0003 -- time: 4.7098 sec.\n",
      "Step(17310) loss: 5.5709 -- time: 4.5579 sec.\n",
      "Step(17320) loss: 5.7090 -- time: 4.5180 sec.\n",
      "Step(17330) loss: 5.1573 -- time: 4.5471 sec.\n",
      "Step(17340) loss: 5.0800 -- time: 4.5527 sec.\n",
      "Step(17350) loss: 4.6860 -- time: 4.5697 sec.\n",
      "Step(17360) loss: 5.4297 -- time: 4.5445 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 949.4794 - val_loss: 0.0000\n",
      "time: 83.5138 sec.\n",
      "time_left: 143.3653 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 98/200\n",
      "----------------------------------------------------------------------\n",
      "Step(17370) loss: 5.3842 -- time: 3.0918 sec.\n",
      "Step(17380) loss: 5.7325 -- time: 4.7007 sec.\n",
      "Step(17390) loss: 5.0465 -- time: 4.6253 sec.\n",
      "Step(17400) loss: 5.0291 -- time: 4.5864 sec.\n",
      "Step(17410) loss: 5.2905 -- time: 4.5219 sec.\n",
      "Step(17420) loss: 5.1647 -- time: 4.4891 sec.\n",
      "Step(17430) loss: 5.0949 -- time: 4.6167 sec.\n",
      "Step(17440) loss: 5.3941 -- time: 4.4308 sec.\n",
      "Step(17450) loss: 5.3049 -- time: 4.7043 sec.\n",
      "Step(17460) loss: 4.9941 -- time: 4.5507 sec.\n",
      "Step(17470) loss: 5.6791 -- time: 4.5696 sec.\n",
      "Step(17480) loss: 5.2739 -- time: 4.4713 sec.\n",
      "Step(17490) loss: 4.8470 -- time: 4.5096 sec.\n",
      "Step(17500) loss: 5.2041 -- time: 4.5280 sec.\n",
      "Step(17510) loss: 4.7188 -- time: 4.5562 sec.\n",
      "Step(17520) loss: 5.0429 -- time: 4.5258 sec.\n",
      "Step(17530) loss: 5.6400 -- time: 4.6283 sec.\n",
      "Step(17540) loss: 5.5408 -- time: 4.5682 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 948.4662 - val_loss: 0.0000\n",
      "time: 83.4883 sec.\n",
      "time_left: 141.9302 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 99/200\n",
      "----------------------------------------------------------------------\n",
      "Step(17550) loss: 5.4286 -- time: 3.6398 sec.\n",
      "Step(17560) loss: 5.1807 -- time: 4.5988 sec.\n",
      "Step(17570) loss: 5.0778 -- time: 4.6983 sec.\n",
      "Step(17580) loss: 5.2836 -- time: 4.6290 sec.\n",
      "Step(17590) loss: 4.9414 -- time: 4.6337 sec.\n",
      "Step(17600) loss: 5.5301 -- time: 4.4970 sec.\n",
      "Step(17610) loss: 6.1626 -- time: 4.6457 sec.\n",
      "Step(17620) loss: 5.1481 -- time: 4.6278 sec.\n",
      "Step(17630) loss: 4.8453 -- time: 4.7463 sec.\n",
      "Step(17640) loss: 5.5749 -- time: 4.4884 sec.\n",
      "Step(17650) loss: 5.2703 -- time: 4.5283 sec.\n",
      "Step(17660) loss: 4.5987 -- time: 4.5725 sec.\n",
      "Step(17670) loss: 5.7337 -- time: 4.5342 sec.\n",
      "Step(17680) loss: 4.6999 -- time: 4.5781 sec.\n",
      "Step(17690) loss: 5.3668 -- time: 4.5633 sec.\n",
      "Step(17700) loss: 5.1964 -- time: 4.6001 sec.\n",
      "Step(17710) loss: 5.0742 -- time: 4.5088 sec.\n",
      "Step(17720) loss: 5.2369 -- time: 4.5439 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.3644 - val_loss: 0.0000\n",
      "time: 83.9304 sec.\n",
      "time_left: 141.2828 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 100/200\n",
      "----------------------------------------------------------------------\n",
      "Step(17730) loss: 4.8917 -- time: 4.2104 sec.\n",
      "Step(17740) loss: 4.2215 -- time: 4.4647 sec.\n",
      "Step(17750) loss: 6.0448 -- time: 4.5428 sec.\n",
      "Step(17760) loss: 5.1027 -- time: 4.5462 sec.\n",
      "Step(17770) loss: 5.0112 -- time: 4.6802 sec.\n",
      "Step(17780) loss: 5.5689 -- time: 4.5098 sec.\n",
      "Step(17790) loss: 4.7274 -- time: 4.5575 sec.\n",
      "Step(17800) loss: 4.4930 -- time: 4.5941 sec.\n",
      "Step(17810) loss: 5.2093 -- time: 4.6627 sec.\n",
      "Step(17820) loss: 5.3255 -- time: 4.4901 sec.\n",
      "Step(17830) loss: 5.1594 -- time: 4.5596 sec.\n",
      "Step(17840) loss: 4.9790 -- time: 4.5594 sec.\n",
      "Step(17850) loss: 5.2200 -- time: 4.6743 sec.\n",
      "Step(17860) loss: 4.9084 -- time: 4.6784 sec.\n",
      "Step(17870) loss: 5.4604 -- time: 4.4826 sec.\n",
      "Step(17880) loss: 5.0909 -- time: 4.5835 sec.\n",
      "Step(17890) loss: 5.3344 -- time: 4.5724 sec.\n",
      "Step(17900) loss: 4.6756 -- time: 4.3718 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 946.0603 - val_loss: 971.3744\n",
      "time: 120.1708 sec.\n",
      "time_left: 200.2847 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 101/200\n",
      "----------------------------------------------------------------------\n",
      "Step(17910) loss: 4.8568 -- time: 4.7768 sec.\n",
      "Step(17920) loss: 5.4066 -- time: 4.6813 sec.\n",
      "Step(17930) loss: 5.8162 -- time: 4.7791 sec.\n",
      "Step(17940) loss: 5.2602 -- time: 4.6966 sec.\n",
      "Step(17950) loss: 5.4339 -- time: 4.8135 sec.\n",
      "Step(17960) loss: 5.4653 -- time: 4.6368 sec.\n",
      "Step(17970) loss: 5.7298 -- time: 4.8787 sec.\n",
      "Step(17980) loss: 5.5604 -- time: 4.6360 sec.\n",
      "Step(17990) loss: 5.4668 -- time: 4.6287 sec.\n",
      "Step(18000) loss: 5.1084 -- time: 4.8393 sec.\n",
      "Step(18010) loss: 4.9403 -- time: 4.7124 sec.\n",
      "Step(18020) loss: 4.8835 -- time: 4.6120 sec.\n",
      "Step(18030) loss: 5.4487 -- time: 4.7343 sec.\n",
      "Step(18040) loss: 6.2493 -- time: 4.6578 sec.\n",
      "Step(18050) loss: 5.0963 -- time: 4.4570 sec.\n",
      "Step(18060) loss: 5.4421 -- time: 4.6123 sec.\n",
      "Step(18070) loss: 5.1337 -- time: 4.6952 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 971.9209 - val_loss: 0.0000\n",
      "time: 85.7507 sec.\n",
      "time_left: 141.4887 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 102/200\n",
      "----------------------------------------------------------------------\n",
      "Step(18080) loss: 5.5625 -- time: 0.3693 sec.\n",
      "Step(18090) loss: 5.5130 -- time: 4.5310 sec.\n",
      "Step(18100) loss: 5.8043 -- time: 4.5084 sec.\n",
      "Step(18110) loss: 5.1266 -- time: 4.6777 sec.\n",
      "Step(18120) loss: 5.4484 -- time: 4.6647 sec.\n",
      "Step(18130) loss: 6.0181 -- time: 4.6352 sec.\n",
      "Step(18140) loss: 4.8874 -- time: 4.4325 sec.\n",
      "Step(18150) loss: 5.5231 -- time: 4.5622 sec.\n",
      "Step(18160) loss: 5.4640 -- time: 4.4850 sec.\n",
      "Step(18170) loss: 6.1428 -- time: 4.5413 sec.\n",
      "Step(18180) loss: 5.2589 -- time: 4.4823 sec.\n",
      "Step(18190) loss: 5.5578 -- time: 4.5350 sec.\n",
      "Step(18200) loss: 5.4859 -- time: 4.6867 sec.\n",
      "Step(18210) loss: 5.5137 -- time: 4.6045 sec.\n",
      "Step(18220) loss: 5.7614 -- time: 4.5690 sec.\n",
      "Step(18230) loss: 5.4729 -- time: 4.5014 sec.\n",
      "Step(18240) loss: 5.8763 -- time: 4.5934 sec.\n",
      "Step(18250) loss: 5.0849 -- time: 4.6217 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.3716 - val_loss: 0.0000\n",
      "time: 83.6654 sec.\n",
      "time_left: 136.6535 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 103/200\n",
      "----------------------------------------------------------------------\n",
      "Step(18260) loss: 5.4268 -- time: 0.8069 sec.\n",
      "Step(18270) loss: 5.7749 -- time: 4.4987 sec.\n",
      "Step(18280) loss: 5.2264 -- time: 4.5885 sec.\n",
      "Step(18290) loss: 4.5042 -- time: 4.4166 sec.\n",
      "Step(18300) loss: 5.3568 -- time: 4.5429 sec.\n",
      "Step(18310) loss: 5.6861 -- time: 4.5958 sec.\n",
      "Step(18320) loss: 5.6584 -- time: 4.5571 sec.\n",
      "Step(18330) loss: 5.3899 -- time: 4.5852 sec.\n",
      "Step(18340) loss: 5.7757 -- time: 4.4399 sec.\n",
      "Step(18350) loss: 5.3869 -- time: 4.6026 sec.\n",
      "Step(18360) loss: 5.8442 -- time: 4.4809 sec.\n",
      "Step(18370) loss: 5.1660 -- time: 4.5748 sec.\n",
      "Step(18380) loss: 5.9077 -- time: 4.5884 sec.\n",
      "Step(18390) loss: 5.4712 -- time: 4.4592 sec.\n",
      "Step(18400) loss: 5.4163 -- time: 4.4900 sec.\n",
      "Step(18410) loss: 5.5980 -- time: 4.5481 sec.\n",
      "Step(18420) loss: 5.1755 -- time: 4.6781 sec.\n",
      "Step(18430) loss: 5.3179 -- time: 4.5045 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 968.4737 - val_loss: 0.0000\n",
      "time: 83.1415 sec.\n",
      "time_left: 134.4121 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 104/200\n",
      "----------------------------------------------------------------------\n",
      "Step(18440) loss: 5.6620 -- time: 1.3472 sec.\n",
      "Step(18450) loss: 5.4799 -- time: 4.6581 sec.\n",
      "Step(18460) loss: 5.5989 -- time: 4.6558 sec.\n",
      "Step(18470) loss: 5.5306 -- time: 4.5882 sec.\n",
      "Step(18480) loss: 5.1584 -- time: 4.5877 sec.\n",
      "Step(18490) loss: 4.9939 -- time: 4.5258 sec.\n",
      "Step(18500) loss: 5.1540 -- time: 4.4230 sec.\n",
      "Step(18510) loss: 4.7937 -- time: 4.5452 sec.\n",
      "Step(18520) loss: 5.0127 -- time: 4.5177 sec.\n",
      "Step(18530) loss: 5.3276 -- time: 4.5493 sec.\n",
      "Step(18540) loss: 5.4511 -- time: 4.6048 sec.\n",
      "Step(18550) loss: 5.3567 -- time: 4.6256 sec.\n",
      "Step(18560) loss: 5.2431 -- time: 4.5836 sec.\n",
      "Step(18570) loss: 5.0553 -- time: 4.7353 sec.\n",
      "Step(18580) loss: 4.9186 -- time: 4.5096 sec.\n",
      "Step(18590) loss: 5.2428 -- time: 4.6966 sec.\n",
      "Step(18600) loss: 5.1034 -- time: 4.4494 sec.\n",
      "Step(18610) loss: 5.1283 -- time: 4.3678 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 967.4950 - val_loss: 0.0000\n",
      "time: 83.6433 sec.\n",
      "time_left: 133.8293 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 105/200\n",
      "----------------------------------------------------------------------\n",
      "Step(18620) loss: 4.5720 -- time: 1.7140 sec.\n",
      "Step(18630) loss: 5.3270 -- time: 4.7269 sec.\n",
      "Step(18640) loss: 5.1370 -- time: 4.3973 sec.\n",
      "Step(18650) loss: 5.1818 -- time: 4.3381 sec.\n",
      "Step(18660) loss: 5.2700 -- time: 4.3499 sec.\n",
      "Step(18670) loss: 5.1531 -- time: 4.4315 sec.\n",
      "Step(18680) loss: 5.0131 -- time: 4.5267 sec.\n",
      "Step(18690) loss: 5.8169 -- time: 4.4403 sec.\n",
      "Step(18700) loss: 5.1597 -- time: 4.5166 sec.\n",
      "Step(18710) loss: 5.6681 -- time: 4.5607 sec.\n",
      "Step(18720) loss: 5.4531 -- time: 4.4447 sec.\n",
      "Step(18730) loss: 5.5444 -- time: 4.3187 sec.\n",
      "Step(18740) loss: 5.7413 -- time: 4.4537 sec.\n",
      "Step(18750) loss: 5.5305 -- time: 4.4305 sec.\n",
      "Step(18760) loss: 5.6015 -- time: 4.4580 sec.\n",
      "Step(18770) loss: 5.0362 -- time: 4.4592 sec.\n",
      "Step(18780) loss: 5.3114 -- time: 4.5389 sec.\n",
      "Step(18790) loss: 5.4436 -- time: 4.4535 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 969.8110 - val_loss: 0.0000\n",
      "time: 81.5709 sec.\n",
      "time_left: 129.1539 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 106/200\n",
      "----------------------------------------------------------------------\n",
      "Step(18800) loss: 5.5993 -- time: 2.1643 sec.\n",
      "Step(18810) loss: 4.9107 -- time: 4.4841 sec.\n",
      "Step(18820) loss: 5.4038 -- time: 4.4867 sec.\n",
      "Step(18830) loss: 5.2698 -- time: 4.4619 sec.\n",
      "Step(18840) loss: 5.1053 -- time: 4.3552 sec.\n",
      "Step(18850) loss: 5.1482 -- time: 4.5602 sec.\n",
      "Step(18860) loss: 5.3486 -- time: 4.4201 sec.\n",
      "Step(18870) loss: 5.3423 -- time: 4.5748 sec.\n",
      "Step(18880) loss: 5.0601 -- time: 4.5093 sec.\n",
      "Step(18890) loss: 5.6136 -- time: 4.4581 sec.\n",
      "Step(18900) loss: 5.0132 -- time: 4.5518 sec.\n",
      "Step(18910) loss: 4.9591 -- time: 4.4734 sec.\n",
      "Step(18920) loss: 5.3707 -- time: 4.3424 sec.\n",
      "Step(18930) loss: 5.4054 -- time: 4.4583 sec.\n",
      "Step(18940) loss: 6.1225 -- time: 4.3839 sec.\n",
      "Step(18950) loss: 5.5316 -- time: 4.4062 sec.\n",
      "Step(18960) loss: 5.3895 -- time: 4.4108 sec.\n",
      "Step(18970) loss: 5.2466 -- time: 4.5505 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.7357 - val_loss: 0.0000\n",
      "time: 81.5576 sec.\n",
      "time_left: 127.7735 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 107/200\n",
      "----------------------------------------------------------------------\n",
      "Step(18980) loss: 5.2835 -- time: 2.6043 sec.\n",
      "Step(18990) loss: 5.7841 -- time: 4.4551 sec.\n",
      "Step(19000) loss: 5.3986 -- time: 4.3586 sec.\n",
      "Step(19010) loss: 5.4570 -- time: 4.3869 sec.\n",
      "Step(19020) loss: 5.4636 -- time: 4.4659 sec.\n",
      "Step(19030) loss: 5.2480 -- time: 4.5742 sec.\n",
      "Step(19040) loss: 5.4469 -- time: 4.5181 sec.\n",
      "Step(19050) loss: 5.4840 -- time: 4.5404 sec.\n",
      "Step(19060) loss: 5.4116 -- time: 4.4926 sec.\n",
      "Step(19070) loss: 5.0879 -- time: 4.4100 sec.\n",
      "Step(19080) loss: 5.1069 -- time: 4.5571 sec.\n",
      "Step(19090) loss: 5.6966 -- time: 4.5508 sec.\n",
      "Step(19100) loss: 5.7641 -- time: 4.3735 sec.\n",
      "Step(19110) loss: 4.8802 -- time: 4.5691 sec.\n",
      "Step(19120) loss: 5.4128 -- time: 4.4242 sec.\n",
      "Step(19130) loss: 5.0594 -- time: 4.4930 sec.\n",
      "Step(19140) loss: 5.1510 -- time: 4.3302 sec.\n",
      "Step(19150) loss: 5.4285 -- time: 4.4005 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 956.5107 - val_loss: 0.0000\n",
      "time: 81.6379 sec.\n",
      "time_left: 126.5388 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 108/200\n",
      "----------------------------------------------------------------------\n",
      "Step(19160) loss: 5.8721 -- time: 3.1937 sec.\n",
      "Step(19170) loss: 5.5225 -- time: 4.3889 sec.\n",
      "Step(19180) loss: 5.8225 -- time: 4.3442 sec.\n",
      "Step(19190) loss: 5.3327 -- time: 4.4948 sec.\n",
      "Step(19200) loss: 5.5045 -- time: 4.3054 sec.\n",
      "Step(19210) loss: 5.4044 -- time: 4.3718 sec.\n",
      "Step(19220) loss: 5.8297 -- time: 4.3748 sec.\n",
      "Step(19230) loss: 5.4396 -- time: 4.5352 sec.\n",
      "Step(19240) loss: 4.9139 -- time: 4.5130 sec.\n",
      "Step(19250) loss: 5.4231 -- time: 4.4049 sec.\n",
      "Step(19260) loss: 5.8487 -- time: 4.2888 sec.\n",
      "Step(19270) loss: 5.5532 -- time: 4.3659 sec.\n",
      "Step(19280) loss: 5.5087 -- time: 4.5159 sec.\n",
      "Step(19290) loss: 5.1631 -- time: 4.5386 sec.\n",
      "Step(19300) loss: 5.0660 -- time: 4.5807 sec.\n",
      "Step(19310) loss: 5.6643 -- time: 4.6098 sec.\n",
      "Step(19320) loss: 5.5449 -- time: 4.4450 sec.\n",
      "Step(19330) loss: 5.7528 -- time: 4.6637 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 969.6901 - val_loss: 0.0000\n",
      "time: 81.5904 sec.\n",
      "time_left: 125.1052 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 109/200\n",
      "----------------------------------------------------------------------\n",
      "Step(19340) loss: 5.2982 -- time: 3.4967 sec.\n",
      "Step(19350) loss: 5.2147 -- time: 4.4429 sec.\n",
      "Step(19360) loss: 5.3252 -- time: 4.4973 sec.\n",
      "Step(19370) loss: 5.7493 -- time: 4.6117 sec.\n",
      "Step(19380) loss: 5.1223 -- time: 4.4579 sec.\n",
      "Step(19390) loss: 5.3759 -- time: 4.5885 sec.\n",
      "Step(19400) loss: 4.8176 -- time: 4.3194 sec.\n",
      "Step(19410) loss: 4.9659 -- time: 4.3629 sec.\n",
      "Step(19420) loss: 5.6388 -- time: 4.4306 sec.\n",
      "Step(19430) loss: 5.3383 -- time: 4.4429 sec.\n",
      "Step(19440) loss: 5.6251 -- time: 4.4964 sec.\n",
      "Step(19450) loss: 5.2984 -- time: 4.5285 sec.\n",
      "Step(19460) loss: 5.4983 -- time: 4.4080 sec.\n",
      "Step(19470) loss: 5.6252 -- time: 4.4434 sec.\n",
      "Step(19480) loss: 5.5098 -- time: 4.5098 sec.\n",
      "Step(19490) loss: 5.1560 -- time: 4.3890 sec.\n",
      "Step(19500) loss: 5.5017 -- time: 4.5112 sec.\n",
      "Step(19510) loss: 5.8079 -- time: 4.3843 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 961.7650 - val_loss: 0.0000\n",
      "time: 81.4617 sec.\n",
      "time_left: 123.5502 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 110/200\n",
      "----------------------------------------------------------------------\n",
      "Step(19520) loss: 5.8405 -- time: 4.0165 sec.\n",
      "Step(19530) loss: 5.3751 -- time: 4.5010 sec.\n",
      "Step(19540) loss: 4.4353 -- time: 4.5303 sec.\n",
      "Step(19550) loss: 5.0283 -- time: 4.4271 sec.\n",
      "Step(19560) loss: 5.2580 -- time: 4.5096 sec.\n",
      "Step(19570) loss: 5.3905 -- time: 4.5330 sec.\n",
      "Step(19580) loss: 5.0546 -- time: 4.4041 sec.\n",
      "Step(19590) loss: 5.4880 -- time: 4.4705 sec.\n",
      "Step(19600) loss: 5.5733 -- time: 4.5734 sec.\n",
      "Step(19610) loss: 5.4081 -- time: 4.5243 sec.\n",
      "Step(19620) loss: 5.2901 -- time: 4.5157 sec.\n",
      "Step(19630) loss: 5.4894 -- time: 4.3616 sec.\n",
      "Step(19640) loss: 6.2106 -- time: 4.3888 sec.\n",
      "Step(19650) loss: 6.1173 -- time: 4.3474 sec.\n",
      "Step(19660) loss: 5.8533 -- time: 4.4613 sec.\n",
      "Step(19670) loss: 5.2070 -- time: 4.4828 sec.\n",
      "Step(19680) loss: 5.5571 -- time: 4.4932 sec.\n",
      "Step(19690) loss: 5.7775 -- time: 4.3179 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 982.3149 - val_loss: 987.2069\n",
      "time: 117.1749 sec.\n",
      "time_left: 175.7623 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 111/200\n",
      "----------------------------------------------------------------------\n",
      "Step(19700) loss: 6.0345 -- time: 4.4708 sec.\n",
      "Step(19710) loss: 5.4920 -- time: 4.5581 sec.\n",
      "Step(19720) loss: 5.8716 -- time: 4.6148 sec.\n",
      "Step(19730) loss: 5.5933 -- time: 4.5026 sec.\n",
      "Step(19740) loss: 5.2323 -- time: 4.5480 sec.\n",
      "Step(19750) loss: 5.9888 -- time: 4.6163 sec.\n",
      "Step(19760) loss: 5.6238 -- time: 4.5109 sec.\n",
      "Step(19770) loss: 5.1462 -- time: 4.5120 sec.\n",
      "Step(19780) loss: 5.4959 -- time: 4.5351 sec.\n",
      "Step(19790) loss: 5.2435 -- time: 4.4551 sec.\n",
      "Step(19800) loss: 5.3967 -- time: 4.5631 sec.\n",
      "Step(19810) loss: 5.7440 -- time: 4.4338 sec.\n",
      "Step(19820) loss: 5.1171 -- time: 4.6794 sec.\n",
      "Step(19830) loss: 5.2825 -- time: 4.5445 sec.\n",
      "Step(19840) loss: 5.4036 -- time: 4.7592 sec.\n",
      "Step(19850) loss: 5.3961 -- time: 4.5452 sec.\n",
      "Step(19860) loss: 5.1756 -- time: 4.4784 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 978.3997 - val_loss: 0.0000\n",
      "time: 83.1021 sec.\n",
      "time_left: 123.2682 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 112/200\n",
      "----------------------------------------------------------------------\n",
      "Step(19870) loss: 5.5256 -- time: 0.3100 sec.\n",
      "Step(19880) loss: 5.2982 -- time: 4.5436 sec.\n",
      "Step(19890) loss: 4.7412 -- time: 4.5843 sec.\n",
      "Step(19900) loss: 5.3724 -- time: 4.5362 sec.\n",
      "Step(19910) loss: 5.9773 -- time: 4.4692 sec.\n",
      "Step(19920) loss: 5.5637 -- time: 4.4969 sec.\n",
      "Step(19930) loss: 4.9317 -- time: 4.4970 sec.\n",
      "Step(19940) loss: 4.7821 -- time: 4.6687 sec.\n",
      "Step(19950) loss: 5.0974 -- time: 4.6109 sec.\n",
      "Step(19960) loss: 5.5834 -- time: 4.5286 sec.\n",
      "Step(19970) loss: 5.0309 -- time: 4.5963 sec.\n",
      "Step(19980) loss: 5.3304 -- time: 4.4992 sec.\n",
      "Step(19990) loss: 5.2297 -- time: 4.6305 sec.\n",
      "Step(20000) loss: 5.6331 -- time: 4.4936 sec.\n",
      "Step(20010) loss: 5.3570 -- time: 4.4739 sec.\n",
      "Step(20020) loss: 5.0973 -- time: 4.4222 sec.\n",
      "Step(20030) loss: 5.0662 -- time: 4.3777 sec.\n",
      "Step(20040) loss: 5.1388 -- time: 4.4350 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 955.3681 - val_loss: 0.0000\n",
      "time: 82.5561 sec.\n",
      "time_left: 121.0822 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 113/200\n",
      "----------------------------------------------------------------------\n",
      "Step(20050) loss: 5.2929 -- time: 0.8060 sec.\n",
      "Step(20060) loss: 5.4990 -- time: 4.4373 sec.\n",
      "Step(20070) loss: 5.5739 -- time: 4.5253 sec.\n",
      "Step(20080) loss: 5.2368 -- time: 4.4263 sec.\n",
      "Step(20090) loss: 5.3479 -- time: 4.5361 sec.\n",
      "Step(20100) loss: 5.5117 -- time: 4.3922 sec.\n",
      "Step(20110) loss: 5.1389 -- time: 4.4815 sec.\n",
      "Step(20120) loss: 5.4868 -- time: 4.5373 sec.\n",
      "Step(20130) loss: 5.2360 -- time: 4.4481 sec.\n",
      "Step(20140) loss: 5.2007 -- time: 4.5213 sec.\n",
      "Step(20150) loss: 5.3239 -- time: 4.5439 sec.\n",
      "Step(20160) loss: 5.5535 -- time: 4.5229 sec.\n",
      "Step(20170) loss: 5.5575 -- time: 4.5531 sec.\n",
      "Step(20180) loss: 5.6471 -- time: 4.3606 sec.\n",
      "Step(20190) loss: 5.0395 -- time: 4.5320 sec.\n",
      "Step(20200) loss: 5.6988 -- time: 4.3692 sec.\n",
      "Step(20210) loss: 4.8434 -- time: 4.3854 sec.\n",
      "Step(20220) loss: 5.0856 -- time: 4.3406 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 953.1982 - val_loss: 0.0000\n",
      "time: 81.6665 sec.\n",
      "time_left: 118.4164 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 114/200\n",
      "----------------------------------------------------------------------\n",
      "Step(20230) loss: 5.5114 -- time: 1.3180 sec.\n",
      "Step(20240) loss: 5.4680 -- time: 4.4859 sec.\n",
      "Step(20250) loss: 5.1833 -- time: 4.4096 sec.\n",
      "Step(20260) loss: 5.2573 -- time: 4.5599 sec.\n",
      "Step(20270) loss: 5.3120 -- time: 4.4344 sec.\n",
      "Step(20280) loss: 5.6878 -- time: 4.5202 sec.\n",
      "Step(20290) loss: 4.9820 -- time: 4.3725 sec.\n",
      "Step(20300) loss: 5.8596 -- time: 4.4425 sec.\n",
      "Step(20310) loss: 5.3679 -- time: 4.4661 sec.\n",
      "Step(20320) loss: 5.8357 -- time: 4.4910 sec.\n",
      "Step(20330) loss: 5.0272 -- time: 4.4843 sec.\n",
      "Step(20340) loss: 4.9956 -- time: 4.4731 sec.\n",
      "Step(20350) loss: 5.3021 -- time: 4.4012 sec.\n",
      "Step(20360) loss: 5.5762 -- time: 4.4138 sec.\n",
      "Step(20370) loss: 5.5676 -- time: 4.5111 sec.\n",
      "Step(20380) loss: 4.9054 -- time: 4.4533 sec.\n",
      "Step(20390) loss: 5.1783 -- time: 4.4769 sec.\n",
      "Step(20400) loss: 5.1026 -- time: 4.4250 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 951.3556 - val_loss: 0.0000\n",
      "time: 81.6141 sec.\n",
      "time_left: 116.9802 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 115/200\n",
      "----------------------------------------------------------------------\n",
      "Step(20410) loss: 5.6249 -- time: 1.7029 sec.\n",
      "Step(20420) loss: 5.6178 -- time: 4.5840 sec.\n",
      "Step(20430) loss: 5.1721 -- time: 4.4242 sec.\n",
      "Step(20440) loss: 4.4828 -- time: 4.4436 sec.\n",
      "Step(20450) loss: 5.0138 -- time: 4.3976 sec.\n",
      "Step(20460) loss: 5.1948 -- time: 4.4083 sec.\n",
      "Step(20470) loss: 5.6774 -- time: 4.4409 sec.\n",
      "Step(20480) loss: 4.9528 -- time: 4.4084 sec.\n",
      "Step(20490) loss: 5.4577 -- time: 4.5437 sec.\n",
      "Step(20500) loss: 5.2539 -- time: 4.4931 sec.\n",
      "Step(20510) loss: 5.1423 -- time: 4.4672 sec.\n",
      "Step(20520) loss: 4.9493 -- time: 4.4018 sec.\n",
      "Step(20530) loss: 5.6678 -- time: 4.6857 sec.\n",
      "Step(20540) loss: 5.2332 -- time: 4.4901 sec.\n",
      "Step(20550) loss: 5.3220 -- time: 4.5610 sec.\n",
      "Step(20560) loss: 5.4299 -- time: 4.4824 sec.\n",
      "Step(20570) loss: 5.2859 -- time: 4.4809 sec.\n",
      "Step(20580) loss: 5.4726 -- time: 4.5546 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 961.0878 - val_loss: 0.0000\n",
      "time: 82.0617 sec.\n",
      "time_left: 116.2541 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 116/200\n",
      "----------------------------------------------------------------------\n",
      "Step(20590) loss: 5.0824 -- time: 2.0854 sec.\n",
      "Step(20600) loss: 5.0398 -- time: 4.3846 sec.\n",
      "Step(20610) loss: 5.2670 -- time: 4.4112 sec.\n",
      "Step(20620) loss: 5.6807 -- time: 4.3757 sec.\n",
      "Step(20630) loss: 5.2386 -- time: 4.5633 sec.\n",
      "Step(20640) loss: 4.7544 -- time: 4.3249 sec.\n",
      "Step(20650) loss: 5.8980 -- time: 4.5212 sec.\n",
      "Step(20660) loss: 5.2598 -- time: 4.3617 sec.\n",
      "Step(20670) loss: 5.1170 -- time: 4.5160 sec.\n",
      "Step(20680) loss: 5.3117 -- time: 4.4742 sec.\n",
      "Step(20690) loss: 4.9668 -- time: 4.6153 sec.\n",
      "Step(20700) loss: 5.1545 -- time: 4.3985 sec.\n",
      "Step(20710) loss: 5.8103 -- time: 4.5001 sec.\n",
      "Step(20720) loss: 5.1147 -- time: 4.3938 sec.\n",
      "Step(20730) loss: 5.5772 -- time: 4.4909 sec.\n",
      "Step(20740) loss: 5.4095 -- time: 4.3439 sec.\n",
      "Step(20750) loss: 5.7498 -- time: 4.6191 sec.\n",
      "Step(20760) loss: 4.9205 -- time: 4.4545 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 957.3537 - val_loss: 0.0000\n",
      "time: 81.3962 sec.\n",
      "time_left: 113.9547 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 117/200\n",
      "----------------------------------------------------------------------\n",
      "Step(20770) loss: 5.1654 -- time: 2.7209 sec.\n",
      "Step(20780) loss: 5.3922 -- time: 4.4642 sec.\n",
      "Step(20790) loss: 5.1048 -- time: 4.3125 sec.\n",
      "Step(20800) loss: 5.5749 -- time: 4.3586 sec.\n",
      "Step(20810) loss: 5.0102 -- time: 4.4204 sec.\n",
      "Step(20820) loss: 5.7621 -- time: 4.5307 sec.\n",
      "Step(20830) loss: 5.4153 -- time: 4.4442 sec.\n",
      "Step(20840) loss: 4.9517 -- time: 4.4670 sec.\n",
      "Step(20850) loss: 5.2941 -- time: 4.4311 sec.\n",
      "Step(20860) loss: 4.8846 -- time: 4.5264 sec.\n",
      "Step(20870) loss: 5.0432 -- time: 4.5008 sec.\n",
      "Step(20880) loss: 5.2489 -- time: 4.5969 sec.\n",
      "Step(20890) loss: 5.0577 -- time: 4.3975 sec.\n",
      "Step(20900) loss: 5.1925 -- time: 4.4739 sec.\n",
      "Step(20910) loss: 5.7512 -- time: 4.3619 sec.\n",
      "Step(20920) loss: 5.2801 -- time: 4.5584 sec.\n",
      "Step(20930) loss: 5.0821 -- time: 4.4914 sec.\n",
      "Step(20940) loss: 5.2200 -- time: 4.6425 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 947.1693 - val_loss: 0.0000\n",
      "time: 81.7408 sec.\n",
      "time_left: 113.0748 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 118/200\n",
      "----------------------------------------------------------------------\n",
      "Step(20950) loss: 4.7459 -- time: 3.1486 sec.\n",
      "Step(20960) loss: 5.2655 -- time: 4.3672 sec.\n",
      "Step(20970) loss: 5.3361 -- time: 4.2929 sec.\n",
      "Step(20980) loss: 5.4783 -- time: 4.5603 sec.\n",
      "Step(20990) loss: 4.8604 -- time: 4.4254 sec.\n",
      "Step(21000) loss: 5.4208 -- time: 4.4977 sec.\n",
      "Step(21010) loss: 5.4904 -- time: 4.3508 sec.\n",
      "Step(21020) loss: 5.4221 -- time: 4.5300 sec.\n",
      "Step(21030) loss: 5.2587 -- time: 4.3566 sec.\n",
      "Step(21040) loss: 5.4187 -- time: 4.5299 sec.\n",
      "Step(21050) loss: 5.5969 -- time: 4.3643 sec.\n",
      "Step(21060) loss: 5.3747 -- time: 4.3807 sec.\n",
      "Step(21070) loss: 5.2872 -- time: 4.6170 sec.\n",
      "Step(21080) loss: 5.5456 -- time: 4.4214 sec.\n",
      "Step(21090) loss: 5.0730 -- time: 4.6028 sec.\n",
      "Step(21100) loss: 5.6037 -- time: 4.4402 sec.\n",
      "Step(21110) loss: 5.3358 -- time: 4.4405 sec.\n",
      "Step(21120) loss: 5.8467 -- time: 4.4452 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 954.3335 - val_loss: 0.0000\n",
      "time: 81.3759 sec.\n",
      "time_left: 111.2137 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 119/200\n",
      "----------------------------------------------------------------------\n",
      "Step(21130) loss: 5.0448 -- time: 3.6069 sec.\n",
      "Step(21140) loss: 5.5831 -- time: 4.3777 sec.\n",
      "Step(21150) loss: 5.4515 -- time: 4.4738 sec.\n",
      "Step(21160) loss: 5.3034 -- time: 4.5107 sec.\n",
      "Step(21170) loss: 4.8854 -- time: 4.3416 sec.\n",
      "Step(21180) loss: 5.7017 -- time: 4.5299 sec.\n",
      "Step(21190) loss: 5.5655 -- time: 4.3698 sec.\n",
      "Step(21200) loss: 5.5328 -- time: 4.4223 sec.\n",
      "Step(21210) loss: 5.6265 -- time: 4.3979 sec.\n",
      "Step(21220) loss: 5.5369 -- time: 4.3479 sec.\n",
      "Step(21230) loss: 5.3207 -- time: 4.4638 sec.\n",
      "Step(21240) loss: 5.1606 -- time: 4.4313 sec.\n",
      "Step(21250) loss: 5.3499 -- time: 4.4109 sec.\n",
      "Step(21260) loss: 5.4223 -- time: 4.4926 sec.\n",
      "Step(21270) loss: 5.2453 -- time: 4.3280 sec.\n",
      "Step(21280) loss: 5.5207 -- time: 4.4237 sec.\n",
      "Step(21290) loss: 5.7207 -- time: 4.5039 sec.\n",
      "Step(21300) loss: 5.6868 -- time: 4.5779 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.7013 - val_loss: 0.0000\n",
      "time: 81.1969 sec.\n",
      "time_left: 109.6159 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 120/200\n",
      "----------------------------------------------------------------------\n",
      "Step(21310) loss: 5.4761 -- time: 4.0555 sec.\n",
      "Step(21320) loss: 5.6062 -- time: 4.4441 sec.\n",
      "Step(21330) loss: 5.1197 -- time: 4.5336 sec.\n",
      "Step(21340) loss: 4.7703 -- time: 4.4391 sec.\n",
      "Step(21350) loss: 5.7631 -- time: 4.3898 sec.\n",
      "Step(21360) loss: 5.6594 -- time: 4.3685 sec.\n",
      "Step(21370) loss: 5.3673 -- time: 4.6114 sec.\n",
      "Step(21380) loss: 4.2804 -- time: 4.4164 sec.\n",
      "Step(21390) loss: 5.0666 -- time: 4.4476 sec.\n",
      "Step(21400) loss: 4.9838 -- time: 4.4740 sec.\n",
      "Step(21410) loss: 5.0820 -- time: 4.4311 sec.\n",
      "Step(21420) loss: 5.2807 -- time: 4.4585 sec.\n",
      "Step(21430) loss: 5.2391 -- time: 4.4524 sec.\n",
      "Step(21440) loss: 4.8325 -- time: 4.5881 sec.\n",
      "Step(21450) loss: 5.1230 -- time: 4.4880 sec.\n",
      "Step(21460) loss: 5.3980 -- time: 4.5485 sec.\n",
      "Step(21470) loss: 5.3937 -- time: 4.4431 sec.\n",
      "Step(21480) loss: 5.0599 -- time: 4.5457 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 954.1744 - val_loss: 959.1455\n",
      "time: 117.6295 sec.\n",
      "time_left: 156.8394 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 121/200\n",
      "----------------------------------------------------------------------\n",
      "Step(21490) loss: 5.1920 -- time: 4.6194 sec.\n",
      "Step(21500) loss: 5.5934 -- time: 4.5664 sec.\n",
      "Step(21510) loss: 5.3869 -- time: 4.8360 sec.\n",
      "Step(21520) loss: 5.8367 -- time: 4.5974 sec.\n",
      "Step(21530) loss: 5.1889 -- time: 4.6980 sec.\n",
      "Step(21540) loss: 5.0371 -- time: 4.4968 sec.\n",
      "Step(21550) loss: 5.0744 -- time: 4.3849 sec.\n",
      "Step(21560) loss: 4.8308 -- time: 4.4583 sec.\n",
      "Step(21570) loss: 5.2927 -- time: 4.5444 sec.\n",
      "Step(21580) loss: 5.5810 -- time: 4.5583 sec.\n",
      "Step(21590) loss: 5.4532 -- time: 4.5651 sec.\n",
      "Step(21600) loss: 5.0611 -- time: 4.4122 sec.\n",
      "Step(21610) loss: 5.5592 -- time: 4.5426 sec.\n",
      "Step(21620) loss: 5.2873 -- time: 4.5424 sec.\n",
      "Step(21630) loss: 5.9318 -- time: 4.5352 sec.\n",
      "Step(21640) loss: 5.4636 -- time: 4.4447 sec.\n",
      "Step(21650) loss: 5.3363 -- time: 4.4235 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.4727 - val_loss: 0.0000\n",
      "time: 82.8684 sec.\n",
      "time_left: 109.1101 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 122/200\n",
      "----------------------------------------------------------------------\n",
      "Step(21660) loss: 5.4897 -- time: 0.3508 sec.\n",
      "Step(21670) loss: 5.0327 -- time: 4.5738 sec.\n",
      "Step(21680) loss: 6.6238 -- time: 4.5121 sec.\n",
      "Step(21690) loss: 5.5429 -- time: 4.4818 sec.\n",
      "Step(21700) loss: 5.8639 -- time: 4.4457 sec.\n",
      "Step(21710) loss: 5.2702 -- time: 4.5056 sec.\n",
      "Step(21720) loss: 5.4591 -- time: 4.4929 sec.\n",
      "Step(21730) loss: 6.4603 -- time: 4.4522 sec.\n",
      "Step(21740) loss: 5.5031 -- time: 4.4781 sec.\n",
      "Step(21750) loss: 5.6526 -- time: 4.5286 sec.\n",
      "Step(21760) loss: 5.3014 -- time: 4.4114 sec.\n",
      "Step(21770) loss: 5.5624 -- time: 4.4820 sec.\n",
      "Step(21780) loss: 5.3250 -- time: 4.4897 sec.\n",
      "Step(21790) loss: 5.3634 -- time: 4.4434 sec.\n",
      "Step(21800) loss: 5.2158 -- time: 4.4345 sec.\n",
      "Step(21810) loss: 6.1247 -- time: 4.5985 sec.\n",
      "Step(21820) loss: 5.3149 -- time: 4.4526 sec.\n",
      "Step(21830) loss: 4.9786 -- time: 4.5732 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 989.5727 - val_loss: 0.0000\n",
      "time: 81.9821 sec.\n",
      "time_left: 106.5768 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 123/200\n",
      "----------------------------------------------------------------------\n",
      "Step(21840) loss: 5.0595 -- time: 0.8066 sec.\n",
      "Step(21850) loss: 5.5558 -- time: 4.4732 sec.\n",
      "Step(21860) loss: 5.3808 -- time: 4.4702 sec.\n",
      "Step(21870) loss: 4.8953 -- time: 4.4239 sec.\n",
      "Step(21880) loss: 5.9247 -- time: 4.3974 sec.\n",
      "Step(21890) loss: 6.0390 -- time: 4.5593 sec.\n",
      "Step(21900) loss: 5.1227 -- time: 4.4008 sec.\n",
      "Step(21910) loss: 5.5989 -- time: 4.4895 sec.\n",
      "Step(21920) loss: 5.5800 -- time: 4.4293 sec.\n",
      "Step(21930) loss: 5.3738 -- time: 4.4424 sec.\n",
      "Step(21940) loss: 5.6948 -- time: 4.3789 sec.\n",
      "Step(21950) loss: 5.3780 -- time: 4.4981 sec.\n",
      "Step(21960) loss: 5.7145 -- time: 4.3983 sec.\n",
      "Step(21970) loss: 5.8467 -- time: 4.5501 sec.\n",
      "Step(21980) loss: 4.9770 -- time: 4.4797 sec.\n",
      "Step(21990) loss: 5.6422 -- time: 4.4996 sec.\n",
      "Step(22000) loss: 5.8200 -- time: 4.5243 sec.\n",
      "Step(22010) loss: 4.9491 -- time: 4.4778 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 984.4246 - val_loss: 0.0000\n",
      "time: 81.5743 sec.\n",
      "time_left: 104.6870 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 124/200\n",
      "----------------------------------------------------------------------\n",
      "Step(22020) loss: 5.5712 -- time: 1.3347 sec.\n",
      "Step(22030) loss: 5.4098 -- time: 4.4978 sec.\n",
      "Step(22040) loss: 5.6009 -- time: 4.3459 sec.\n",
      "Step(22050) loss: 4.6441 -- time: 4.5920 sec.\n",
      "Step(22060) loss: 5.9394 -- time: 4.5386 sec.\n",
      "Step(22070) loss: 5.7414 -- time: 4.3329 sec.\n",
      "Step(22080) loss: 5.3986 -- time: 4.6186 sec.\n",
      "Step(22090) loss: 5.4437 -- time: 4.4407 sec.\n",
      "Step(22100) loss: 5.4767 -- time: 4.4397 sec.\n",
      "Step(22110) loss: 4.3651 -- time: 4.4796 sec.\n",
      "Step(22120) loss: 5.7061 -- time: 4.3785 sec.\n",
      "Step(22130) loss: 5.5564 -- time: 4.4407 sec.\n",
      "Step(22140) loss: 5.1561 -- time: 4.4145 sec.\n",
      "Step(22150) loss: 5.6048 -- time: 4.4529 sec.\n",
      "Step(22160) loss: 5.7385 -- time: 4.5774 sec.\n",
      "Step(22170) loss: 5.7358 -- time: 4.4659 sec.\n",
      "Step(22180) loss: 5.1107 -- time: 4.4566 sec.\n",
      "Step(22190) loss: 5.4889 -- time: 4.4753 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 967.2305 - val_loss: 0.0000\n",
      "time: 81.7158 sec.\n",
      "time_left: 103.5067 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 125/200\n",
      "----------------------------------------------------------------------\n",
      "Step(22200) loss: 5.6513 -- time: 1.7280 sec.\n",
      "Step(22210) loss: 4.8575 -- time: 4.4900 sec.\n",
      "Step(22220) loss: 5.8413 -- time: 4.4129 sec.\n",
      "Step(22230) loss: 5.6118 -- time: 4.3593 sec.\n",
      "Step(22240) loss: 5.2282 -- time: 4.4987 sec.\n",
      "Step(22250) loss: 5.0672 -- time: 4.5185 sec.\n",
      "Step(22260) loss: 5.3967 -- time: 4.5950 sec.\n",
      "Step(22270) loss: 5.4793 -- time: 4.4885 sec.\n",
      "Step(22280) loss: 4.7759 -- time: 4.4703 sec.\n",
      "Step(22290) loss: 5.4982 -- time: 4.5013 sec.\n",
      "Step(22300) loss: 5.0745 -- time: 4.5001 sec.\n",
      "Step(22310) loss: 5.6711 -- time: 4.4608 sec.\n",
      "Step(22320) loss: 5.7653 -- time: 4.5241 sec.\n",
      "Step(22330) loss: 5.4936 -- time: 4.5911 sec.\n",
      "Step(22340) loss: 5.1867 -- time: 4.3852 sec.\n",
      "Step(22350) loss: 5.1762 -- time: 4.5736 sec.\n",
      "Step(22360) loss: 5.5151 -- time: 4.5409 sec.\n",
      "Step(22370) loss: 4.9056 -- time: 4.4067 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 958.0638 - val_loss: 0.0000\n",
      "time: 81.9683 sec.\n",
      "time_left: 102.4604 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 126/200\n",
      "----------------------------------------------------------------------\n",
      "Step(22380) loss: 5.2410 -- time: 2.1501 sec.\n",
      "Step(22390) loss: 5.4924 -- time: 4.4553 sec.\n",
      "Step(22400) loss: 5.7264 -- time: 4.4451 sec.\n",
      "Step(22410) loss: 5.0218 -- time: 4.5128 sec.\n",
      "Step(22420) loss: 4.8087 -- time: 4.5473 sec.\n",
      "Step(22430) loss: 4.9722 -- time: 4.4562 sec.\n",
      "Step(22440) loss: 4.9712 -- time: 4.5205 sec.\n",
      "Step(22450) loss: 5.3077 -- time: 4.6423 sec.\n",
      "Step(22460) loss: 5.2787 -- time: 4.5671 sec.\n",
      "Step(22470) loss: 5.6186 -- time: 4.5936 sec.\n",
      "Step(22480) loss: 6.1128 -- time: 4.5201 sec.\n",
      "Step(22490) loss: 5.1974 -- time: 4.4535 sec.\n",
      "Step(22500) loss: 5.1455 -- time: 4.4741 sec.\n",
      "Step(22510) loss: 5.6384 -- time: 4.4950 sec.\n",
      "Step(22520) loss: 5.5102 -- time: 4.4751 sec.\n",
      "Step(22530) loss: 5.5430 -- time: 4.4860 sec.\n",
      "Step(22540) loss: 5.6253 -- time: 4.5075 sec.\n",
      "Step(22550) loss: 5.5203 -- time: 4.5316 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 963.6438 - val_loss: 0.0000\n",
      "time: 82.4228 sec.\n",
      "time_left: 101.6548 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 127/200\n",
      "----------------------------------------------------------------------\n",
      "Step(22560) loss: 5.9412 -- time: 2.6572 sec.\n",
      "Step(22570) loss: 5.2816 -- time: 4.3209 sec.\n",
      "Step(22580) loss: 5.1590 -- time: 4.5554 sec.\n",
      "Step(22590) loss: 5.1066 -- time: 4.4842 sec.\n",
      "Step(22600) loss: 5.6070 -- time: 4.3021 sec.\n",
      "Step(22610) loss: 5.3170 -- time: 4.3636 sec.\n",
      "Step(22620) loss: 5.1727 -- time: 4.4189 sec.\n",
      "Step(22630) loss: 5.0567 -- time: 4.4079 sec.\n",
      "Step(22640) loss: 5.3284 -- time: 4.4175 sec.\n",
      "Step(22650) loss: 5.7681 -- time: 4.5379 sec.\n",
      "Step(22660) loss: 5.0822 -- time: 4.5082 sec.\n",
      "Step(22670) loss: 5.5083 -- time: 4.2656 sec.\n",
      "Step(22680) loss: 6.1661 -- time: 4.4883 sec.\n",
      "Step(22690) loss: 6.0542 -- time: 4.3074 sec.\n",
      "Step(22700) loss: 5.5511 -- time: 4.4206 sec.\n",
      "Step(22710) loss: 4.9236 -- time: 4.5972 sec.\n",
      "Step(22720) loss: 5.4311 -- time: 4.5115 sec.\n",
      "Step(22730) loss: 5.7956 -- time: 4.5607 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 968.9591 - val_loss: 0.0000\n",
      "time: 81.3031 sec.\n",
      "time_left: 98.9187 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 128/200\n",
      "----------------------------------------------------------------------\n",
      "Step(22740) loss: 5.4974 -- time: 3.0160 sec.\n",
      "Step(22750) loss: 5.4809 -- time: 4.4696 sec.\n",
      "Step(22760) loss: 5.4322 -- time: 4.4797 sec.\n",
      "Step(22770) loss: 5.1984 -- time: 4.3420 sec.\n",
      "Step(22780) loss: 5.2832 -- time: 4.3391 sec.\n",
      "Step(22790) loss: 5.1645 -- time: 4.5206 sec.\n",
      "Step(22800) loss: 5.7088 -- time: 4.4015 sec.\n",
      "Step(22810) loss: 5.4613 -- time: 4.5283 sec.\n",
      "Step(22820) loss: 5.7201 -- time: 4.3737 sec.\n",
      "Step(22830) loss: 5.4234 -- time: 4.3992 sec.\n",
      "Step(22840) loss: 5.4883 -- time: 4.3196 sec.\n",
      "Step(22850) loss: 5.5166 -- time: 4.6102 sec.\n",
      "Step(22860) loss: 5.4719 -- time: 4.3787 sec.\n",
      "Step(22870) loss: 5.2026 -- time: 4.4277 sec.\n",
      "Step(22880) loss: 5.6032 -- time: 4.3570 sec.\n",
      "Step(22890) loss: 5.0550 -- time: 4.4966 sec.\n",
      "Step(22900) loss: 5.1618 -- time: 4.5486 sec.\n",
      "Step(22910) loss: 5.2358 -- time: 4.2461 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 964.9333 - val_loss: 0.0000\n",
      "time: 80.8865 sec.\n",
      "time_left: 97.0638 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 129/200\n",
      "----------------------------------------------------------------------\n",
      "Step(22920) loss: 5.4056 -- time: 3.6202 sec.\n",
      "Step(22930) loss: 5.6128 -- time: 4.6376 sec.\n",
      "Step(22940) loss: 5.5057 -- time: 4.4149 sec.\n",
      "Step(22950) loss: 5.4299 -- time: 4.5834 sec.\n",
      "Step(22960) loss: 5.4436 -- time: 4.6951 sec.\n",
      "Step(22970) loss: 4.9527 -- time: 4.4825 sec.\n",
      "Step(22980) loss: 5.2722 -- time: 4.5529 sec.\n",
      "Step(22990) loss: 6.1302 -- time: 4.3678 sec.\n",
      "Step(23000) loss: 5.1534 -- time: 4.3447 sec.\n",
      "Step(23010) loss: 5.2071 -- time: 4.4595 sec.\n",
      "Step(23020) loss: 5.5975 -- time: 4.4855 sec.\n",
      "Step(23030) loss: 5.5711 -- time: 4.4355 sec.\n",
      "Step(23040) loss: 5.4509 -- time: 4.4416 sec.\n",
      "Step(23050) loss: 5.8634 -- time: 4.4478 sec.\n",
      "Step(23060) loss: 5.1855 -- time: 4.5187 sec.\n",
      "Step(23070) loss: 5.1981 -- time: 4.3894 sec.\n",
      "Step(23080) loss: 5.0753 -- time: 4.5991 sec.\n",
      "Step(23090) loss: 5.0574 -- time: 4.3716 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 962.0331 - val_loss: 0.0000\n",
      "time: 82.0506 sec.\n",
      "time_left: 97.0932 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 130/200\n",
      "----------------------------------------------------------------------\n",
      "Step(23100) loss: 5.6884 -- time: 3.8349 sec.\n",
      "Step(23110) loss: 5.0681 -- time: 4.5852 sec.\n",
      "Step(23120) loss: 4.9124 -- time: 4.4896 sec.\n",
      "Step(23130) loss: 5.3333 -- time: 4.3560 sec.\n",
      "Step(23140) loss: 5.3824 -- time: 4.6438 sec.\n",
      "Step(23150) loss: 4.9052 -- time: 4.4684 sec.\n",
      "Step(23160) loss: 5.4281 -- time: 4.3528 sec.\n",
      "Step(23170) loss: 4.8945 -- time: 4.4256 sec.\n",
      "Step(23180) loss: 5.2978 -- time: 4.4237 sec.\n",
      "Step(23190) loss: 5.6210 -- time: 4.4505 sec.\n",
      "Step(23200) loss: 5.1865 -- time: 4.4543 sec.\n",
      "Step(23210) loss: 5.3181 -- time: 4.4983 sec.\n",
      "Step(23220) loss: 5.2661 -- time: 4.4452 sec.\n",
      "Step(23230) loss: 5.9994 -- time: 4.5715 sec.\n",
      "Step(23240) loss: 4.8803 -- time: 4.4964 sec.\n",
      "Step(23250) loss: 5.4941 -- time: 4.5038 sec.\n",
      "Step(23260) loss: 5.2778 -- time: 4.4402 sec.\n",
      "Step(23270) loss: 5.3942 -- time: 4.3276 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 954.1194 - val_loss: 975.6905\n",
      "time: 117.1490 sec.\n",
      "time_left: 136.6738 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 131/200\n",
      "----------------------------------------------------------------------\n",
      "Step(23280) loss: 5.4535 -- time: 4.6856 sec.\n",
      "Step(23290) loss: 5.2900 -- time: 4.6234 sec.\n",
      "Step(23300) loss: 5.5374 -- time: 4.6251 sec.\n",
      "Step(23310) loss: 5.4939 -- time: 4.6452 sec.\n",
      "Step(23320) loss: 5.0892 -- time: 4.5168 sec.\n",
      "Step(23330) loss: 5.3399 -- time: 4.6357 sec.\n",
      "Step(23340) loss: 5.3401 -- time: 4.6239 sec.\n",
      "Step(23350) loss: 4.8756 -- time: 4.5650 sec.\n",
      "Step(23360) loss: 5.3117 -- time: 4.6477 sec.\n",
      "Step(23370) loss: 5.2158 -- time: 4.5060 sec.\n",
      "Step(23380) loss: 5.6317 -- time: 4.3793 sec.\n",
      "Step(23390) loss: 5.6130 -- time: 4.4737 sec.\n",
      "Step(23400) loss: 4.8123 -- time: 4.3619 sec.\n",
      "Step(23410) loss: 5.7130 -- time: 4.3888 sec.\n",
      "Step(23420) loss: 5.3430 -- time: 4.3955 sec.\n",
      "Step(23430) loss: 5.2416 -- time: 4.5133 sec.\n",
      "Step(23440) loss: 5.2665 -- time: 4.4351 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 963.2637 - val_loss: 0.0000\n",
      "time: 82.7365 sec.\n",
      "time_left: 95.1470 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 132/200\n",
      "----------------------------------------------------------------------\n",
      "Step(23450) loss: 5.7770 -- time: 0.3781 sec.\n",
      "Step(23460) loss: 4.9091 -- time: 4.4211 sec.\n",
      "Step(23470) loss: 5.4495 -- time: 4.3956 sec.\n",
      "Step(23480) loss: 5.7611 -- time: 4.3839 sec.\n",
      "Step(23490) loss: 5.2321 -- time: 4.4907 sec.\n",
      "Step(23500) loss: 5.6379 -- time: 4.6030 sec.\n",
      "Step(23510) loss: 5.5354 -- time: 4.4667 sec.\n",
      "Step(23520) loss: 5.5794 -- time: 4.4947 sec.\n",
      "Step(23530) loss: 5.7305 -- time: 4.4692 sec.\n",
      "Step(23540) loss: 5.8357 -- time: 4.5283 sec.\n",
      "Step(23550) loss: 5.3574 -- time: 4.5906 sec.\n",
      "Step(23560) loss: 4.9149 -- time: 4.4471 sec.\n",
      "Step(23570) loss: 5.6663 -- time: 4.5008 sec.\n",
      "Step(23580) loss: 4.7165 -- time: 4.5377 sec.\n",
      "Step(23590) loss: 5.5085 -- time: 4.5297 sec.\n",
      "Step(23600) loss: 5.3948 -- time: 4.6038 sec.\n",
      "Step(23610) loss: 5.6259 -- time: 4.4749 sec.\n",
      "Step(23620) loss: 5.0528 -- time: 4.3111 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 976.6560 - val_loss: 0.0000\n",
      "time: 81.9429 sec.\n",
      "time_left: 92.8687 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 133/200\n",
      "----------------------------------------------------------------------\n",
      "Step(23630) loss: 5.6556 -- time: 0.7821 sec.\n",
      "Step(23640) loss: 5.0140 -- time: 4.4951 sec.\n",
      "Step(23650) loss: 5.1890 -- time: 4.5107 sec.\n",
      "Step(23660) loss: 5.6134 -- time: 4.4808 sec.\n",
      "Step(23670) loss: 5.6401 -- time: 4.4833 sec.\n",
      "Step(23680) loss: 5.3803 -- time: 4.3733 sec.\n",
      "Step(23690) loss: 5.7929 -- time: 4.3506 sec.\n",
      "Step(23700) loss: 5.4490 -- time: 4.4299 sec.\n",
      "Step(23710) loss: 6.0164 -- time: 4.5357 sec.\n",
      "Step(23720) loss: 5.2419 -- time: 4.4120 sec.\n",
      "Step(23730) loss: 5.4964 -- time: 4.5280 sec.\n",
      "Step(23740) loss: 5.1353 -- time: 4.4657 sec.\n",
      "Step(23750) loss: 5.3960 -- time: 4.4335 sec.\n",
      "Step(23760) loss: 5.5048 -- time: 4.4963 sec.\n",
      "Step(23770) loss: 5.5700 -- time: 4.3983 sec.\n",
      "Step(23780) loss: 5.3398 -- time: 4.3874 sec.\n",
      "Step(23790) loss: 6.2300 -- time: 4.5662 sec.\n",
      "Step(23800) loss: 5.8425 -- time: 4.4188 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 979.0889 - val_loss: 0.0000\n",
      "time: 81.4825 sec.\n",
      "time_left: 90.9888 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 134/200\n",
      "----------------------------------------------------------------------\n",
      "Step(23810) loss: 5.3343 -- time: 1.2030 sec.\n",
      "Step(23820) loss: 5.1668 -- time: 4.5452 sec.\n",
      "Step(23830) loss: 5.7011 -- time: 4.4943 sec.\n",
      "Step(23840) loss: 5.1381 -- time: 4.5074 sec.\n",
      "Step(23850) loss: 5.3730 -- time: 4.4203 sec.\n",
      "Step(23860) loss: 5.2728 -- time: 4.4415 sec.\n",
      "Step(23870) loss: 5.3893 -- time: 4.4353 sec.\n",
      "Step(23880) loss: 5.0521 -- time: 4.3983 sec.\n",
      "Step(23890) loss: 5.8736 -- time: 4.5764 sec.\n",
      "Step(23900) loss: 5.1121 -- time: 4.3941 sec.\n",
      "Step(23910) loss: 5.0612 -- time: 4.4289 sec.\n",
      "Step(23920) loss: 5.6082 -- time: 4.4072 sec.\n",
      "Step(23930) loss: 5.4522 -- time: 4.3979 sec.\n",
      "Step(23940) loss: 4.6734 -- time: 4.3968 sec.\n",
      "Step(23950) loss: 5.4265 -- time: 4.4851 sec.\n",
      "Step(23960) loss: 5.3378 -- time: 4.6024 sec.\n",
      "Step(23970) loss: 5.9674 -- time: 4.5054 sec.\n",
      "Step(23980) loss: 4.9289 -- time: 4.4420 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 968.3555 - val_loss: 0.0000\n",
      "time: 81.6441 sec.\n",
      "time_left: 89.8085 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 135/200\n",
      "----------------------------------------------------------------------\n",
      "Step(23990) loss: 5.4923 -- time: 1.7083 sec.\n",
      "Step(24000) loss: 5.1903 -- time: 4.4247 sec.\n",
      "Step(24010) loss: 4.8943 -- time: 4.4419 sec.\n",
      "Step(24020) loss: 5.3938 -- time: 4.4745 sec.\n",
      "Step(24030) loss: 5.2877 -- time: 4.3426 sec.\n",
      "Step(24040) loss: 5.4191 -- time: 4.4517 sec.\n",
      "Step(24050) loss: 5.9228 -- time: 4.4053 sec.\n",
      "Step(24060) loss: 5.2410 -- time: 4.4043 sec.\n",
      "Step(24070) loss: 5.0144 -- time: 4.5952 sec.\n",
      "Step(24080) loss: 5.7077 -- time: 4.4967 sec.\n",
      "Step(24090) loss: 5.2101 -- time: 4.5880 sec.\n",
      "Step(24100) loss: 5.5179 -- time: 4.4714 sec.\n",
      "Step(24110) loss: 5.1682 -- time: 4.4403 sec.\n",
      "Step(24120) loss: 6.3290 -- time: 4.4802 sec.\n",
      "Step(24130) loss: 5.0605 -- time: 4.4030 sec.\n",
      "Step(24140) loss: 4.7950 -- time: 4.4106 sec.\n",
      "Step(24150) loss: 5.0530 -- time: 4.2309 sec.\n",
      "Step(24160) loss: 4.8807 -- time: 4.3834 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 965.0639 - val_loss: 0.0000\n",
      "time: 81.1668 sec.\n",
      "time_left: 87.9307 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 136/200\n",
      "----------------------------------------------------------------------\n",
      "Step(24170) loss: 4.9380 -- time: 2.2966 sec.\n",
      "Step(24180) loss: 5.4447 -- time: 4.5070 sec.\n",
      "Step(24190) loss: 4.8982 -- time: 4.5123 sec.\n",
      "Step(24200) loss: 5.2827 -- time: 4.4959 sec.\n",
      "Step(24210) loss: 4.7693 -- time: 4.5160 sec.\n",
      "Step(24220) loss: 5.2787 -- time: 4.3690 sec.\n",
      "Step(24230) loss: 5.2999 -- time: 4.4621 sec.\n",
      "Step(24240) loss: 5.6607 -- time: 4.5903 sec.\n",
      "Step(24250) loss: 5.9576 -- time: 4.4777 sec.\n",
      "Step(24260) loss: 5.3682 -- time: 4.4028 sec.\n",
      "Step(24270) loss: 5.2681 -- time: 4.3738 sec.\n",
      "Step(24280) loss: 5.6903 -- time: 4.5135 sec.\n",
      "Step(24290) loss: 5.4965 -- time: 4.4877 sec.\n",
      "Step(24300) loss: 5.6826 -- time: 4.6223 sec.\n",
      "Step(24310) loss: 5.7262 -- time: 4.5893 sec.\n",
      "Step(24320) loss: 4.7644 -- time: 4.5186 sec.\n",
      "Step(24330) loss: 5.7184 -- time: 4.4693 sec.\n",
      "Step(24340) loss: 5.6055 -- time: 4.5677 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 955.7042 - val_loss: 0.0000\n",
      "time: 82.3824 sec.\n",
      "time_left: 87.8745 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 137/200\n",
      "----------------------------------------------------------------------\n",
      "Step(24350) loss: 5.1188 -- time: 2.7304 sec.\n",
      "Step(24360) loss: 5.4810 -- time: 4.4963 sec.\n",
      "Step(24370) loss: 4.9448 -- time: 4.4978 sec.\n",
      "Step(24380) loss: 5.3857 -- time: 4.4513 sec.\n",
      "Step(24390) loss: 5.5238 -- time: 4.4796 sec.\n",
      "Step(24400) loss: 5.3771 -- time: 4.4829 sec.\n",
      "Step(24410) loss: 5.4290 -- time: 4.4815 sec.\n",
      "Step(24420) loss: 5.9098 -- time: 4.4059 sec.\n",
      "Step(24430) loss: 5.3802 -- time: 4.4502 sec.\n",
      "Step(24440) loss: 5.2225 -- time: 4.5758 sec.\n",
      "Step(24450) loss: 5.7756 -- time: 4.5271 sec.\n",
      "Step(24460) loss: 5.6311 -- time: 4.4778 sec.\n",
      "Step(24470) loss: 5.7538 -- time: 4.3488 sec.\n",
      "Step(24480) loss: 5.4872 -- time: 4.3194 sec.\n",
      "Step(24490) loss: 5.2724 -- time: 4.2369 sec.\n",
      "Step(24500) loss: 5.2805 -- time: 4.4766 sec.\n",
      "Step(24510) loss: 5.5597 -- time: 4.5624 sec.\n",
      "Step(24520) loss: 5.5408 -- time: 4.5712 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 962.3541 - val_loss: 0.0000\n",
      "time: 81.6765 sec.\n",
      "time_left: 85.7603 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 138/200\n",
      "----------------------------------------------------------------------\n",
      "Step(24530) loss: 5.4756 -- time: 3.1175 sec.\n",
      "Step(24540) loss: 5.9481 -- time: 4.4739 sec.\n",
      "Step(24550) loss: 5.6415 -- time: 4.5552 sec.\n",
      "Step(24560) loss: 5.7914 -- time: 4.4015 sec.\n",
      "Step(24570) loss: 5.3734 -- time: 4.3816 sec.\n",
      "Step(24580) loss: 4.9437 -- time: 4.4729 sec.\n",
      "Step(24590) loss: 5.2730 -- time: 4.4420 sec.\n",
      "Step(24600) loss: 5.3821 -- time: 4.4833 sec.\n",
      "Step(24610) loss: 5.2258 -- time: 4.4825 sec.\n",
      "Step(24620) loss: 5.5128 -- time: 4.4284 sec.\n",
      "Step(24630) loss: 5.5859 -- time: 4.5458 sec.\n",
      "Step(24640) loss: 5.5336 -- time: 4.5280 sec.\n",
      "Step(24650) loss: 5.5188 -- time: 4.5230 sec.\n",
      "Step(24660) loss: 5.2510 -- time: 4.5249 sec.\n",
      "Step(24670) loss: 5.4081 -- time: 4.4946 sec.\n",
      "Step(24680) loss: 5.3406 -- time: 4.4149 sec.\n",
      "Step(24690) loss: 5.5590 -- time: 4.5471 sec.\n",
      "Step(24700) loss: 5.4188 -- time: 4.4694 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 961.7389 - val_loss: 0.0000\n",
      "time: 81.9392 sec.\n",
      "time_left: 84.6705 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 139/200\n",
      "----------------------------------------------------------------------\n",
      "Step(24710) loss: 5.3649 -- time: 3.5115 sec.\n",
      "Step(24720) loss: 5.4614 -- time: 4.3522 sec.\n",
      "Step(24730) loss: 5.1066 -- time: 4.4708 sec.\n",
      "Step(24740) loss: 5.6952 -- time: 4.5215 sec.\n",
      "Step(24750) loss: 5.9407 -- time: 4.4791 sec.\n",
      "Step(24760) loss: 6.0765 -- time: 4.3494 sec.\n",
      "Step(24770) loss: 5.6678 -- time: 4.4922 sec.\n",
      "Step(24780) loss: 4.8759 -- time: 4.4521 sec.\n",
      "Step(24790) loss: 5.2071 -- time: 4.3124 sec.\n",
      "Step(24800) loss: 5.6801 -- time: 4.5130 sec.\n",
      "Step(24810) loss: 5.4964 -- time: 4.3945 sec.\n",
      "Step(24820) loss: 5.4292 -- time: 4.4262 sec.\n",
      "Step(24830) loss: 5.2477 -- time: 4.3822 sec.\n",
      "Step(24840) loss: 5.0112 -- time: 4.3990 sec.\n",
      "Step(24850) loss: 5.1115 -- time: 4.4639 sec.\n",
      "Step(24860) loss: 5.2524 -- time: 4.5779 sec.\n",
      "Step(24870) loss: 5.1383 -- time: 4.3994 sec.\n",
      "Step(24880) loss: 5.7094 -- time: 4.4876 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 960.6214 - val_loss: 0.0000\n",
      "time: 81.1733 sec.\n",
      "time_left: 82.5262 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 140/200\n",
      "----------------------------------------------------------------------\n",
      "Step(24890) loss: 5.5457 -- time: 3.9602 sec.\n",
      "Step(24900) loss: 5.0542 -- time: 4.4890 sec.\n",
      "Step(24910) loss: 4.6889 -- time: 4.3746 sec.\n",
      "Step(24920) loss: 5.5339 -- time: 4.3899 sec.\n",
      "Step(24930) loss: 4.9319 -- time: 4.6135 sec.\n",
      "Step(24940) loss: 5.2435 -- time: 4.4151 sec.\n",
      "Step(24950) loss: 5.2462 -- time: 4.5549 sec.\n",
      "Step(24960) loss: 5.3419 -- time: 4.3657 sec.\n",
      "Step(24970) loss: 4.9078 -- time: 4.5182 sec.\n",
      "Step(24980) loss: 5.0677 -- time: 4.4737 sec.\n",
      "Step(24990) loss: 5.0783 -- time: 4.4564 sec.\n",
      "Step(25000) loss: 5.9160 -- time: 4.5540 sec.\n",
      "Step(25010) loss: 4.9127 -- time: 4.4200 sec.\n",
      "Step(25020) loss: 5.9222 -- time: 4.5753 sec.\n",
      "Step(25030) loss: 5.2943 -- time: 4.4436 sec.\n",
      "Step(25040) loss: 4.8818 -- time: 4.4680 sec.\n",
      "Step(25050) loss: 4.8888 -- time: 4.5261 sec.\n",
      "Step(25060) loss: 5.0303 -- time: 4.3585 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 961.6106 - val_loss: 965.6420\n",
      "time: 117.3241 sec.\n",
      "time_left: 117.3241 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 141/200\n",
      "----------------------------------------------------------------------\n",
      "Step(25070) loss: 5.4893 -- time: 4.5201 sec.\n",
      "Step(25080) loss: 5.2810 -- time: 4.6136 sec.\n",
      "Step(25090) loss: 5.2394 -- time: 4.5173 sec.\n",
      "Step(25100) loss: 5.1548 -- time: 4.4573 sec.\n",
      "Step(25110) loss: 5.1377 -- time: 4.6496 sec.\n",
      "Step(25120) loss: 5.4321 -- time: 4.4160 sec.\n",
      "Step(25130) loss: 5.3696 -- time: 4.5317 sec.\n",
      "Step(25140) loss: 4.9703 -- time: 4.5749 sec.\n",
      "Step(25150) loss: 5.1083 -- time: 4.6463 sec.\n",
      "Step(25160) loss: 5.4146 -- time: 4.4090 sec.\n",
      "Step(25170) loss: 4.7232 -- time: 4.4909 sec.\n",
      "Step(25180) loss: 5.1038 -- time: 4.5148 sec.\n",
      "Step(25190) loss: 5.6466 -- time: 4.4854 sec.\n",
      "Step(25200) loss: 5.6266 -- time: 4.4553 sec.\n",
      "Step(25210) loss: 5.2660 -- time: 4.4653 sec.\n",
      "Step(25220) loss: 4.9467 -- time: 4.5450 sec.\n",
      "Step(25230) loss: 5.3476 -- time: 4.5051 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 965.7888 - val_loss: 0.0000\n",
      "time: 82.4506 sec.\n",
      "time_left: 81.0764 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 142/200\n",
      "----------------------------------------------------------------------\n",
      "Step(25240) loss: 5.3527 -- time: 0.3403 sec.\n",
      "Step(25250) loss: 5.6129 -- time: 4.5145 sec.\n",
      "Step(25260) loss: 5.9550 -- time: 4.4189 sec.\n",
      "Step(25270) loss: 5.1976 -- time: 4.5459 sec.\n",
      "Step(25280) loss: 5.6132 -- time: 4.4496 sec.\n",
      "Step(25290) loss: 4.9563 -- time: 4.4945 sec.\n",
      "Step(25300) loss: 5.4350 -- time: 4.4778 sec.\n",
      "Step(25310) loss: 5.3654 -- time: 4.4865 sec.\n",
      "Step(25320) loss: 5.8545 -- time: 4.4670 sec.\n",
      "Step(25330) loss: 5.7079 -- time: 4.3936 sec.\n",
      "Step(25340) loss: 5.6507 -- time: 4.4989 sec.\n",
      "Step(25350) loss: 5.5625 -- time: 4.3431 sec.\n",
      "Step(25360) loss: 5.9454 -- time: 4.3822 sec.\n",
      "Step(25370) loss: 5.2788 -- time: 4.5056 sec.\n",
      "Step(25380) loss: 5.1377 -- time: 4.3247 sec.\n",
      "Step(25390) loss: 5.6411 -- time: 4.4916 sec.\n",
      "Step(25400) loss: 5.2745 -- time: 4.4418 sec.\n",
      "Step(25410) loss: 5.2851 -- time: 4.4757 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 973.6228 - val_loss: 0.0000\n",
      "time: 81.4671 sec.\n",
      "time_left: 78.7515 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 143/200\n",
      "----------------------------------------------------------------------\n",
      "Step(25420) loss: 5.5191 -- time: 0.7688 sec.\n",
      "Step(25430) loss: 5.8718 -- time: 4.4330 sec.\n",
      "Step(25440) loss: 4.9314 -- time: 4.4476 sec.\n",
      "Step(25450) loss: 5.2266 -- time: 4.3893 sec.\n",
      "Step(25460) loss: 5.1640 -- time: 4.4329 sec.\n",
      "Step(25470) loss: 5.2229 -- time: 4.4430 sec.\n",
      "Step(25480) loss: 5.5406 -- time: 4.4732 sec.\n",
      "Step(25490) loss: 5.2969 -- time: 4.4413 sec.\n",
      "Step(25500) loss: 5.1724 -- time: 4.4209 sec.\n",
      "Step(25510) loss: 4.7190 -- time: 4.4643 sec.\n",
      "Step(25520) loss: 5.9441 -- time: 4.4557 sec.\n",
      "Step(25530) loss: 5.0938 -- time: 4.5345 sec.\n",
      "Step(25540) loss: 5.5420 -- time: 4.5175 sec.\n",
      "Step(25550) loss: 5.5127 -- time: 4.5009 sec.\n",
      "Step(25560) loss: 4.8125 -- time: 4.4963 sec.\n",
      "Step(25570) loss: 5.4574 -- time: 4.2550 sec.\n",
      "Step(25580) loss: 5.3471 -- time: 4.4722 sec.\n",
      "Step(25590) loss: 5.8839 -- time: 4.4571 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 968.9484 - val_loss: 0.0000\n",
      "time: 81.3156 sec.\n",
      "time_left: 77.2498 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 144/200\n",
      "----------------------------------------------------------------------\n",
      "Step(25600) loss: 5.9462 -- time: 1.3752 sec.\n",
      "Step(25610) loss: 5.4003 -- time: 4.6453 sec.\n",
      "Step(25620) loss: 5.3645 -- time: 4.4957 sec.\n",
      "Step(25630) loss: 5.4460 -- time: 4.5302 sec.\n",
      "Step(25640) loss: 5.4080 -- time: 4.4996 sec.\n",
      "Step(25650) loss: 5.9463 -- time: 4.4666 sec.\n",
      "Step(25660) loss: 5.6465 -- time: 4.5007 sec.\n",
      "Step(25670) loss: 5.3734 -- time: 4.4280 sec.\n",
      "Step(25680) loss: 5.2013 -- time: 4.3965 sec.\n",
      "Step(25690) loss: 5.6826 -- time: 4.5009 sec.\n",
      "Step(25700) loss: 5.9534 -- time: 4.5671 sec.\n",
      "Step(25710) loss: 5.5338 -- time: 4.5041 sec.\n",
      "Step(25720) loss: 5.1116 -- time: 4.5575 sec.\n",
      "Step(25730) loss: 5.8531 -- time: 4.4722 sec.\n",
      "Step(25740) loss: 5.4755 -- time: 4.5073 sec.\n",
      "Step(25750) loss: 5.7738 -- time: 4.6178 sec.\n",
      "Step(25760) loss: 5.5391 -- time: 4.4701 sec.\n",
      "Step(25770) loss: 5.7259 -- time: 4.4768 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 980.1701 - val_loss: 0.0000\n",
      "time: 82.4351 sec.\n",
      "time_left: 76.9394 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 145/200\n",
      "----------------------------------------------------------------------\n",
      "Step(25780) loss: 5.3096 -- time: 1.7806 sec.\n",
      "Step(25790) loss: 5.2253 -- time: 4.4540 sec.\n",
      "Step(25800) loss: 5.2030 -- time: 4.3729 sec.\n",
      "Step(25810) loss: 6.2530 -- time: 4.4400 sec.\n",
      "Step(25820) loss: 5.2067 -- time: 4.5031 sec.\n",
      "Step(25830) loss: 5.3599 -- time: 4.4619 sec.\n",
      "Step(25840) loss: 5.4382 -- time: 4.5011 sec.\n",
      "Step(25850) loss: 5.6039 -- time: 4.4641 sec.\n",
      "Step(25860) loss: 5.1305 -- time: 4.5536 sec.\n",
      "Step(25870) loss: 5.3586 -- time: 4.6441 sec.\n",
      "Step(25880) loss: 5.8174 -- time: 4.3746 sec.\n",
      "Step(25890) loss: 5.5644 -- time: 4.4993 sec.\n",
      "Step(25900) loss: 5.3910 -- time: 4.5606 sec.\n",
      "Step(25910) loss: 5.4474 -- time: 4.4819 sec.\n",
      "Step(25920) loss: 5.3432 -- time: 4.6054 sec.\n",
      "Step(25930) loss: 5.3675 -- time: 4.5770 sec.\n",
      "Step(25940) loss: 5.7195 -- time: 4.5313 sec.\n",
      "Step(25950) loss: 5.4071 -- time: 4.4960 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 974.8072 - val_loss: 0.0000\n",
      "time: 82.3027 sec.\n",
      "time_left: 75.4441 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 146/200\n",
      "----------------------------------------------------------------------\n",
      "Step(25960) loss: 5.8659 -- time: 2.2335 sec.\n",
      "Step(25970) loss: 4.9011 -- time: 4.4035 sec.\n",
      "Step(25980) loss: 5.6419 -- time: 4.4419 sec.\n",
      "Step(25990) loss: 5.8249 -- time: 4.3931 sec.\n",
      "Step(26000) loss: 5.2412 -- time: 4.4824 sec.\n",
      "Step(26010) loss: 5.7227 -- time: 4.4401 sec.\n",
      "Step(26020) loss: 5.2733 -- time: 4.5525 sec.\n",
      "Step(26030) loss: 5.2187 -- time: 4.5087 sec.\n",
      "Step(26040) loss: 5.0024 -- time: 4.4531 sec.\n",
      "Step(26050) loss: 6.0559 -- time: 4.4297 sec.\n",
      "Step(26060) loss: 5.6139 -- time: 4.3516 sec.\n",
      "Step(26070) loss: 5.3161 -- time: 4.4131 sec.\n",
      "Step(26080) loss: 5.1199 -- time: 4.4439 sec.\n",
      "Step(26090) loss: 5.7182 -- time: 4.5257 sec.\n",
      "Step(26100) loss: 5.0760 -- time: 4.3153 sec.\n",
      "Step(26110) loss: 5.4075 -- time: 4.5920 sec.\n",
      "Step(26120) loss: 5.4381 -- time: 4.4822 sec.\n",
      "Step(26130) loss: 5.9542 -- time: 4.3691 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 969.1424 - val_loss: 0.0000\n",
      "time: 81.3439 sec.\n",
      "time_left: 73.2095 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 147/200\n",
      "----------------------------------------------------------------------\n",
      "Step(26140) loss: 5.2607 -- time: 2.5701 sec.\n",
      "Step(26150) loss: 4.8072 -- time: 4.3870 sec.\n",
      "Step(26160) loss: 5.7304 -- time: 4.4519 sec.\n",
      "Step(26170) loss: 5.7321 -- time: 4.4706 sec.\n",
      "Step(26180) loss: 5.4282 -- time: 4.3936 sec.\n",
      "Step(26190) loss: 6.3116 -- time: 4.4727 sec.\n",
      "Step(26200) loss: 5.0799 -- time: 4.5939 sec.\n",
      "Step(26210) loss: 5.4538 -- time: 4.4891 sec.\n",
      "Step(26220) loss: 5.7594 -- time: 4.4790 sec.\n",
      "Step(26230) loss: 5.6023 -- time: 4.5186 sec.\n",
      "Step(26240) loss: 5.0385 -- time: 4.4382 sec.\n",
      "Step(26250) loss: 5.1750 -- time: 4.4608 sec.\n",
      "Step(26260) loss: 4.8989 -- time: 4.5077 sec.\n",
      "Step(26270) loss: 5.5054 -- time: 4.5582 sec.\n",
      "Step(26280) loss: 5.4798 -- time: 4.5370 sec.\n",
      "Step(26290) loss: 5.4309 -- time: 4.5416 sec.\n",
      "Step(26300) loss: 4.9575 -- time: 4.4511 sec.\n",
      "Step(26310) loss: 5.4366 -- time: 4.5003 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 975.2786 - val_loss: 0.0000\n",
      "time: 81.8871 sec.\n",
      "time_left: 72.3336 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 148/200\n",
      "----------------------------------------------------------------------\n",
      "Step(26320) loss: 5.3784 -- time: 3.1498 sec.\n",
      "Step(26330) loss: 5.0118 -- time: 4.4868 sec.\n",
      "Step(26340) loss: 5.5282 -- time: 4.5420 sec.\n",
      "Step(26350) loss: 4.8510 -- time: 4.3262 sec.\n",
      "Step(26360) loss: 5.2419 -- time: 4.4416 sec.\n",
      "Step(26370) loss: 4.9666 -- time: 4.4934 sec.\n",
      "Step(26380) loss: 5.0621 -- time: 4.5663 sec.\n",
      "Step(26390) loss: 5.0611 -- time: 4.4527 sec.\n",
      "Step(26400) loss: 5.5057 -- time: 4.4322 sec.\n",
      "Step(26410) loss: 5.3286 -- time: 4.4012 sec.\n",
      "Step(26420) loss: 5.2529 -- time: 4.4755 sec.\n",
      "Step(26430) loss: 5.6333 -- time: 4.5615 sec.\n",
      "Step(26440) loss: 4.9387 -- time: 4.4831 sec.\n",
      "Step(26450) loss: 4.8773 -- time: 4.3337 sec.\n",
      "Step(26460) loss: 5.4366 -- time: 4.4832 sec.\n",
      "Step(26470) loss: 4.7340 -- time: 4.3862 sec.\n",
      "Step(26480) loss: 5.2258 -- time: 4.4378 sec.\n",
      "Step(26490) loss: 5.1784 -- time: 4.3890 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 965.3978 - val_loss: 0.0000\n",
      "time: 81.4808 sec.\n",
      "time_left: 70.6167 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 149/200\n",
      "----------------------------------------------------------------------\n",
      "Step(26500) loss: 5.4464 -- time: 3.5787 sec.\n",
      "Step(26510) loss: 5.4890 -- time: 4.3513 sec.\n",
      "Step(26520) loss: 5.0392 -- time: 4.6284 sec.\n",
      "Step(26530) loss: 5.9176 -- time: 4.4589 sec.\n",
      "Step(26540) loss: 5.6673 -- time: 4.4147 sec.\n",
      "Step(26550) loss: 5.3398 -- time: 4.4549 sec.\n",
      "Step(26560) loss: 5.5591 -- time: 4.4862 sec.\n",
      "Step(26570) loss: 5.2616 -- time: 4.3624 sec.\n",
      "Step(26580) loss: 5.2071 -- time: 4.4838 sec.\n",
      "Step(26590) loss: 5.0798 -- time: 4.4516 sec.\n",
      "Step(26600) loss: 5.3706 -- time: 4.3573 sec.\n",
      "Step(26610) loss: 6.0897 -- time: 4.4173 sec.\n",
      "Step(26620) loss: 6.0216 -- time: 4.4649 sec.\n",
      "Step(26630) loss: 5.8420 -- time: 4.4916 sec.\n",
      "Step(26640) loss: 5.3391 -- time: 4.3888 sec.\n",
      "Step(26650) loss: 6.2194 -- time: 4.4462 sec.\n",
      "Step(26660) loss: 5.5125 -- time: 4.5844 sec.\n",
      "Step(26670) loss: 5.8524 -- time: 4.5271 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 986.9968 - val_loss: 0.0000\n",
      "time: 81.5253 sec.\n",
      "time_left: 69.2965 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 150/200\n",
      "----------------------------------------------------------------------\n",
      "Step(26680) loss: 5.2933 -- time: 3.9305 sec.\n",
      "Step(26690) loss: 5.5806 -- time: 4.5046 sec.\n",
      "Step(26700) loss: 5.4210 -- time: 4.4466 sec.\n",
      "Step(26710) loss: 6.3847 -- time: 4.3189 sec.\n",
      "Step(26720) loss: 5.3340 -- time: 4.4879 sec.\n",
      "Step(26730) loss: 6.4965 -- time: 4.5214 sec.\n",
      "Step(26740) loss: 5.5991 -- time: 4.3876 sec.\n",
      "Step(26750) loss: 5.6028 -- time: 4.3685 sec.\n",
      "Step(26760) loss: 5.8192 -- time: 4.3668 sec.\n",
      "Step(26770) loss: 5.3881 -- time: 4.4008 sec.\n",
      "Step(26780) loss: 5.6418 -- time: 4.4145 sec.\n",
      "Step(26790) loss: 5.6757 -- time: 4.3876 sec.\n",
      "Step(26800) loss: 5.4192 -- time: 4.4261 sec.\n",
      "Step(26810) loss: 5.8666 -- time: 4.4360 sec.\n",
      "Step(26820) loss: 4.9837 -- time: 4.4992 sec.\n",
      "Step(26830) loss: 5.4033 -- time: 4.5509 sec.\n",
      "Step(26840) loss: 5.1308 -- time: 4.3398 sec.\n",
      "Step(26850) loss: 5.1874 -- time: 4.3401 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 999.5294 - val_loss: 997.4433\n",
      "time: 116.6761 sec.\n",
      "time_left: 97.2300 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 151/200\n",
      "----------------------------------------------------------------------\n",
      "Step(26860) loss: 5.0509 -- time: 4.4224 sec.\n",
      "Step(26870) loss: 5.3947 -- time: 4.4283 sec.\n",
      "Step(26880) loss: 5.3889 -- time: 4.4971 sec.\n",
      "Step(26890) loss: 6.2958 -- time: 4.4593 sec.\n",
      "Step(26900) loss: 5.2955 -- time: 4.5532 sec.\n",
      "Step(26910) loss: 5.2487 -- time: 4.3807 sec.\n",
      "Step(26920) loss: 5.8326 -- time: 4.4365 sec.\n",
      "Step(26930) loss: 5.0563 -- time: 4.3833 sec.\n",
      "Step(26940) loss: 5.7167 -- time: 4.4148 sec.\n",
      "Step(26950) loss: 6.0692 -- time: 4.3057 sec.\n",
      "Step(26960) loss: 5.0003 -- time: 4.3667 sec.\n",
      "Step(26970) loss: 5.4554 -- time: 4.4500 sec.\n",
      "Step(26980) loss: 5.8210 -- time: 4.4141 sec.\n",
      "Step(26990) loss: 5.4737 -- time: 4.5066 sec.\n",
      "Step(27000) loss: 5.4745 -- time: 4.4828 sec.\n",
      "Step(27010) loss: 5.2107 -- time: 4.3342 sec.\n",
      "Step(27020) loss: 5.6352 -- time: 4.4627 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 982.4430 - val_loss: 0.0000\n",
      "time: 81.0891 sec.\n",
      "time_left: 66.2228 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 152/200\n",
      "----------------------------------------------------------------------\n",
      "Step(27030) loss: 5.1745 -- time: 0.3403 sec.\n",
      "Step(27040) loss: 5.1118 -- time: 4.3188 sec.\n",
      "Step(27050) loss: 5.9852 -- time: 4.5560 sec.\n",
      "Step(27060) loss: 5.3699 -- time: 4.5286 sec.\n",
      "Step(27070) loss: 5.4254 -- time: 4.4408 sec.\n",
      "Step(27080) loss: 5.4380 -- time: 4.4349 sec.\n",
      "Step(27090) loss: 5.4976 -- time: 4.5082 sec.\n",
      "Step(27100) loss: 5.8290 -- time: 4.2960 sec.\n",
      "Step(27110) loss: 5.3757 -- time: 4.4517 sec.\n",
      "Step(27120) loss: 5.6870 -- time: 4.3233 sec.\n",
      "Step(27130) loss: 5.4631 -- time: 4.5319 sec.\n",
      "Step(27140) loss: 5.0055 -- time: 4.3998 sec.\n",
      "Step(27150) loss: 5.4368 -- time: 4.4580 sec.\n",
      "Step(27160) loss: 4.2797 -- time: 4.2876 sec.\n",
      "Step(27170) loss: 5.1646 -- time: 4.5586 sec.\n",
      "Step(27180) loss: 5.3810 -- time: 4.4824 sec.\n",
      "Step(27190) loss: 5.2654 -- time: 4.6572 sec.\n",
      "Step(27200) loss: 4.9081 -- time: 4.5022 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 969.6987 - val_loss: 0.0000\n",
      "time: 81.4724 sec.\n",
      "time_left: 65.1779 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 153/200\n",
      "----------------------------------------------------------------------\n",
      "Step(27210) loss: 5.2180 -- time: 0.8291 sec.\n",
      "Step(27220) loss: 5.2263 -- time: 4.5925 sec.\n",
      "Step(27230) loss: 5.5789 -- time: 4.4224 sec.\n",
      "Step(27240) loss: 5.1707 -- time: 4.4227 sec.\n",
      "Step(27250) loss: 4.9822 -- time: 4.4568 sec.\n",
      "Step(27260) loss: 5.4629 -- time: 4.3370 sec.\n",
      "Step(27270) loss: 4.8257 -- time: 4.4570 sec.\n",
      "Step(27280) loss: 5.7862 -- time: 4.4762 sec.\n",
      "Step(27290) loss: 5.2908 -- time: 4.4821 sec.\n",
      "Step(27300) loss: 5.3420 -- time: 4.4734 sec.\n",
      "Step(27310) loss: 5.2390 -- time: 4.4382 sec.\n",
      "Step(27320) loss: 5.2843 -- time: 4.5787 sec.\n",
      "Step(27330) loss: 5.1748 -- time: 4.4297 sec.\n",
      "Step(27340) loss: 5.5111 -- time: 4.3892 sec.\n",
      "Step(27350) loss: 5.2030 -- time: 4.3097 sec.\n",
      "Step(27360) loss: 5.3410 -- time: 4.5423 sec.\n",
      "Step(27370) loss: 5.6364 -- time: 4.4182 sec.\n",
      "Step(27380) loss: 5.1229 -- time: 4.4616 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 959.4601 - val_loss: 0.0000\n",
      "time: 81.3891 sec.\n",
      "time_left: 63.7548 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 154/200\n",
      "----------------------------------------------------------------------\n",
      "Step(27390) loss: 5.1865 -- time: 1.1792 sec.\n",
      "Step(27400) loss: 4.7264 -- time: 4.3950 sec.\n",
      "Step(27410) loss: 4.8294 -- time: 4.4211 sec.\n",
      "Step(27420) loss: 5.5594 -- time: 4.5615 sec.\n",
      "Step(27430) loss: 5.7212 -- time: 4.5427 sec.\n",
      "Step(27440) loss: 5.3749 -- time: 4.5418 sec.\n",
      "Step(27450) loss: 5.6466 -- time: 4.5597 sec.\n",
      "Step(27460) loss: 5.3904 -- time: 4.3940 sec.\n",
      "Step(27470) loss: 5.6447 -- time: 4.4609 sec.\n",
      "Step(27480) loss: 4.7445 -- time: 4.4282 sec.\n",
      "Step(27490) loss: 5.1416 -- time: 4.4528 sec.\n",
      "Step(27500) loss: 5.4817 -- time: 4.5544 sec.\n",
      "Step(27510) loss: 5.6406 -- time: 4.4790 sec.\n",
      "Step(27520) loss: 6.1117 -- time: 4.5557 sec.\n",
      "Step(27530) loss: 5.7752 -- time: 4.4236 sec.\n",
      "Step(27540) loss: 5.5063 -- time: 4.3431 sec.\n",
      "Step(27550) loss: 5.6283 -- time: 4.4845 sec.\n",
      "Step(27560) loss: 5.1403 -- time: 4.4695 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 964.9147 - val_loss: 0.0000\n",
      "time: 81.6014 sec.\n",
      "time_left: 62.5611 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 155/200\n",
      "----------------------------------------------------------------------\n",
      "Step(27570) loss: 5.3858 -- time: 1.7256 sec.\n",
      "Step(27580) loss: 5.2674 -- time: 4.5165 sec.\n",
      "Step(27590) loss: 5.2062 -- time: 4.4809 sec.\n",
      "Step(27600) loss: 5.2112 -- time: 4.3856 sec.\n",
      "Step(27610) loss: 4.9998 -- time: 4.4390 sec.\n",
      "Step(27620) loss: 4.6927 -- time: 4.4272 sec.\n",
      "Step(27630) loss: 5.2764 -- time: 4.3082 sec.\n",
      "Step(27640) loss: 5.7338 -- time: 4.5995 sec.\n",
      "Step(27650) loss: 4.4254 -- time: 4.3221 sec.\n",
      "Step(27660) loss: 5.8958 -- time: 4.3830 sec.\n",
      "Step(27670) loss: 5.6324 -- time: 4.5267 sec.\n",
      "Step(27680) loss: 5.4020 -- time: 4.3611 sec.\n",
      "Step(27690) loss: 5.4910 -- time: 4.4914 sec.\n",
      "Step(27700) loss: 5.2333 -- time: 4.4874 sec.\n",
      "Step(27710) loss: 5.6789 -- time: 4.3881 sec.\n",
      "Step(27720) loss: 5.2596 -- time: 4.3509 sec.\n",
      "Step(27730) loss: 5.1321 -- time: 4.4084 sec.\n",
      "Step(27740) loss: 5.6009 -- time: 4.5489 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 966.6463 - val_loss: 0.0000\n",
      "time: 81.1763 sec.\n",
      "time_left: 60.8823 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 156/200\n",
      "----------------------------------------------------------------------\n",
      "Step(27750) loss: 5.9535 -- time: 2.2302 sec.\n",
      "Step(27760) loss: 5.6624 -- time: 4.4575 sec.\n",
      "Step(27770) loss: 4.9771 -- time: 4.4313 sec.\n",
      "Step(27780) loss: 6.1662 -- time: 4.3937 sec.\n",
      "Step(27790) loss: 4.9996 -- time: 4.4314 sec.\n",
      "Step(27800) loss: 5.4280 -- time: 4.5761 sec.\n",
      "Step(27810) loss: 5.4806 -- time: 4.4487 sec.\n",
      "Step(27820) loss: 5.1363 -- time: 4.5311 sec.\n",
      "Step(27830) loss: 5.2699 -- time: 4.3825 sec.\n",
      "Step(27840) loss: 5.2693 -- time: 4.3896 sec.\n",
      "Step(27850) loss: 4.7415 -- time: 4.5119 sec.\n",
      "Step(27860) loss: 5.1820 -- time: 4.3827 sec.\n",
      "Step(27870) loss: 4.8875 -- time: 4.5558 sec.\n",
      "Step(27880) loss: 5.7735 -- time: 4.5899 sec.\n",
      "Step(27890) loss: 5.4545 -- time: 4.3392 sec.\n",
      "Step(27900) loss: 5.3094 -- time: 4.4764 sec.\n",
      "Step(27910) loss: 5.5682 -- time: 4.5440 sec.\n",
      "Step(27920) loss: 5.6040 -- time: 4.3538 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 968.6014 - val_loss: 0.0000\n",
      "time: 81.6743 sec.\n",
      "time_left: 59.8945 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 157/200\n",
      "----------------------------------------------------------------------\n",
      "Step(27930) loss: 5.2075 -- time: 2.6668 sec.\n",
      "Step(27940) loss: 5.8045 -- time: 4.5421 sec.\n",
      "Step(27950) loss: 5.3074 -- time: 4.4390 sec.\n",
      "Step(27960) loss: 4.9950 -- time: 4.4468 sec.\n",
      "Step(27970) loss: 5.4655 -- time: 4.4741 sec.\n",
      "Step(27980) loss: 5.4280 -- time: 4.6275 sec.\n",
      "Step(27990) loss: 5.4015 -- time: 4.4819 sec.\n",
      "Step(28000) loss: 4.6774 -- time: 4.3078 sec.\n",
      "Step(28010) loss: 4.8712 -- time: 4.4951 sec.\n",
      "Step(28020) loss: 5.5648 -- time: 4.4721 sec.\n",
      "Step(28030) loss: 5.0001 -- time: 4.4967 sec.\n",
      "Step(28040) loss: 5.4321 -- time: 4.4427 sec.\n",
      "Step(28050) loss: 5.2877 -- time: 4.5660 sec.\n",
      "Step(28060) loss: 5.7137 -- time: 4.5058 sec.\n",
      "Step(28070) loss: 5.4070 -- time: 4.4976 sec.\n",
      "Step(28080) loss: 5.6532 -- time: 4.5938 sec.\n",
      "Step(28090) loss: 5.9765 -- time: 4.3967 sec.\n",
      "Step(28100) loss: 5.1543 -- time: 4.3988 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 966.1430 - val_loss: 0.0000\n",
      "time: 81.9758 sec.\n",
      "time_left: 58.7493 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 158/200\n",
      "----------------------------------------------------------------------\n",
      "Step(28110) loss: 5.2858 -- time: 3.1398 sec.\n",
      "Step(28120) loss: 5.5073 -- time: 4.5408 sec.\n",
      "Step(28130) loss: 5.1434 -- time: 4.5352 sec.\n",
      "Step(28140) loss: 5.2673 -- time: 4.4980 sec.\n",
      "Step(28150) loss: 5.3158 -- time: 4.5759 sec.\n",
      "Step(28160) loss: 6.0333 -- time: 4.5044 sec.\n",
      "Step(28170) loss: 5.3612 -- time: 4.4753 sec.\n",
      "Step(28180) loss: 6.0314 -- time: 4.4583 sec.\n",
      "Step(28190) loss: 5.4898 -- time: 4.3946 sec.\n",
      "Step(28200) loss: 5.3084 -- time: 4.3917 sec.\n",
      "Step(28210) loss: 5.2156 -- time: 4.3096 sec.\n",
      "Step(28220) loss: 5.0576 -- time: 4.4847 sec.\n",
      "Step(28230) loss: 5.2253 -- time: 4.3615 sec.\n",
      "Step(28240) loss: 5.2004 -- time: 4.4921 sec.\n",
      "Step(28250) loss: 5.3096 -- time: 4.3499 sec.\n",
      "Step(28260) loss: 5.9433 -- time: 4.5296 sec.\n",
      "Step(28270) loss: 5.7007 -- time: 4.3286 sec.\n",
      "Step(28280) loss: 5.5002 -- time: 4.3790 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 969.3782 - val_loss: 0.0000\n",
      "time: 81.3336 sec.\n",
      "time_left: 56.9335 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 159/200\n",
      "----------------------------------------------------------------------\n",
      "Step(28290) loss: 5.5577 -- time: 3.4896 sec.\n",
      "Step(28300) loss: 5.8697 -- time: 4.5278 sec.\n",
      "Step(28310) loss: 5.3551 -- time: 4.4039 sec.\n",
      "Step(28320) loss: 5.8936 -- time: 4.4386 sec.\n",
      "Step(28330) loss: 5.1278 -- time: 4.4675 sec.\n",
      "Step(28340) loss: 5.3019 -- time: 4.4871 sec.\n",
      "Step(28350) loss: 5.4169 -- time: 4.4294 sec.\n",
      "Step(28360) loss: 5.0388 -- time: 4.4745 sec.\n",
      "Step(28370) loss: 5.3959 -- time: 4.5828 sec.\n",
      "Step(28380) loss: 5.5837 -- time: 4.6399 sec.\n",
      "Step(28390) loss: 5.5050 -- time: 4.4590 sec.\n",
      "Step(28400) loss: 5.7975 -- time: 4.5404 sec.\n",
      "Step(28410) loss: 6.2808 -- time: 4.4828 sec.\n",
      "Step(28420) loss: 5.7986 -- time: 4.3894 sec.\n",
      "Step(28430) loss: 5.0982 -- time: 4.4327 sec.\n",
      "Step(28440) loss: 5.5709 -- time: 4.3726 sec.\n",
      "Step(28450) loss: 5.6166 -- time: 4.6926 sec.\n",
      "Step(28460) loss: 5.0553 -- time: 4.4098 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 983.2952 - val_loss: 0.0000\n",
      "time: 81.9167 sec.\n",
      "time_left: 55.9764 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 160/200\n",
      "----------------------------------------------------------------------\n",
      "Step(28470) loss: 5.1288 -- time: 4.0247 sec.\n",
      "Step(28480) loss: 5.7307 -- time: 4.4291 sec.\n",
      "Step(28490) loss: 6.2004 -- time: 4.5189 sec.\n",
      "Step(28500) loss: 5.5327 -- time: 4.4754 sec.\n",
      "Step(28510) loss: 5.7170 -- time: 4.4412 sec.\n",
      "Step(28520) loss: 5.8517 -- time: 4.5088 sec.\n",
      "Step(28530) loss: 5.7557 -- time: 4.4260 sec.\n",
      "Step(28540) loss: 5.7319 -- time: 4.3391 sec.\n",
      "Step(28550) loss: 5.6784 -- time: 4.4617 sec.\n",
      "Step(28560) loss: 5.6983 -- time: 4.4180 sec.\n",
      "Step(28570) loss: 5.4742 -- time: 4.3747 sec.\n",
      "Step(28580) loss: 5.6932 -- time: 4.4146 sec.\n",
      "Step(28590) loss: 5.2981 -- time: 4.6253 sec.\n",
      "Step(28600) loss: 5.9176 -- time: 4.4794 sec.\n",
      "Step(28610) loss: 5.8332 -- time: 4.4675 sec.\n",
      "Step(28620) loss: 6.1610 -- time: 4.4662 sec.\n",
      "Step(28630) loss: 5.7770 -- time: 4.4608 sec.\n",
      "Step(28640) loss: 6.0103 -- time: 4.3765 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1024.5111 - val_loss: 1029.8528\n",
      "time: 117.1220 sec.\n",
      "time_left: 78.0813 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 161/200\n",
      "----------------------------------------------------------------------\n",
      "Step(28650) loss: 6.0012 -- time: 4.7671 sec.\n",
      "Step(28660) loss: 5.1395 -- time: 4.5609 sec.\n",
      "Step(28670) loss: 6.2603 -- time: 4.6206 sec.\n",
      "Step(28680) loss: 5.8320 -- time: 4.4891 sec.\n",
      "Step(28690) loss: 5.2620 -- time: 4.5235 sec.\n",
      "Step(28700) loss: 5.8673 -- time: 4.4714 sec.\n",
      "Step(28710) loss: 6.1034 -- time: 4.4341 sec.\n",
      "Step(28720) loss: 5.7235 -- time: 4.3561 sec.\n",
      "Step(28730) loss: 5.5655 -- time: 4.4990 sec.\n",
      "Step(28740) loss: 5.6332 -- time: 4.4053 sec.\n",
      "Step(28750) loss: 5.7218 -- time: 4.4715 sec.\n",
      "Step(28760) loss: 5.8338 -- time: 4.4300 sec.\n",
      "Step(28770) loss: 5.2536 -- time: 4.6022 sec.\n",
      "Step(28780) loss: 5.6227 -- time: 4.3614 sec.\n",
      "Step(28790) loss: 5.3945 -- time: 4.4374 sec.\n",
      "Step(28800) loss: 5.5417 -- time: 4.4925 sec.\n",
      "Step(28810) loss: 5.4558 -- time: 4.4422 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1005.8880 - val_loss: 0.0000\n",
      "time: 82.1913 sec.\n",
      "time_left: 53.4243 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 162/200\n",
      "----------------------------------------------------------------------\n",
      "Step(28820) loss: 5.2323 -- time: 0.3500 sec.\n",
      "Step(28830) loss: 5.9454 -- time: 4.4968 sec.\n",
      "Step(28840) loss: 5.7104 -- time: 4.3897 sec.\n",
      "Step(28850) loss: 5.0356 -- time: 4.3645 sec.\n",
      "Step(28860) loss: 5.6894 -- time: 4.4427 sec.\n",
      "Step(28870) loss: 5.1874 -- time: 4.4520 sec.\n",
      "Step(28880) loss: 5.0728 -- time: 4.3794 sec.\n",
      "Step(28890) loss: 5.4406 -- time: 4.3616 sec.\n",
      "Step(28900) loss: 5.4949 -- time: 4.4815 sec.\n",
      "Step(28910) loss: 5.2563 -- time: 4.3573 sec.\n",
      "Step(28920) loss: 5.4476 -- time: 4.3916 sec.\n",
      "Step(28930) loss: 6.0874 -- time: 4.4231 sec.\n",
      "Step(28940) loss: 6.3269 -- time: 4.3831 sec.\n",
      "Step(28950) loss: 5.1559 -- time: 4.4001 sec.\n",
      "Step(28960) loss: 5.9132 -- time: 4.5051 sec.\n",
      "Step(28970) loss: 5.1466 -- time: 4.3918 sec.\n",
      "Step(28980) loss: 5.0721 -- time: 4.3403 sec.\n",
      "Step(28990) loss: 5.1707 -- time: 4.4510 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 989.7992 - val_loss: 0.0000\n",
      "time: 80.8064 sec.\n",
      "time_left: 51.1774 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 163/200\n",
      "----------------------------------------------------------------------\n",
      "Step(29000) loss: 5.1907 -- time: 0.7873 sec.\n",
      "Step(29010) loss: 5.8101 -- time: 4.5129 sec.\n",
      "Step(29020) loss: 19.9474 -- time: 4.4215 sec.\n",
      "Step(29030) loss: 6.2364 -- time: 4.3572 sec.\n",
      "Step(29040) loss: 5.7008 -- time: 4.5311 sec.\n",
      "Step(29050) loss: 5.8764 -- time: 4.4421 sec.\n",
      "Step(29060) loss: 5.5910 -- time: 4.3645 sec.\n",
      "Step(29070) loss: 6.2413 -- time: 4.4539 sec.\n",
      "Step(29080) loss: 5.8434 -- time: 4.4205 sec.\n",
      "Step(29090) loss: 5.8502 -- time: 4.4533 sec.\n",
      "Step(29100) loss: 5.9209 -- time: 4.5208 sec.\n",
      "Step(29110) loss: 5.3967 -- time: 4.4672 sec.\n",
      "Step(29120) loss: 5.3516 -- time: 4.4139 sec.\n",
      "Step(29130) loss: 5.8320 -- time: 4.4470 sec.\n",
      "Step(29140) loss: 5.6123 -- time: 4.5401 sec.\n",
      "Step(29150) loss: 5.5630 -- time: 4.4887 sec.\n",
      "Step(29160) loss: 5.6840 -- time: 4.3742 sec.\n",
      "Step(29170) loss: 5.4651 -- time: 4.4260 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1057.8399 - val_loss: 0.0000\n",
      "time: 81.2969 sec.\n",
      "time_left: 50.1331 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 164/200\n",
      "----------------------------------------------------------------------\n",
      "Step(29180) loss: 5.8100 -- time: 1.3020 sec.\n",
      "Step(29190) loss: 5.8045 -- time: 4.3797 sec.\n",
      "Step(29200) loss: 5.2034 -- time: 4.4656 sec.\n",
      "Step(29210) loss: 5.5725 -- time: 4.4004 sec.\n",
      "Step(29220) loss: 5.8703 -- time: 4.4069 sec.\n",
      "Step(29230) loss: 5.5176 -- time: 4.4790 sec.\n",
      "Step(29240) loss: 5.5175 -- time: 4.5228 sec.\n",
      "Step(29250) loss: 5.7491 -- time: 4.3917 sec.\n",
      "Step(29260) loss: 5.8871 -- time: 4.3761 sec.\n",
      "Step(29270) loss: 5.3778 -- time: 4.4115 sec.\n",
      "Step(29280) loss: 5.5568 -- time: 4.3721 sec.\n",
      "Step(29290) loss: 5.2538 -- time: 4.5328 sec.\n",
      "Step(29300) loss: 5.1970 -- time: 4.4628 sec.\n",
      "Step(29310) loss: 5.5311 -- time: 4.4859 sec.\n",
      "Step(29320) loss: 5.3645 -- time: 4.5609 sec.\n",
      "Step(29330) loss: 5.9433 -- time: 4.5234 sec.\n",
      "Step(29340) loss: 5.2852 -- time: 4.4363 sec.\n",
      "Step(29350) loss: 5.3755 -- time: 4.4668 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 989.8417 - val_loss: 0.0000\n",
      "time: 81.4175 sec.\n",
      "time_left: 48.8505 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 165/200\n",
      "----------------------------------------------------------------------\n",
      "Step(29360) loss: 5.2892 -- time: 1.7155 sec.\n",
      "Step(29370) loss: 5.2677 -- time: 4.3890 sec.\n",
      "Step(29380) loss: 5.3242 -- time: 4.4835 sec.\n",
      "Step(29390) loss: 5.1669 -- time: 4.3393 sec.\n",
      "Step(29400) loss: 5.8898 -- time: 4.5114 sec.\n",
      "Step(29410) loss: 5.3726 -- time: 4.4134 sec.\n",
      "Step(29420) loss: 5.2974 -- time: 4.4541 sec.\n",
      "Step(29430) loss: 5.2880 -- time: 4.5278 sec.\n",
      "Step(29440) loss: 5.2262 -- time: 4.5800 sec.\n",
      "Step(29450) loss: 5.9708 -- time: 4.5180 sec.\n",
      "Step(29460) loss: 5.4883 -- time: 4.4348 sec.\n",
      "Step(29470) loss: 5.2294 -- time: 4.5189 sec.\n",
      "Step(29480) loss: 4.9285 -- time: 4.4257 sec.\n",
      "Step(29490) loss: 5.9849 -- time: 4.4670 sec.\n",
      "Step(29500) loss: 6.0689 -- time: 4.3363 sec.\n",
      "Step(29510) loss: 5.6948 -- time: 4.4903 sec.\n",
      "Step(29520) loss: 4.7963 -- time: 4.4202 sec.\n",
      "Step(29530) loss: 4.9741 -- time: 4.4746 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 982.7994 - val_loss: 0.0000\n",
      "time: 81.5385 sec.\n",
      "time_left: 47.5641 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 166/200\n",
      "----------------------------------------------------------------------\n",
      "Step(29540) loss: 5.0046 -- time: 2.2489 sec.\n",
      "Step(29550) loss: 5.5286 -- time: 4.4817 sec.\n",
      "Step(29560) loss: 5.6538 -- time: 4.4951 sec.\n",
      "Step(29570) loss: 5.7828 -- time: 4.4537 sec.\n",
      "Step(29580) loss: 5.5111 -- time: 4.4265 sec.\n",
      "Step(29590) loss: 5.6339 -- time: 4.4042 sec.\n",
      "Step(29600) loss: 5.2733 -- time: 4.5266 sec.\n",
      "Step(29610) loss: 5.7578 -- time: 4.4284 sec.\n",
      "Step(29620) loss: 5.0551 -- time: 4.4760 sec.\n",
      "Step(29630) loss: 6.1597 -- time: 4.4102 sec.\n",
      "Step(29640) loss: 5.7238 -- time: 4.3690 sec.\n",
      "Step(29650) loss: 5.2865 -- time: 4.5381 sec.\n",
      "Step(29660) loss: 5.2497 -- time: 4.5021 sec.\n",
      "Step(29670) loss: 5.1073 -- time: 4.3861 sec.\n",
      "Step(29680) loss: 5.0482 -- time: 4.4432 sec.\n",
      "Step(29690) loss: 5.6289 -- time: 4.4980 sec.\n",
      "Step(29700) loss: 5.5077 -- time: 4.3566 sec.\n",
      "Step(29710) loss: 5.0102 -- time: 4.5187 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 976.6261 - val_loss: 0.0000\n",
      "time: 81.4401 sec.\n",
      "time_left: 46.1494 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 167/200\n",
      "----------------------------------------------------------------------\n",
      "Step(29720) loss: 5.3864 -- time: 2.7133 sec.\n",
      "Step(29730) loss: 5.9669 -- time: 4.5476 sec.\n",
      "Step(29740) loss: 5.7034 -- time: 4.3741 sec.\n",
      "Step(29750) loss: 6.1110 -- time: 4.3821 sec.\n",
      "Step(29760) loss: 5.3530 -- time: 4.4719 sec.\n",
      "Step(29770) loss: 5.4125 -- time: 4.5244 sec.\n",
      "Step(29780) loss: 4.8708 -- time: 4.5191 sec.\n",
      "Step(29790) loss: 5.1306 -- time: 4.3913 sec.\n",
      "Step(29800) loss: 5.3020 -- time: 4.4781 sec.\n",
      "Step(29810) loss: 5.2880 -- time: 4.3376 sec.\n",
      "Step(29820) loss: 5.7104 -- time: 4.3437 sec.\n",
      "Step(29830) loss: 5.1191 -- time: 4.3149 sec.\n",
      "Step(29840) loss: 5.0406 -- time: 4.4973 sec.\n",
      "Step(29850) loss: 5.9858 -- time: 4.4580 sec.\n",
      "Step(29860) loss: 5.7174 -- time: 4.5349 sec.\n",
      "Step(29870) loss: 5.7314 -- time: 4.5575 sec.\n",
      "Step(29880) loss: 5.0314 -- time: 4.4554 sec.\n",
      "Step(29890) loss: 5.2718 -- time: 4.4672 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 972.0078 - val_loss: 0.0000\n",
      "time: 81.4104 sec.\n",
      "time_left: 44.7757 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 168/200\n",
      "----------------------------------------------------------------------\n",
      "Step(29900) loss: 4.9695 -- time: 3.1084 sec.\n",
      "Step(29910) loss: 5.6152 -- time: 4.4944 sec.\n",
      "Step(29920) loss: 5.5459 -- time: 4.4364 sec.\n",
      "Step(29930) loss: 5.0447 -- time: 4.4641 sec.\n",
      "Step(29940) loss: 5.2109 -- time: 4.4448 sec.\n",
      "Step(29950) loss: 5.4739 -- time: 4.4553 sec.\n",
      "Step(29960) loss: 5.4509 -- time: 4.4754 sec.\n",
      "Step(29970) loss: 5.1793 -- time: 4.5112 sec.\n",
      "Step(29980) loss: 5.1080 -- time: 4.4833 sec.\n",
      "Step(29990) loss: 5.1863 -- time: 4.4013 sec.\n",
      "Step(30000) loss: 5.0338 -- time: 4.5127 sec.\n",
      "Step(30010) loss: 5.3974 -- time: 4.4844 sec.\n",
      "Step(30020) loss: 5.5945 -- time: 4.5528 sec.\n",
      "Step(30030) loss: 5.0882 -- time: 4.3924 sec.\n",
      "Step(30040) loss: 5.1156 -- time: 4.4684 sec.\n",
      "Step(30050) loss: 4.9707 -- time: 4.3517 sec.\n",
      "Step(30060) loss: 5.2278 -- time: 4.4035 sec.\n",
      "Step(30070) loss: 5.1289 -- time: 4.6211 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 975.8827 - val_loss: 0.0000\n",
      "time: 81.6787 sec.\n",
      "time_left: 43.5620 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 169/200\n",
      "----------------------------------------------------------------------\n",
      "Step(30080) loss: 5.4681 -- time: 3.6527 sec.\n",
      "Step(30090) loss: 5.5326 -- time: 4.4764 sec.\n",
      "Step(30100) loss: 5.3882 -- time: 4.6037 sec.\n",
      "Step(30110) loss: 4.9104 -- time: 4.5250 sec.\n",
      "Step(30120) loss: 5.8097 -- time: 4.4482 sec.\n",
      "Step(30130) loss: 5.6379 -- time: 4.5652 sec.\n",
      "Step(30140) loss: 5.6422 -- time: 4.4330 sec.\n",
      "Step(30150) loss: 5.3633 -- time: 4.3366 sec.\n",
      "Step(30160) loss: 5.4074 -- time: 4.3694 sec.\n",
      "Step(30170) loss: 4.8741 -- time: 4.5875 sec.\n",
      "Step(30180) loss: 5.2827 -- time: 4.4561 sec.\n",
      "Step(30190) loss: 5.9012 -- time: 4.4119 sec.\n",
      "Step(30200) loss: 5.3800 -- time: 4.3872 sec.\n",
      "Step(30210) loss: 5.4996 -- time: 4.4609 sec.\n",
      "Step(30220) loss: 5.3406 -- time: 4.5585 sec.\n",
      "Step(30230) loss: 5.2016 -- time: 4.4700 sec.\n",
      "Step(30240) loss: 5.2674 -- time: 4.4099 sec.\n",
      "Step(30250) loss: 5.4137 -- time: 4.3263 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 979.2787 - val_loss: 0.0000\n",
      "time: 81.6401 sec.\n",
      "time_left: 42.1807 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 170/200\n",
      "----------------------------------------------------------------------\n",
      "Step(30260) loss: 5.9342 -- time: 4.0518 sec.\n",
      "Step(30270) loss: 5.2832 -- time: 4.3943 sec.\n",
      "Step(30280) loss: 5.2815 -- time: 4.3447 sec.\n",
      "Step(30290) loss: 5.3858 -- time: 4.4327 sec.\n",
      "Step(30300) loss: 5.7291 -- time: 4.4213 sec.\n",
      "Step(30310) loss: 5.7488 -- time: 4.7047 sec.\n",
      "Step(30320) loss: 4.9936 -- time: 4.5093 sec.\n",
      "Step(30330) loss: 4.8898 -- time: 4.4365 sec.\n",
      "Step(30340) loss: 5.3980 -- time: 4.4949 sec.\n",
      "Step(30350) loss: 5.2825 -- time: 4.4566 sec.\n",
      "Step(30360) loss: 5.3646 -- time: 4.5185 sec.\n",
      "Step(30370) loss: 5.4546 -- time: 4.5291 sec.\n",
      "Step(30380) loss: 5.4786 -- time: 4.4079 sec.\n",
      "Step(30390) loss: 5.3833 -- time: 4.4724 sec.\n",
      "Step(30400) loss: 5.1038 -- time: 4.6250 sec.\n",
      "Step(30410) loss: 5.6809 -- time: 4.4424 sec.\n",
      "Step(30420) loss: 5.0811 -- time: 4.4862 sec.\n",
      "Step(30430) loss: 5.3885 -- time: 4.4199 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 967.4105 - val_loss: 1022.7866\n",
      "time: 117.8586 sec.\n",
      "time_left: 58.9293 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 171/200\n",
      "----------------------------------------------------------------------\n",
      "Step(30440) loss: 5.9160 -- time: 4.5907 sec.\n",
      "Step(30450) loss: 5.6471 -- time: 4.3485 sec.\n",
      "Step(30460) loss: 7.3739 -- time: 4.5143 sec.\n",
      "Step(30470) loss: 6.7012 -- time: 4.5829 sec.\n",
      "Step(30480) loss: 6.3761 -- time: 4.3620 sec.\n",
      "Step(30490) loss: 6.5707 -- time: 4.4023 sec.\n",
      "Step(30500) loss: 6.2445 -- time: 4.4863 sec.\n",
      "Step(30510) loss: 6.2882 -- time: 4.4881 sec.\n",
      "Step(30520) loss: 6.4476 -- time: 4.5173 sec.\n",
      "Step(30530) loss: 6.0588 -- time: 4.2936 sec.\n",
      "Step(30540) loss: 6.1529 -- time: 4.5395 sec.\n",
      "Step(30550) loss: 6.3714 -- time: 4.2308 sec.\n",
      "Step(30560) loss: 6.1691 -- time: 4.5024 sec.\n",
      "Step(30570) loss: 5.7735 -- time: 4.4159 sec.\n",
      "Step(30580) loss: 5.7984 -- time: 4.3602 sec.\n",
      "Step(30590) loss: 6.2255 -- time: 4.4300 sec.\n",
      "Step(30600) loss: 6.4654 -- time: 4.4483 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1106.9526 - val_loss: 0.0000\n",
      "time: 81.2517 sec.\n",
      "time_left: 39.2717 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 172/200\n",
      "----------------------------------------------------------------------\n",
      "Step(30610) loss: 5.5381 -- time: 0.3235 sec.\n",
      "Step(30620) loss: 5.6242 -- time: 4.5014 sec.\n",
      "Step(30630) loss: 5.7568 -- time: 4.5144 sec.\n",
      "Step(30640) loss: 5.7526 -- time: 4.4714 sec.\n",
      "Step(30650) loss: 5.9650 -- time: 4.5228 sec.\n",
      "Step(30660) loss: 5.8932 -- time: 4.4530 sec.\n",
      "Step(30670) loss: 5.8001 -- time: 4.3932 sec.\n",
      "Step(30680) loss: 5.5501 -- time: 4.3533 sec.\n",
      "Step(30690) loss: 5.6009 -- time: 4.5205 sec.\n",
      "Step(30700) loss: 5.3201 -- time: 4.4363 sec.\n",
      "Step(30710) loss: 5.6697 -- time: 4.5078 sec.\n",
      "Step(30720) loss: 5.3901 -- time: 4.3204 sec.\n",
      "Step(30730) loss: 6.3994 -- time: 4.5910 sec.\n",
      "Step(30740) loss: 6.3260 -- time: 4.4896 sec.\n",
      "Step(30750) loss: 5.5575 -- time: 4.4780 sec.\n",
      "Step(30760) loss: 5.3434 -- time: 4.4718 sec.\n",
      "Step(30770) loss: 5.6664 -- time: 4.4059 sec.\n",
      "Step(30780) loss: 5.9525 -- time: 4.4422 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1027.5485 - val_loss: 0.0000\n",
      "time: 81.5369 sec.\n",
      "time_left: 38.0505 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 173/200\n",
      "----------------------------------------------------------------------\n",
      "Step(30790) loss: 5.6016 -- time: 0.8028 sec.\n",
      "Step(30800) loss: 5.6269 -- time: 4.3543 sec.\n",
      "Step(30810) loss: 5.7220 -- time: 4.6430 sec.\n",
      "Step(30820) loss: 5.9295 -- time: 4.4249 sec.\n",
      "Step(30830) loss: 5.3086 -- time: 4.4246 sec.\n",
      "Step(30840) loss: 5.6839 -- time: 4.5014 sec.\n",
      "Step(30850) loss: 5.4286 -- time: 4.3350 sec.\n",
      "Step(30860) loss: 5.9065 -- time: 4.2674 sec.\n",
      "Step(30870) loss: 5.4587 -- time: 4.5717 sec.\n",
      "Step(30880) loss: 5.3571 -- time: 4.4268 sec.\n",
      "Step(30890) loss: 6.1036 -- time: 4.5771 sec.\n",
      "Step(30900) loss: 5.7631 -- time: 4.4133 sec.\n",
      "Step(30910) loss: 5.4755 -- time: 4.5190 sec.\n",
      "Step(30920) loss: 5.1447 -- time: 4.4427 sec.\n",
      "Step(30930) loss: 5.6843 -- time: 4.5477 sec.\n",
      "Step(30940) loss: 5.5629 -- time: 4.3284 sec.\n",
      "Step(30950) loss: 5.9679 -- time: 4.4775 sec.\n",
      "Step(30960) loss: 5.5455 -- time: 4.4263 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1011.8427 - val_loss: 0.0000\n",
      "time: 81.4126 sec.\n",
      "time_left: 36.6357 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 174/200\n",
      "----------------------------------------------------------------------\n",
      "Step(30970) loss: 5.4647 -- time: 1.2622 sec.\n",
      "Step(30980) loss: 5.2232 -- time: 4.3758 sec.\n",
      "Step(30990) loss: 5.7271 -- time: 4.5175 sec.\n",
      "Step(31000) loss: 5.9219 -- time: 4.4948 sec.\n",
      "Step(31010) loss: 5.6968 -- time: 4.5480 sec.\n",
      "Step(31020) loss: 5.4983 -- time: 4.4987 sec.\n",
      "Step(31030) loss: 5.1928 -- time: 4.4017 sec.\n",
      "Step(31040) loss: 5.5143 -- time: 4.3795 sec.\n",
      "Step(31050) loss: 5.4651 -- time: 4.4811 sec.\n",
      "Step(31060) loss: 5.5770 -- time: 4.4770 sec.\n",
      "Step(31070) loss: 5.4858 -- time: 4.5529 sec.\n",
      "Step(31080) loss: 6.0151 -- time: 4.3616 sec.\n",
      "Step(31090) loss: 5.2166 -- time: 4.3756 sec.\n",
      "Step(31100) loss: 5.4240 -- time: 4.4251 sec.\n",
      "Step(31110) loss: 5.6644 -- time: 4.5878 sec.\n",
      "Step(31120) loss: 5.7965 -- time: 4.7020 sec.\n",
      "Step(31130) loss: 7.2870 -- time: 4.5871 sec.\n",
      "Step(31140) loss: 20.0621 -- time: 4.3878 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1058.8667 - val_loss: 0.0000\n",
      "time: 81.8982 sec.\n",
      "time_left: 35.4892 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 175/200\n",
      "----------------------------------------------------------------------\n",
      "Step(31150) loss: 7.5721 -- time: 1.7879 sec.\n",
      "Step(31160) loss: 7.1822 -- time: 4.4394 sec.\n",
      "Step(31170) loss: 7.2189 -- time: 4.3749 sec.\n",
      "Step(31180) loss: 6.8539 -- time: 4.5134 sec.\n",
      "Step(31190) loss: 7.3760 -- time: 4.5620 sec.\n",
      "Step(31200) loss: 6.6214 -- time: 4.4487 sec.\n",
      "Step(31210) loss: 6.3839 -- time: 4.4898 sec.\n",
      "Step(31220) loss: 6.5365 -- time: 4.5488 sec.\n",
      "Step(31230) loss: 6.6835 -- time: 4.4338 sec.\n",
      "Step(31240) loss: 6.3675 -- time: 4.4728 sec.\n",
      "Step(31250) loss: 6.2231 -- time: 4.3843 sec.\n",
      "Step(31260) loss: 5.9935 -- time: 4.3624 sec.\n",
      "Step(31270) loss: 6.5430 -- time: 4.4293 sec.\n",
      "Step(31280) loss: 6.0556 -- time: 4.3233 sec.\n",
      "Step(31290) loss: 6.3595 -- time: 4.3752 sec.\n",
      "Step(31300) loss: 5.8669 -- time: 4.4522 sec.\n",
      "Step(31310) loss: 6.5145 -- time: 4.6136 sec.\n",
      "Step(31320) loss: 5.9801 -- time: 4.4655 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1165.4062 - val_loss: 0.0000\n",
      "time: 81.4701 sec.\n",
      "time_left: 33.9459 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 176/200\n",
      "----------------------------------------------------------------------\n",
      "Step(31330) loss: 6.3323 -- time: 2.2226 sec.\n",
      "Step(31340) loss: 5.9269 -- time: 4.5009 sec.\n",
      "Step(31350) loss: 6.1066 -- time: 4.4505 sec.\n",
      "Step(31360) loss: 5.8789 -- time: 4.4571 sec.\n",
      "Step(31370) loss: 5.9042 -- time: 4.5709 sec.\n",
      "Step(31380) loss: 6.1321 -- time: 4.5121 sec.\n",
      "Step(31390) loss: 5.7090 -- time: 4.5383 sec.\n",
      "Step(31400) loss: 6.1870 -- time: 4.4159 sec.\n",
      "Step(31410) loss: 5.8029 -- time: 4.4009 sec.\n",
      "Step(31420) loss: 6.1786 -- time: 4.4603 sec.\n",
      "Step(31430) loss: 6.6085 -- time: 4.6337 sec.\n",
      "Step(31440) loss: 5.8949 -- time: 4.4225 sec.\n",
      "Step(31450) loss: 5.4436 -- time: 4.3878 sec.\n",
      "Step(31460) loss: 5.8116 -- time: 4.5174 sec.\n",
      "Step(31470) loss: 5.4004 -- time: 4.4936 sec.\n",
      "Step(31480) loss: 5.5155 -- time: 4.5552 sec.\n",
      "Step(31490) loss: 6.3239 -- time: 4.4606 sec.\n",
      "Step(31500) loss: 5.9656 -- time: 4.3079 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1070.1085 - val_loss: 0.0000\n",
      "time: 81.8898 sec.\n",
      "time_left: 32.7559 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 177/200\n",
      "----------------------------------------------------------------------\n",
      "Step(31510) loss: 5.4131 -- time: 2.6045 sec.\n",
      "Step(31520) loss: 6.4777 -- time: 4.5031 sec.\n",
      "Step(31530) loss: 5.6121 -- time: 4.3972 sec.\n",
      "Step(31540) loss: 5.9143 -- time: 4.5261 sec.\n",
      "Step(31550) loss: 5.2957 -- time: 4.5251 sec.\n",
      "Step(31560) loss: 5.7866 -- time: 4.4313 sec.\n",
      "Step(31570) loss: 5.8837 -- time: 4.4809 sec.\n",
      "Step(31580) loss: 5.9675 -- time: 4.3145 sec.\n",
      "Step(31590) loss: 5.4624 -- time: 4.4739 sec.\n",
      "Step(31600) loss: 5.7506 -- time: 4.5191 sec.\n",
      "Step(31610) loss: 5.7868 -- time: 4.3783 sec.\n",
      "Step(31620) loss: 5.8204 -- time: 4.5578 sec.\n",
      "Step(31630) loss: 5.5386 -- time: 4.5739 sec.\n",
      "Step(31640) loss: 5.5731 -- time: 4.3662 sec.\n",
      "Step(31650) loss: 5.6666 -- time: 4.4820 sec.\n",
      "Step(31660) loss: 5.4350 -- time: 4.5464 sec.\n",
      "Step(31670) loss: 5.4832 -- time: 4.4095 sec.\n",
      "Step(31680) loss: 6.0856 -- time: 4.4833 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1026.1098 - val_loss: 0.0000\n",
      "time: 81.6620 sec.\n",
      "time_left: 31.3038 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 178/200\n",
      "----------------------------------------------------------------------\n",
      "Step(31690) loss: 5.7824 -- time: 3.0374 sec.\n",
      "Step(31700) loss: 5.4214 -- time: 4.3838 sec.\n",
      "Step(31710) loss: 5.6988 -- time: 4.3292 sec.\n",
      "Step(31720) loss: 5.4352 -- time: 4.4897 sec.\n",
      "Step(31730) loss: 5.1306 -- time: 4.4132 sec.\n",
      "Step(31740) loss: 5.4337 -- time: 4.4823 sec.\n",
      "Step(31750) loss: 5.5115 -- time: 4.3396 sec.\n",
      "Step(31760) loss: 5.9037 -- time: 4.4650 sec.\n",
      "Step(31770) loss: 5.3445 -- time: 4.4870 sec.\n",
      "Step(31780) loss: 5.5186 -- time: 4.5131 sec.\n",
      "Step(31790) loss: 5.5241 -- time: 4.4099 sec.\n",
      "Step(31800) loss: 5.8422 -- time: 4.5738 sec.\n",
      "Step(31810) loss: 6.4567 -- time: 4.4015 sec.\n",
      "Step(31820) loss: 5.3054 -- time: 4.3616 sec.\n",
      "Step(31830) loss: 5.6171 -- time: 4.4560 sec.\n",
      "Step(31840) loss: 5.6138 -- time: 4.4385 sec.\n",
      "Step(31850) loss: 6.1251 -- time: 4.4995 sec.\n",
      "Step(31860) loss: 5.5500 -- time: 4.4820 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1011.0080 - val_loss: 0.0000\n",
      "time: 81.2231 sec.\n",
      "time_left: 29.7818 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 179/200\n",
      "----------------------------------------------------------------------\n",
      "Step(31870) loss: 5.8776 -- time: 3.6045 sec.\n",
      "Step(31880) loss: 11.2962 -- time: 4.4133 sec.\n",
      "Step(31890) loss: 7.9733 -- time: 4.4454 sec.\n",
      "Step(31900) loss: 7.4547 -- time: 4.4129 sec.\n",
      "Step(31910) loss: 7.2964 -- time: 4.4315 sec.\n",
      "Step(31920) loss: 6.9751 -- time: 4.4176 sec.\n",
      "Step(31930) loss: 7.0173 -- time: 4.6587 sec.\n",
      "Step(31940) loss: 6.7815 -- time: 4.5698 sec.\n",
      "Step(31950) loss: 7.0512 -- time: 4.5504 sec.\n",
      "Step(31960) loss: 6.6835 -- time: 4.5100 sec.\n",
      "Step(31970) loss: 6.1533 -- time: 4.2355 sec.\n",
      "Step(31980) loss: 6.6998 -- time: 4.5752 sec.\n",
      "Step(31990) loss: 6.3916 -- time: 4.4167 sec.\n",
      "Step(32000) loss: 6.7410 -- time: 4.2974 sec.\n",
      "Step(32010) loss: 6.5895 -- time: 4.4669 sec.\n",
      "Step(32020) loss: 6.1817 -- time: 4.7206 sec.\n",
      "Step(32030) loss: 5.8582 -- time: 4.4570 sec.\n",
      "Step(32040) loss: 6.7971 -- time: 4.5195 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1318.9099 - val_loss: 0.0000\n",
      "time: 81.8437 sec.\n",
      "time_left: 28.6453 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 180/200\n",
      "----------------------------------------------------------------------\n",
      "Step(32050) loss: 6.0239 -- time: 4.0825 sec.\n",
      "Step(32060) loss: 5.9231 -- time: 4.4022 sec.\n",
      "Step(32070) loss: 6.4172 -- time: 4.4823 sec.\n",
      "Step(32080) loss: 5.8566 -- time: 4.6056 sec.\n",
      "Step(32090) loss: 5.4604 -- time: 4.5852 sec.\n",
      "Step(32100) loss: 5.7084 -- time: 4.4830 sec.\n",
      "Step(32110) loss: 5.6721 -- time: 4.5048 sec.\n",
      "Step(32120) loss: 6.0930 -- time: 4.4745 sec.\n",
      "Step(32130) loss: 5.9963 -- time: 4.5545 sec.\n",
      "Step(32140) loss: 6.4886 -- time: 4.6634 sec.\n",
      "Step(32150) loss: 6.4596 -- time: 4.4962 sec.\n",
      "Step(32160) loss: 5.5670 -- time: 4.5302 sec.\n",
      "Step(32170) loss: 6.3420 -- time: 4.4759 sec.\n",
      "Step(32180) loss: 5.9686 -- time: 4.6777 sec.\n",
      "Step(32190) loss: 5.8086 -- time: 4.5532 sec.\n",
      "Step(32200) loss: 6.2462 -- time: 4.4697 sec.\n",
      "Step(32210) loss: 6.0137 -- time: 4.5371 sec.\n",
      "Step(32220) loss: 5.9299 -- time: 4.5042 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1098.5946 - val_loss: 1102.4218\n",
      "time: 118.7391 sec.\n",
      "time_left: 39.5797 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 181/200\n",
      "----------------------------------------------------------------------\n",
      "Step(32230) loss: 6.2148 -- time: 4.4008 sec.\n",
      "Step(32240) loss: 6.5197 -- time: 4.6086 sec.\n",
      "Step(32250) loss: 6.0608 -- time: 4.2755 sec.\n",
      "Step(32260) loss: 6.2329 -- time: 4.4760 sec.\n",
      "Step(32270) loss: 6.1306 -- time: 4.5213 sec.\n",
      "Step(32280) loss: 6.1417 -- time: 4.4240 sec.\n",
      "Step(32290) loss: 6.2567 -- time: 4.3871 sec.\n",
      "Step(32300) loss: 6.6178 -- time: 4.5320 sec.\n",
      "Step(32310) loss: 6.0752 -- time: 4.4968 sec.\n",
      "Step(32320) loss: 6.1607 -- time: 4.6804 sec.\n",
      "Step(32330) loss: 5.6309 -- time: 4.5698 sec.\n",
      "Step(32340) loss: 6.2657 -- time: 4.6059 sec.\n",
      "Step(32350) loss: 6.1276 -- time: 4.5168 sec.\n",
      "Step(32360) loss: 6.6342 -- time: 4.4202 sec.\n",
      "Step(32370) loss: 5.8403 -- time: 4.4704 sec.\n",
      "Step(32380) loss: 6.0215 -- time: 4.5325 sec.\n",
      "Step(32390) loss: 6.4285 -- time: 4.4851 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1095.4166 - val_loss: 0.0000\n",
      "time: 82.0601 sec.\n",
      "time_left: 25.9857 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 182/200\n",
      "----------------------------------------------------------------------\n",
      "Step(32400) loss: 5.9157 -- time: 0.4221 sec.\n",
      "Step(32410) loss: 5.9627 -- time: 4.4477 sec.\n",
      "Step(32420) loss: 6.0212 -- time: 4.4700 sec.\n",
      "Step(32430) loss: 5.7762 -- time: 4.4971 sec.\n",
      "Step(32440) loss: 5.4947 -- time: 4.4360 sec.\n",
      "Step(32450) loss: 5.6199 -- time: 4.6502 sec.\n",
      "Step(32460) loss: 5.9359 -- time: 4.4169 sec.\n",
      "Step(32470) loss: 5.8219 -- time: 4.6440 sec.\n",
      "Step(32480) loss: 5.8011 -- time: 4.5896 sec.\n",
      "Step(32490) loss: 6.0480 -- time: 4.3306 sec.\n",
      "Step(32500) loss: 5.5146 -- time: 4.3901 sec.\n",
      "Step(32510) loss: 5.5085 -- time: 4.4083 sec.\n",
      "Step(32520) loss: 6.1795 -- time: 4.5482 sec.\n",
      "Step(32530) loss: 6.1636 -- time: 4.6142 sec.\n",
      "Step(32540) loss: 5.7671 -- time: 4.5074 sec.\n",
      "Step(32550) loss: 5.8340 -- time: 4.5643 sec.\n",
      "Step(32560) loss: 5.4611 -- time: 4.5225 sec.\n",
      "Step(32570) loss: 5.8640 -- time: 4.5530 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1046.4256 - val_loss: 0.0000\n",
      "time: 82.4484 sec.\n",
      "time_left: 24.7345 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 183/200\n",
      "----------------------------------------------------------------------\n",
      "Step(32580) loss: 5.5881 -- time: 0.7544 sec.\n",
      "Step(32590) loss: 5.4720 -- time: 4.3468 sec.\n",
      "Step(32600) loss: 6.0921 -- time: 4.5617 sec.\n",
      "Step(32610) loss: 5.5606 -- time: 4.5578 sec.\n",
      "Step(32620) loss: 5.2256 -- time: 4.6396 sec.\n",
      "Step(32630) loss: 5.8683 -- time: 4.4867 sec.\n",
      "Step(32640) loss: 5.6664 -- time: 4.6032 sec.\n",
      "Step(32650) loss: 5.7108 -- time: 4.5112 sec.\n",
      "Step(32660) loss: 5.5187 -- time: 4.5266 sec.\n",
      "Step(32670) loss: 5.6337 -- time: 4.5730 sec.\n",
      "Step(32680) loss: 5.5305 -- time: 4.3690 sec.\n",
      "Step(32690) loss: 6.2179 -- time: 4.4414 sec.\n",
      "Step(32700) loss: 5.5213 -- time: 4.4540 sec.\n",
      "Step(32710) loss: 5.5839 -- time: 4.5840 sec.\n",
      "Step(32720) loss: 6.0675 -- time: 4.6948 sec.\n",
      "Step(32730) loss: 5.6354 -- time: 4.4250 sec.\n",
      "Step(32740) loss: 5.8312 -- time: 4.5339 sec.\n",
      "Step(32750) loss: 5.9967 -- time: 4.3530 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1028.9970 - val_loss: 0.0000\n",
      "time: 82.3977 sec.\n",
      "time_left: 23.3460 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 184/200\n",
      "----------------------------------------------------------------------\n",
      "Step(32760) loss: 5.3152 -- time: 1.2838 sec.\n",
      "Step(32770) loss: 5.9778 -- time: 4.4717 sec.\n",
      "Step(32780) loss: 5.3978 -- time: 4.4611 sec.\n",
      "Step(32790) loss: 6.0686 -- time: 4.4712 sec.\n",
      "Step(32800) loss: 5.8348 -- time: 4.4542 sec.\n",
      "Step(32810) loss: 5.1566 -- time: 4.3787 sec.\n",
      "Step(32820) loss: 5.8644 -- time: 4.5553 sec.\n",
      "Step(32830) loss: 5.5341 -- time: 4.4902 sec.\n",
      "Step(32840) loss: 5.5815 -- time: 4.3384 sec.\n",
      "Step(32850) loss: 5.4618 -- time: 4.4936 sec.\n",
      "Step(32860) loss: 5.1645 -- time: 4.4820 sec.\n",
      "Step(32870) loss: 5.7592 -- time: 4.3536 sec.\n",
      "Step(32880) loss: 5.6110 -- time: 4.4067 sec.\n",
      "Step(32890) loss: 5.7977 -- time: 4.4716 sec.\n",
      "Step(32900) loss: 5.5654 -- time: 4.5002 sec.\n",
      "Step(32910) loss: 5.6416 -- time: 4.4950 sec.\n",
      "Step(32920) loss: 5.4238 -- time: 4.5294 sec.\n",
      "Step(32930) loss: 5.7291 -- time: 4.3473 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1025.0304 - val_loss: 0.0000\n",
      "time: 81.3990 sec.\n",
      "time_left: 21.7064 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 185/200\n",
      "----------------------------------------------------------------------\n",
      "Step(32940) loss: 5.6708 -- time: 1.7210 sec.\n",
      "Step(32950) loss: 5.5640 -- time: 4.3758 sec.\n",
      "Step(32960) loss: 5.9610 -- time: 4.3729 sec.\n",
      "Step(32970) loss: 6.0382 -- time: 4.4510 sec.\n",
      "Step(32980) loss: 5.8386 -- time: 4.5385 sec.\n",
      "Step(32990) loss: 5.5918 -- time: 4.4869 sec.\n",
      "Step(33000) loss: 5.9814 -- time: 4.4757 sec.\n",
      "Step(33010) loss: 5.5994 -- time: 4.5514 sec.\n",
      "Step(33020) loss: 5.5733 -- time: 4.4720 sec.\n",
      "Step(33030) loss: 5.6727 -- time: 4.3959 sec.\n",
      "Step(33040) loss: 5.1947 -- time: 4.4817 sec.\n",
      "Step(33050) loss: 5.5101 -- time: 4.5445 sec.\n",
      "Step(33060) loss: 5.2322 -- time: 4.3341 sec.\n",
      "Step(33070) loss: 5.6888 -- time: 4.4074 sec.\n",
      "Step(33080) loss: 6.1980 -- time: 4.3988 sec.\n",
      "Step(33090) loss: 6.8038 -- time: 4.4927 sec.\n",
      "Step(33100) loss: 6.2866 -- time: 4.4977 sec.\n",
      "Step(33110) loss: 5.8600 -- time: 4.4112 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1024.1551 - val_loss: 0.0000\n",
      "time: 81.4677 sec.\n",
      "time_left: 20.3669 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 186/200\n",
      "----------------------------------------------------------------------\n",
      "Step(33120) loss: 6.0565 -- time: 2.1812 sec.\n",
      "Step(33130) loss: 5.7903 -- time: 4.5606 sec.\n",
      "Step(33140) loss: 5.5331 -- time: 4.3468 sec.\n",
      "Step(33150) loss: 6.0239 -- time: 4.4476 sec.\n",
      "Step(33160) loss: 5.6006 -- time: 4.4086 sec.\n",
      "Step(33170) loss: 6.0530 -- time: 4.5152 sec.\n",
      "Step(33180) loss: 5.7800 -- time: 4.4426 sec.\n",
      "Step(33190) loss: 5.7287 -- time: 4.6087 sec.\n",
      "Step(33200) loss: 6.1731 -- time: 4.4810 sec.\n",
      "Step(33210) loss: 6.0488 -- time: 4.3507 sec.\n",
      "Step(33220) loss: 6.4274 -- time: 4.4569 sec.\n",
      "Step(33230) loss: 5.5242 -- time: 4.4602 sec.\n",
      "Step(33240) loss: 5.3661 -- time: 4.4902 sec.\n",
      "Step(33250) loss: 5.3501 -- time: 4.5941 sec.\n",
      "Step(33260) loss: 5.6556 -- time: 4.6747 sec.\n",
      "Step(33270) loss: 6.0759 -- time: 4.4618 sec.\n",
      "Step(33280) loss: 5.3343 -- time: 4.4434 sec.\n",
      "Step(33290) loss: 5.4160 -- time: 4.5060 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1029.8929 - val_loss: 0.0000\n",
      "time: 81.9288 sec.\n",
      "time_left: 19.1167 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 187/200\n",
      "----------------------------------------------------------------------\n",
      "Step(33300) loss: 5.6194 -- time: 2.6438 sec.\n",
      "Step(33310) loss: 5.3083 -- time: 4.4089 sec.\n",
      "Step(33320) loss: 5.1847 -- time: 4.4653 sec.\n",
      "Step(33330) loss: 5.5556 -- time: 4.4581 sec.\n",
      "Step(33340) loss: 5.7390 -- time: 4.3598 sec.\n",
      "Step(33350) loss: 5.7975 -- time: 4.5378 sec.\n",
      "Step(33360) loss: 5.5048 -- time: 4.4996 sec.\n",
      "Step(33370) loss: 6.3061 -- time: 4.4558 sec.\n",
      "Step(33380) loss: 5.5574 -- time: 4.4559 sec.\n",
      "Step(33390) loss: 5.9304 -- time: 4.5036 sec.\n",
      "Step(33400) loss: 5.4071 -- time: 4.4436 sec.\n",
      "Step(33410) loss: 5.3294 -- time: 4.3824 sec.\n",
      "Step(33420) loss: 6.0070 -- time: 4.5776 sec.\n",
      "Step(33430) loss: 5.4516 -- time: 4.4334 sec.\n",
      "Step(33440) loss: 5.2289 -- time: 4.5173 sec.\n",
      "Step(33450) loss: 5.3202 -- time: 4.3953 sec.\n",
      "Step(33460) loss: 5.8471 -- time: 4.5437 sec.\n",
      "Step(33470) loss: 5.9293 -- time: 4.5852 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1011.1555 - val_loss: 0.0000\n",
      "time: 81.8241 sec.\n",
      "time_left: 17.7286 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 188/200\n",
      "----------------------------------------------------------------------\n",
      "Step(33480) loss: 6.0049 -- time: 3.1380 sec.\n",
      "Step(33490) loss: 6.2031 -- time: 4.4377 sec.\n",
      "Step(33500) loss: 5.4174 -- time: 4.4454 sec.\n",
      "Step(33510) loss: 5.3362 -- time: 4.4039 sec.\n",
      "Step(33520) loss: 5.1099 -- time: 4.5721 sec.\n",
      "Step(33530) loss: 5.4381 -- time: 4.4266 sec.\n",
      "Step(33540) loss: 5.2937 -- time: 4.5351 sec.\n",
      "Step(33550) loss: 5.6921 -- time: 4.5172 sec.\n",
      "Step(33560) loss: 5.8497 -- time: 4.3501 sec.\n",
      "Step(33570) loss: 5.6284 -- time: 4.4433 sec.\n",
      "Step(33580) loss: 5.6677 -- time: 4.3560 sec.\n",
      "Step(33590) loss: 5.5992 -- time: 4.4902 sec.\n",
      "Step(33600) loss: 5.4642 -- time: 4.3965 sec.\n",
      "Step(33610) loss: 6.1686 -- time: 4.5334 sec.\n",
      "Step(33620) loss: 6.0816 -- time: 4.4415 sec.\n",
      "Step(33630) loss: 5.2444 -- time: 4.4696 sec.\n",
      "Step(33640) loss: 5.1019 -- time: 4.3842 sec.\n",
      "Step(33650) loss: 5.9654 -- time: 4.3086 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 998.0447 - val_loss: 0.0000\n",
      "time: 81.3128 sec.\n",
      "time_left: 16.2626 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 189/200\n",
      "----------------------------------------------------------------------\n",
      "Step(33660) loss: 4.8742 -- time: 3.5090 sec.\n",
      "Step(33670) loss: 5.7612 -- time: 4.4093 sec.\n",
      "Step(33680) loss: 5.4809 -- time: 4.4821 sec.\n",
      "Step(33690) loss: 6.0156 -- time: 4.5418 sec.\n",
      "Step(33700) loss: 5.4089 -- time: 4.5514 sec.\n",
      "Step(33710) loss: 5.2806 -- time: 4.4604 sec.\n",
      "Step(33720) loss: 5.1314 -- time: 4.5036 sec.\n",
      "Step(33730) loss: 5.9412 -- time: 4.2710 sec.\n",
      "Step(33740) loss: 5.3219 -- time: 4.5356 sec.\n",
      "Step(33750) loss: 5.5499 -- time: 4.5962 sec.\n",
      "Step(33760) loss: 5.6352 -- time: 4.4873 sec.\n",
      "Step(33770) loss: 5.9119 -- time: 4.4995 sec.\n",
      "Step(33780) loss: 5.4012 -- time: 4.4874 sec.\n",
      "Step(33790) loss: 5.4606 -- time: 4.5344 sec.\n",
      "Step(33800) loss: 5.7409 -- time: 4.5999 sec.\n",
      "Step(33810) loss: 5.6751 -- time: 4.4510 sec.\n",
      "Step(33820) loss: 5.6809 -- time: 4.5101 sec.\n",
      "Step(33830) loss: 5.5582 -- time: 4.4221 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 999.1012 - val_loss: 0.0000\n",
      "time: 82.0410 sec.\n",
      "time_left: 15.0409 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 190/200\n",
      "----------------------------------------------------------------------\n",
      "Step(33840) loss: 5.2644 -- time: 4.0795 sec.\n",
      "Step(33850) loss: 5.0257 -- time: 4.4552 sec.\n",
      "Step(33860) loss: 5.3634 -- time: 4.4805 sec.\n",
      "Step(33870) loss: 5.6527 -- time: 4.5485 sec.\n",
      "Step(33880) loss: 5.6292 -- time: 4.3742 sec.\n",
      "Step(33890) loss: 5.7288 -- time: 4.4473 sec.\n",
      "Step(33900) loss: 5.7840 -- time: 4.3548 sec.\n",
      "Step(33910) loss: 5.4288 -- time: 4.4804 sec.\n",
      "Step(33920) loss: 5.5378 -- time: 4.5130 sec.\n",
      "Step(33930) loss: 5.5663 -- time: 4.4569 sec.\n",
      "Step(33940) loss: 5.6901 -- time: 4.4762 sec.\n",
      "Step(33950) loss: 5.4168 -- time: 4.5713 sec.\n",
      "Step(33960) loss: 5.0751 -- time: 4.2651 sec.\n",
      "Step(33970) loss: 5.6149 -- time: 4.4807 sec.\n",
      "Step(33980) loss: 5.1062 -- time: 4.5063 sec.\n",
      "Step(33990) loss: 5.7375 -- time: 4.4514 sec.\n",
      "Step(34000) loss: 5.5884 -- time: 4.4262 sec.\n",
      "Step(34010) loss: 5.5075 -- time: 4.3624 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 987.6908 - val_loss: 994.1088\n",
      "time: 117.0286 sec.\n",
      "time_left: 19.5048 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 191/200\n",
      "----------------------------------------------------------------------\n",
      "Step(34020) loss: 5.5543 -- time: 4.6814 sec.\n",
      "Step(34030) loss: 6.0923 -- time: 4.5960 sec.\n",
      "Step(34040) loss: 5.9692 -- time: 4.5748 sec.\n",
      "Step(34050) loss: 6.3471 -- time: 4.6816 sec.\n",
      "Step(34060) loss: 5.9645 -- time: 4.5629 sec.\n",
      "Step(34070) loss: 5.6375 -- time: 4.5175 sec.\n",
      "Step(34080) loss: 5.8961 -- time: 4.5107 sec.\n",
      "Step(34090) loss: 5.5612 -- time: 4.6798 sec.\n",
      "Step(34100) loss: 6.0408 -- time: 4.5387 sec.\n",
      "Step(34110) loss: 6.0606 -- time: 4.7237 sec.\n",
      "Step(34120) loss: 5.9049 -- time: 4.5738 sec.\n",
      "Step(34130) loss: 5.9020 -- time: 4.7035 sec.\n",
      "Step(34140) loss: 5.7582 -- time: 4.7047 sec.\n",
      "Step(34150) loss: 4.9310 -- time: 4.5074 sec.\n",
      "Step(34160) loss: 5.6192 -- time: 4.4881 sec.\n",
      "Step(34170) loss: 5.2446 -- time: 4.5067 sec.\n",
      "Step(34180) loss: 6.1415 -- time: 4.5643 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1038.6923 - val_loss: 0.0000\n",
      "time: 83.9431 sec.\n",
      "time_left: 12.5915 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 192/200\n",
      "----------------------------------------------------------------------\n",
      "Step(34190) loss: 6.1244 -- time: 0.3983 sec.\n",
      "Step(34200) loss: 5.2504 -- time: 4.4986 sec.\n",
      "Step(34210) loss: 6.0908 -- time: 4.6802 sec.\n",
      "Step(34220) loss: 5.0463 -- time: 4.5475 sec.\n",
      "Step(34230) loss: 5.3625 -- time: 4.6054 sec.\n",
      "Step(34240) loss: 5.1907 -- time: 4.5732 sec.\n",
      "Step(34250) loss: 5.3840 -- time: 4.4904 sec.\n",
      "Step(34260) loss: 5.9082 -- time: 4.4360 sec.\n",
      "Step(34270) loss: 5.4056 -- time: 4.5394 sec.\n",
      "Step(34280) loss: 6.0460 -- time: 4.5613 sec.\n",
      "Step(34290) loss: 5.9921 -- time: 4.7118 sec.\n",
      "Step(34300) loss: 5.5617 -- time: 4.5974 sec.\n",
      "Step(34310) loss: 6.1195 -- time: 4.6112 sec.\n",
      "Step(34320) loss: 6.2500 -- time: 4.5061 sec.\n",
      "Step(34330) loss: 7.0002 -- time: 4.4156 sec.\n",
      "Step(34340) loss: 6.2281 -- time: 4.4723 sec.\n",
      "Step(34350) loss: 6.0925 -- time: 4.5572 sec.\n",
      "Step(34360) loss: 6.3073 -- time: 4.5218 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1071.1104 - val_loss: 0.0000\n",
      "time: 83.0447 sec.\n",
      "time_left: 11.0726 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 193/200\n",
      "----------------------------------------------------------------------\n",
      "Step(34370) loss: 6.2898 -- time: 0.7926 sec.\n",
      "Step(34380) loss: 6.2106 -- time: 4.3607 sec.\n",
      "Step(34390) loss: 6.2605 -- time: 4.4492 sec.\n",
      "Step(34400) loss: 5.1856 -- time: 4.3813 sec.\n",
      "Step(34410) loss: 5.4496 -- time: 4.6648 sec.\n",
      "Step(34420) loss: 5.7866 -- time: 4.3949 sec.\n",
      "Step(34430) loss: 5.8355 -- time: 4.4839 sec.\n",
      "Step(34440) loss: 6.0292 -- time: 4.6339 sec.\n",
      "Step(34450) loss: 5.5680 -- time: 4.4954 sec.\n",
      "Step(34460) loss: 5.7621 -- time: 4.5147 sec.\n",
      "Step(34470) loss: 5.3897 -- time: 4.3060 sec.\n",
      "Step(34480) loss: 5.6772 -- time: 4.4961 sec.\n",
      "Step(34490) loss: 5.7437 -- time: 4.3582 sec.\n",
      "Step(34500) loss: 5.6685 -- time: 4.3822 sec.\n",
      "Step(34510) loss: 5.6429 -- time: 4.3834 sec.\n",
      "Step(34520) loss: 5.8185 -- time: 4.4459 sec.\n",
      "Step(34530) loss: 5.6348 -- time: 4.3648 sec.\n",
      "Step(34540) loss: 5.7278 -- time: 4.4853 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1043.9336 - val_loss: 0.0000\n",
      "time: 81.3766 sec.\n",
      "time_left: 9.4939 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 194/200\n",
      "----------------------------------------------------------------------\n",
      "Step(34550) loss: 5.8295 -- time: 1.2787 sec.\n",
      "Step(34560) loss: 5.6599 -- time: 4.4597 sec.\n",
      "Step(34570) loss: 6.3093 -- time: 4.4514 sec.\n",
      "Step(34580) loss: 5.6245 -- time: 4.5336 sec.\n",
      "Step(34590) loss: 5.5204 -- time: 4.4059 sec.\n",
      "Step(34600) loss: 5.8336 -- time: 4.4714 sec.\n",
      "Step(34610) loss: 5.2800 -- time: 4.3531 sec.\n",
      "Step(34620) loss: 5.4985 -- time: 4.3117 sec.\n",
      "Step(34630) loss: 5.4037 -- time: 4.4928 sec.\n",
      "Step(34640) loss: 5.2977 -- time: 4.3986 sec.\n",
      "Step(34650) loss: 5.5782 -- time: 4.6436 sec.\n",
      "Step(34660) loss: 5.4964 -- time: 4.4205 sec.\n",
      "Step(34670) loss: 5.4353 -- time: 4.4821 sec.\n",
      "Step(34680) loss: 5.4682 -- time: 4.4348 sec.\n",
      "Step(34690) loss: 6.1094 -- time: 4.4184 sec.\n",
      "Step(34700) loss: 5.7018 -- time: 4.4375 sec.\n",
      "Step(34710) loss: 5.5647 -- time: 4.5088 sec.\n",
      "Step(34720) loss: 5.3794 -- time: 4.4697 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1009.2455 - val_loss: 0.0000\n",
      "time: 81.4332 sec.\n",
      "time_left: 8.1433 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 195/200\n",
      "----------------------------------------------------------------------\n",
      "Step(34730) loss: 5.9926 -- time: 1.6735 sec.\n",
      "Step(34740) loss: 5.3801 -- time: 4.4741 sec.\n",
      "Step(34750) loss: 5.2670 -- time: 4.2845 sec.\n",
      "Step(34760) loss: 5.6906 -- time: 4.3385 sec.\n",
      "Step(34770) loss: 5.3445 -- time: 4.3767 sec.\n",
      "Step(34780) loss: 5.6372 -- time: 4.4224 sec.\n",
      "Step(34790) loss: 5.9300 -- time: 4.4977 sec.\n",
      "Step(34800) loss: 5.9221 -- time: 4.3939 sec.\n",
      "Step(34810) loss: 5.9641 -- time: 4.5739 sec.\n",
      "Step(34820) loss: 5.6767 -- time: 4.4818 sec.\n",
      "Step(34830) loss: 6.0518 -- time: 4.4658 sec.\n",
      "Step(34840) loss: 5.2974 -- time: 4.4741 sec.\n",
      "Step(34850) loss: 5.6766 -- time: 4.5295 sec.\n",
      "Step(34860) loss: 5.3366 -- time: 4.6256 sec.\n",
      "Step(34870) loss: 6.3770 -- time: 4.4029 sec.\n",
      "Step(34880) loss: 5.6853 -- time: 4.4374 sec.\n",
      "Step(34890) loss: 5.6209 -- time: 4.5824 sec.\n",
      "Step(34900) loss: 5.7882 -- time: 4.4106 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1003.4706 - val_loss: 0.0000\n",
      "time: 81.4778 sec.\n",
      "time_left: 6.7898 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 196/200\n",
      "----------------------------------------------------------------------\n",
      "Step(34910) loss: 5.4656 -- time: 2.1878 sec.\n",
      "Step(34920) loss: 5.1198 -- time: 4.6104 sec.\n",
      "Step(34930) loss: 5.4256 -- time: 4.4808 sec.\n",
      "Step(34940) loss: 5.2998 -- time: 4.4615 sec.\n",
      "Step(34950) loss: 5.2887 -- time: 4.5439 sec.\n",
      "Step(34960) loss: 5.4898 -- time: 4.3599 sec.\n",
      "Step(34970) loss: 5.2815 -- time: 4.5224 sec.\n",
      "Step(34980) loss: 5.5665 -- time: 4.3044 sec.\n",
      "Step(34990) loss: 5.2999 -- time: 4.4234 sec.\n",
      "Step(35000) loss: 5.6152 -- time: 4.5341 sec.\n",
      "Step(35010) loss: 5.6116 -- time: 4.3648 sec.\n",
      "Step(35020) loss: 5.4471 -- time: 4.4981 sec.\n",
      "Step(35030) loss: 6.0029 -- time: 4.4309 sec.\n",
      "Step(35040) loss: 5.7727 -- time: 4.5223 sec.\n",
      "Step(35050) loss: 5.7485 -- time: 4.4274 sec.\n",
      "Step(35060) loss: 5.3697 -- time: 4.5141 sec.\n",
      "Step(35070) loss: 5.3191 -- time: 4.3478 sec.\n",
      "Step(35080) loss: 5.4197 -- time: 4.5249 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 998.1601 - val_loss: 0.0000\n",
      "time: 81.5219 sec.\n",
      "time_left: 5.4348 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 197/200\n",
      "----------------------------------------------------------------------\n",
      "Step(35090) loss: 5.2981 -- time: 2.6256 sec.\n",
      "Step(35100) loss: 6.1148 -- time: 4.5555 sec.\n",
      "Step(35110) loss: 5.6754 -- time: 4.4715 sec.\n",
      "Step(35120) loss: 5.8011 -- time: 4.4387 sec.\n",
      "Step(35130) loss: 5.4228 -- time: 4.3686 sec.\n",
      "Step(35140) loss: 5.6100 -- time: 4.5282 sec.\n",
      "Step(35150) loss: 5.0150 -- time: 4.4541 sec.\n",
      "Step(35160) loss: 5.0567 -- time: 4.3882 sec.\n",
      "Step(35170) loss: 5.3254 -- time: 4.5791 sec.\n",
      "Step(35180) loss: 6.3111 -- time: 4.4579 sec.\n",
      "Step(35190) loss: 6.0625 -- time: 4.5828 sec.\n",
      "Step(35200) loss: 6.0678 -- time: 4.3922 sec.\n",
      "Step(35210) loss: 5.7775 -- time: 4.5711 sec.\n",
      "Step(35220) loss: 5.0958 -- time: 4.6100 sec.\n",
      "Step(35230) loss: 5.9768 -- time: 4.5335 sec.\n",
      "Step(35240) loss: 5.2022 -- time: 4.5684 sec.\n",
      "Step(35250) loss: 5.0768 -- time: 4.4826 sec.\n",
      "Step(35260) loss: 5.6046 -- time: 4.5619 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1001.5251 - val_loss: 0.0000\n",
      "time: 82.2160 sec.\n",
      "time_left: 4.1108 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 198/200\n",
      "----------------------------------------------------------------------\n",
      "Step(35270) loss: 6.1824 -- time: 3.1079 sec.\n",
      "Step(35280) loss: 5.6966 -- time: 4.5474 sec.\n",
      "Step(35290) loss: 5.6171 -- time: 4.4951 sec.\n",
      "Step(35300) loss: 5.8134 -- time: 4.6533 sec.\n",
      "Step(35310) loss: 5.5913 -- time: 4.4686 sec.\n",
      "Step(35320) loss: 5.5129 -- time: 4.5108 sec.\n",
      "Step(35330) loss: 5.8077 -- time: 4.4698 sec.\n",
      "Step(35340) loss: 5.7652 -- time: 4.3637 sec.\n",
      "Step(35350) loss: 6.5967 -- time: 4.4076 sec.\n",
      "Step(35360) loss: 6.9239 -- time: 4.4315 sec.\n",
      "Step(35370) loss: 6.0518 -- time: 4.3789 sec.\n",
      "Step(35380) loss: 6.2098 -- time: 4.5501 sec.\n",
      "Step(35390) loss: 5.8011 -- time: 4.4733 sec.\n",
      "Step(35400) loss: 5.8556 -- time: 4.4298 sec.\n",
      "Step(35410) loss: 5.7815 -- time: 4.5288 sec.\n",
      "Step(35420) loss: 5.8419 -- time: 4.4256 sec.\n",
      "Step(35430) loss: 5.8090 -- time: 4.3360 sec.\n",
      "Step(35440) loss: 5.2827 -- time: 4.5631 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1054.1365 - val_loss: 0.0000\n",
      "time: 81.7926 sec.\n",
      "time_left: 2.7264 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 199/200\n",
      "----------------------------------------------------------------------\n",
      "Step(35450) loss: 5.4644 -- time: 3.5776 sec.\n",
      "Step(35460) loss: 5.9802 -- time: 4.5315 sec.\n",
      "Step(35470) loss: 5.2400 -- time: 4.5057 sec.\n",
      "Step(35480) loss: 5.7026 -- time: 4.3425 sec.\n",
      "Step(35490) loss: 5.7751 -- time: 4.5075 sec.\n",
      "Step(35500) loss: 5.9108 -- time: 4.4527 sec.\n",
      "Step(35510) loss: 6.3468 -- time: 4.4370 sec.\n",
      "Step(35520) loss: 6.1479 -- time: 4.5222 sec.\n",
      "Step(35530) loss: 5.9759 -- time: 4.6142 sec.\n",
      "Step(35540) loss: 5.5251 -- time: 4.4544 sec.\n",
      "Step(35550) loss: 5.9313 -- time: 4.4511 sec.\n",
      "Step(35560) loss: 5.6558 -- time: 4.5447 sec.\n",
      "Step(35570) loss: 5.7732 -- time: 4.4129 sec.\n",
      "Step(35580) loss: 5.7539 -- time: 4.5132 sec.\n",
      "Step(35590) loss: 5.4354 -- time: 4.4220 sec.\n",
      "Step(35600) loss: 5.2297 -- time: 4.4746 sec.\n",
      "Step(35610) loss: 5.9363 -- time: 4.5206 sec.\n",
      "Step(35620) loss: 5.8308 -- time: 4.4061 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1044.3548 - val_loss: 0.0000\n",
      "time: 81.8714 sec.\n",
      "time_left: 1.3645 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 200/200\n",
      "----------------------------------------------------------------------\n",
      "Step(35630) loss: 6.2546 -- time: 4.1745 sec.\n",
      "Step(35640) loss: 5.8886 -- time: 4.5079 sec.\n",
      "Step(35650) loss: 5.9036 -- time: 4.5949 sec.\n",
      "Step(35660) loss: 5.6741 -- time: 4.5702 sec.\n",
      "Step(35670) loss: 5.8646 -- time: 4.4843 sec.\n",
      "Step(35680) loss: 5.7797 -- time: 4.6229 sec.\n",
      "Step(35690) loss: 5.6884 -- time: 4.4981 sec.\n",
      "Step(35700) loss: 5.7682 -- time: 4.5405 sec.\n",
      "Step(35710) loss: 5.7695 -- time: 4.4583 sec.\n",
      "Step(35720) loss: 5.6034 -- time: 4.4757 sec.\n",
      "Step(35730) loss: 6.1551 -- time: 4.4458 sec.\n",
      "Step(35740) loss: 5.4512 -- time: 4.5462 sec.\n",
      "Step(35750) loss: 5.7407 -- time: 4.6517 sec.\n",
      "Step(35760) loss: 5.9154 -- time: 4.5026 sec.\n",
      "Step(35770) loss: 5.6767 -- time: 4.5324 sec.\n",
      "Step(35780) loss: 5.9918 -- time: 4.4694 sec.\n",
      "Step(35790) loss: 4.9742 -- time: 4.4694 sec.\n",
      "Step(35800) loss: 5.4785 -- time: 4.3149 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1036.9566 - val_loss: 1063.7620\n",
      "time: 118.0719 sec.\n",
      "time_left: 0.0000 min\n",
      "--saved weights--\n",
      "CPU times: total: 1h 41min 34s\n",
      "Wall time: 4h 47min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "num_epochs = 200\n",
    "train(\n",
    "    net,\n",
    "    dataloaders_dict,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "# print(os.environ['CUDA_LAUNCH_BLOCKING'])\n",
    "# csvidx = os.listdir('loss_csv')\n",
    "# print(csvidx)\n",
    "# csvidx = [int(os.path.splitext(i)[0].split('_')[2]) for i in csvidx]\n",
    "# csvpath = '/Users/ShimaSef/object_detection/loss_csv/epoch_loss_{}.csv'.format(max(csvidx)+1)\n",
    "# print(csvpath)\n",
    "# weightidx = os.listdir('weights')\n",
    "# weightidx = [int(f.split('_')[2]) for f in weightidx if os.path.isdir(os.path.join('weights', f))]\n",
    "# if not os.path.exists('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1)):\n",
    "#   os.mkdir('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1))\n",
    "# max(csvidx)\n",
    "# print(csvidx)\n",
    "# weightidx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
