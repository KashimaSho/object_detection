{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# ---------- edit ---------- #\n",
    "print(torch.cuda.get_device_name(torch.device('cuda')))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "# -------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from voc import make_filepath_list, GetBBoxAndLabel, DataTransform, multiobject_collate_fn\n",
    "from preprocessDataset import PreprocessVOC2012\n",
    "\n",
    "# rootpath = '/home/masakibandai/object_detection/data/VOCdevkit/VOC2012/'\n",
    "rootpath = '/Users/ShimaSef/object_detection/data/VOCdevkit/VOC2012/'\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_filepath_list(rootpath)\n",
    "voc_classes = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "color_mean = (104, 117, 123)\n",
    "input_size = 300\n",
    "train_dataset = PreprocessVOC2012(\n",
    "    train_img_list,\n",
    "    train_anno_list,\n",
    "    phase='train',\n",
    "    transform=DataTransform(input_size, color_mean),\n",
    "    get_bbox_label=GetBBoxAndLabel(voc_classes)\n",
    ")\n",
    "\n",
    "val_dataset = PreprocessVOC2012(\n",
    "    val_img_list,\n",
    "    val_anno_list,\n",
    "    phase='val',\n",
    "    transform=DataTransform(input_size, color_mean),\n",
    "    get_bbox_label=GetBBoxAndLabel(voc_classes)\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=multiobject_collate_fn\n",
    ")\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=multiobject_collate_fn\n",
    ")\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SSD                                      [32, 3, 300, 300]         [32, 8732, 4]             --\n",
       "├─ModuleList: 1-3                        --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-1                       [32, 3, 300, 300]         [32, 64, 300, 300]        1,792\n",
       "│    └─ReLU: 2-2                         [32, 64, 300, 300]        [32, 64, 300, 300]        --\n",
       "│    └─Conv2d: 2-3                       [32, 64, 300, 300]        [32, 64, 300, 300]        36,928\n",
       "│    └─ReLU: 2-4                         [32, 64, 300, 300]        [32, 64, 300, 300]        --\n",
       "│    └─MaxPool2d: 2-5                    [32, 64, 300, 300]        [32, 64, 150, 150]        --\n",
       "│    └─Conv2d: 2-6                       [32, 64, 150, 150]        [32, 128, 150, 150]       73,856\n",
       "│    └─ReLU: 2-7                         [32, 128, 150, 150]       [32, 128, 150, 150]       --\n",
       "│    └─Conv2d: 2-8                       [32, 128, 150, 150]       [32, 128, 150, 150]       147,584\n",
       "│    └─ReLU: 2-9                         [32, 128, 150, 150]       [32, 128, 150, 150]       --\n",
       "│    └─MaxPool2d: 2-10                   [32, 128, 150, 150]       [32, 128, 75, 75]         --\n",
       "│    └─Conv2d: 2-11                      [32, 128, 75, 75]         [32, 256, 75, 75]         295,168\n",
       "│    └─ReLU: 2-12                        [32, 256, 75, 75]         [32, 256, 75, 75]         --\n",
       "│    └─Conv2d: 2-13                      [32, 256, 75, 75]         [32, 256, 75, 75]         590,080\n",
       "│    └─ReLU: 2-14                        [32, 256, 75, 75]         [32, 256, 75, 75]         --\n",
       "│    └─Conv2d: 2-15                      [32, 256, 75, 75]         [32, 256, 75, 75]         590,080\n",
       "│    └─ReLU: 2-16                        [32, 256, 75, 75]         [32, 256, 75, 75]         --\n",
       "│    └─MaxPool2d: 2-17                   [32, 256, 75, 75]         [32, 256, 38, 38]         --\n",
       "│    └─Conv2d: 2-18                      [32, 256, 38, 38]         [32, 512, 38, 38]         1,180,160\n",
       "│    └─ReLU: 2-19                        [32, 512, 38, 38]         [32, 512, 38, 38]         --\n",
       "│    └─Conv2d: 2-20                      [32, 512, 38, 38]         [32, 512, 38, 38]         2,359,808\n",
       "│    └─ReLU: 2-21                        [32, 512, 38, 38]         [32, 512, 38, 38]         --\n",
       "│    └─Conv2d: 2-22                      [32, 512, 38, 38]         [32, 512, 38, 38]         2,359,808\n",
       "│    └─ReLU: 2-23                        [32, 512, 38, 38]         [32, 512, 38, 38]         --\n",
       "├─L2Norm: 1-2                            [32, 512, 38, 38]         [32, 512, 38, 38]         512\n",
       "├─ModuleList: 1-3                        --                        --                        (recursive)\n",
       "│    └─MaxPool2d: 2-24                   [32, 512, 38, 38]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-25                      [32, 512, 19, 19]         [32, 512, 19, 19]         2,359,808\n",
       "│    └─ReLU: 2-26                        [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-27                      [32, 512, 19, 19]         [32, 512, 19, 19]         2,359,808\n",
       "│    └─ReLU: 2-28                        [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-29                      [32, 512, 19, 19]         [32, 512, 19, 19]         2,359,808\n",
       "│    └─ReLU: 2-30                        [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─MaxPool2d: 2-31                   [32, 512, 19, 19]         [32, 512, 19, 19]         --\n",
       "│    └─Conv2d: 2-32                      [32, 512, 19, 19]         [32, 1024, 19, 19]        4,719,616\n",
       "│    └─ReLU: 2-33                        [32, 1024, 19, 19]        [32, 1024, 19, 19]        --\n",
       "│    └─Conv2d: 2-34                      [32, 1024, 19, 19]        [32, 1024, 19, 19]        1,049,600\n",
       "│    └─ReLU: 2-35                        [32, 1024, 19, 19]        [32, 1024, 19, 19]        --\n",
       "├─ModuleList: 1-4                        --                        --                        --\n",
       "│    └─Conv2d: 2-36                      [32, 1024, 19, 19]        [32, 256, 19, 19]         262,400\n",
       "│    └─Conv2d: 2-37                      [32, 256, 19, 19]         [32, 512, 10, 10]         1,180,160\n",
       "│    └─Conv2d: 2-38                      [32, 512, 10, 10]         [32, 128, 10, 10]         65,664\n",
       "│    └─Conv2d: 2-39                      [32, 128, 10, 10]         [32, 256, 5, 5]           295,168\n",
       "│    └─Conv2d: 2-40                      [32, 256, 5, 5]           [32, 128, 5, 5]           32,896\n",
       "│    └─Conv2d: 2-41                      [32, 128, 5, 5]           [32, 256, 3, 3]           295,168\n",
       "│    └─Conv2d: 2-42                      [32, 256, 3, 3]           [32, 128, 3, 3]           32,896\n",
       "│    └─Conv2d: 2-43                      [32, 128, 3, 3]           [32, 256, 1, 1]           295,168\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-44                      [32, 512, 38, 38]         [32, 16, 38, 38]          73,744\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-45                      [32, 512, 38, 38]         [32, 84, 38, 38]          387,156\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-46                      [32, 1024, 19, 19]        [32, 24, 19, 19]          221,208\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-47                      [32, 1024, 19, 19]        [32, 126, 19, 19]         1,161,342\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-48                      [32, 512, 10, 10]         [32, 24, 10, 10]          110,616\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-49                      [32, 512, 10, 10]         [32, 126, 10, 10]         580,734\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-50                      [32, 256, 5, 5]           [32, 24, 5, 5]            55,320\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-51                      [32, 256, 5, 5]           [32, 126, 5, 5]           290,430\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-52                      [32, 256, 3, 3]           [32, 16, 3, 3]            36,880\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-53                      [32, 256, 3, 3]           [32, 84, 3, 3]            193,620\n",
       "├─ModuleList: 1-15                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-54                      [32, 256, 1, 1]           [32, 16, 1, 1]            36,880\n",
       "├─ModuleList: 1-16                       --                        --                        (recursive)\n",
       "│    └─Conv2d: 2-55                      [32, 256, 1, 1]           [32, 84, 1, 1]            193,620\n",
       "===================================================================================================================\n",
       "Total params: 26,285,486\n",
       "Trainable params: 26,285,486\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.00\n",
       "===================================================================================================================\n",
       "Input size (MB): 34.56\n",
       "Forward/backward pass size (MB): 6717.23\n",
       "Params size (MB): 105.14\n",
       "Estimated Total Size (MB): 6856.93\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from ssd import SSD\n",
    "from torchinfo import summary\n",
    "\n",
    "ssd_cfg = {\n",
    "    'classes_num': 21,\n",
    "    'input_size': 300,\n",
    "    'dbox_num': [4, 6, 6, 6, 4, 4],\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "net = SSD(phase='train', cfg=ssd_cfg)\n",
    "# weightpath = '/home/masakibandai/object_detection/weights/vgg16_reducedfc.pth'\n",
    "weightpath = '/Users/ShimaSef/object_detection/weights/vgg16_reducedfc.pth'\n",
    "vgg_weights = torch.load(weightpath)\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "summary(\n",
    "    net,\n",
    "    input_size=(batch_size, 3, 300, 300),\n",
    "    col_names=['input_size', 'output_size', 'num_params']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from ssd import MultiBoxLoss\n",
    "\n",
    "criterion = MultiBoxLoss(\n",
    "    jaccard_thresh=0.5,\n",
    "    neg_pos=3,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ---------- edit ---------- #\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(),\n",
    "    lr=1e-3,\n",
    "    # momentum=0.9,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "# -------------------------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def train(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    '''\n",
    "    Parameter:\n",
    "        net(object): SSD model\n",
    "        dataloaders_dict(dict of object): dataloader\n",
    "        criterion(object): loss function\n",
    "        optimizer(object): optimizer\n",
    "        num_epochs(object): num learning\n",
    "    '''\n",
    "    print(device)\n",
    "    # ---------edit--------- #\n",
    "    net.to(device)\n",
    "    # net.cuda()\n",
    "    # ---------------------- #\n",
    "    print('Start training with {}'.format(torch.cuda.get_device_name()))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                if ((epoch+1) % 10 == 0):\n",
    "                    net.eval()\n",
    "                    print('----------------------------------------------------------------------')\n",
    "                    print('(validation)')\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "                # ---------edit---------- #\n",
    "                # images.cuda()\n",
    "                # targets.cuda()\n",
    "                # ----------------------- #\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = net(images)\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('Step({}) loss: {:.4f} -- time: {:.4f} sec.'.format(iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        \n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "        t_epoch_finish = time.time()\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "        print('train_loss: {:.4f} - val_loss: {:.4f}'.format(epoch_train_loss, epoch_val_loss))\n",
    "        print('time: {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        print('time_left: {:.4f} min'.format((t_epoch_finish-t_epoch_start)*(num_epochs-epoch-1)/60))\n",
    "\n",
    "        t_epoch_start = time.time()\n",
    "        log_epoch = {\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': epoch_train_loss,\n",
    "            'val_loss': epoch_val_loss\n",
    "        }\n",
    "\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        # ---------- edit ---------- #\n",
    "        # csvpath = '/home/masakibandai/object_detection/epoch_loss.csv'\n",
    "        if epoch == 0:\n",
    "            csvidx = os.listdir('loss_csv')\n",
    "            csvidx = [int(os.path.splitext(i)[0].split('_')[2]) for i in csvidx]\n",
    "            csvpath = '/Users/ShimaSef/object_detection/loss_csv/epoch_loss_{}.csv'.format(max(csvidx)+1)\n",
    "        # -------------------------- #\n",
    "        df.to_csv(csvpath)\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        \n",
    "        # ---------- edit ---------- #\n",
    "        # statedictpath = '/home/masakibandai/object_detection/weights/ssd_weights'\n",
    "        if epoch == 0:\n",
    "            weightidx = os.listdir('weights')\n",
    "            weightidx = [int(f.split('_')[2]) for f in weightidx if os.path.isdir(os.path.join('weights', f))]\n",
    "            if not os.path.exists('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1)):\n",
    "                os.mkdir('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1))\n",
    "            statedictpath = '/Users/ShimaSef/object_detection/weights/ssd_weights_{}/ssd_weights_'.format(max(weightidx)+1)\n",
    "        # -------------------------- #\n",
    "\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(\n",
    "                net.state_dict(),\n",
    "                 statedictpath + str(epoch+1) + '.pth'\n",
    "            )\n",
    "            print('--saved weights--')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Start training with NVIDIA GeForce RTX 4090\n",
      "----------------------------------------------------------------------\n",
      "Epoch 1/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10) loss: 14.6157 -- time: 11.7751 sec.\n",
      "Step(20) loss: 49.1457 -- time: 5.1677 sec.\n",
      "Step(30) loss: 15.1407 -- time: 5.1734 sec.\n",
      "Step(40) loss: 13.0464 -- time: 5.0840 sec.\n",
      "Step(50) loss: 9.5318 -- time: 5.1928 sec.\n",
      "Step(60) loss: 12.0531 -- time: 5.0445 sec.\n",
      "Step(70) loss: 10.4175 -- time: 5.1474 sec.\n",
      "Step(80) loss: 7.7630 -- time: 5.1808 sec.\n",
      "Step(90) loss: 10.3285 -- time: 5.0385 sec.\n",
      "Step(100) loss: 8.2770 -- time: 5.0868 sec.\n",
      "Step(110) loss: 10.6653 -- time: 5.1570 sec.\n",
      "Step(120) loss: 8.0794 -- time: 5.1786 sec.\n",
      "Step(130) loss: 7.8079 -- time: 5.2341 sec.\n",
      "Step(140) loss: 11.0748 -- time: 4.9170 sec.\n",
      "Step(150) loss: 8.2388 -- time: 5.2333 sec.\n",
      "Step(160) loss: 10.0891 -- time: 5.1455 sec.\n",
      "Step(170) loss: 25.9709 -- time: 5.0954 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 3983.6895 - val_loss: 0.0000\n",
      "time: 106.6762 sec.\n",
      "time_left: 176.0157 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2/100\n",
      "----------------------------------------------------------------------\n",
      "Step(180) loss: 8.2100 -- time: 0.3701 sec.\n",
      "Step(190) loss: 4.9935 -- time: 4.1671 sec.\n",
      "Step(200) loss: 6.4519 -- time: 4.3862 sec.\n",
      "Step(210) loss: 9.0556 -- time: 4.2854 sec.\n",
      "Step(220) loss: 7.1754 -- time: 4.2808 sec.\n",
      "Step(230) loss: 7.1247 -- time: 4.3562 sec.\n",
      "Step(240) loss: 5.1707 -- time: 4.3004 sec.\n",
      "Step(250) loss: 12.4231 -- time: 4.3144 sec.\n",
      "Step(260) loss: 7.9172 -- time: 4.4039 sec.\n",
      "Step(270) loss: 8.1086 -- time: 4.2831 sec.\n",
      "Step(280) loss: 11.6915 -- time: 4.2428 sec.\n",
      "Step(290) loss: 7.1107 -- time: 4.3358 sec.\n",
      "Step(300) loss: 6.0512 -- time: 4.2210 sec.\n",
      "Step(310) loss: 7.0767 -- time: 4.3450 sec.\n",
      "Step(320) loss: 8.9135 -- time: 4.2618 sec.\n",
      "Step(330) loss: 5.3640 -- time: 4.2658 sec.\n",
      "Step(340) loss: 12.2121 -- time: 4.1988 sec.\n",
      "Step(350) loss: 9.9566 -- time: 4.2363 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1578.5820 - val_loss: 0.0000\n",
      "time: 78.5404 sec.\n",
      "time_left: 128.2826 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3/100\n",
      "----------------------------------------------------------------------\n",
      "Step(360) loss: 7.8438 -- time: 0.7898 sec.\n",
      "Step(370) loss: 6.8726 -- time: 4.2894 sec.\n",
      "Step(380) loss: 7.8525 -- time: 4.3097 sec.\n",
      "Step(390) loss: 7.0786 -- time: 4.3514 sec.\n",
      "Step(400) loss: 5.2231 -- time: 4.2428 sec.\n",
      "Step(410) loss: 13.3790 -- time: 4.3602 sec.\n",
      "Step(420) loss: 13.3351 -- time: 4.2676 sec.\n",
      "Step(430) loss: 9.1042 -- time: 4.3849 sec.\n",
      "Step(440) loss: 7.1273 -- time: 4.3138 sec.\n",
      "Step(450) loss: 8.2942 -- time: 4.1599 sec.\n",
      "Step(460) loss: 8.1573 -- time: 4.2543 sec.\n",
      "Step(470) loss: 7.7631 -- time: 4.3328 sec.\n",
      "Step(480) loss: 10.3045 -- time: 4.4009 sec.\n",
      "Step(490) loss: 10.4901 -- time: 4.3163 sec.\n",
      "Step(500) loss: 9.3324 -- time: 4.4947 sec.\n",
      "Step(510) loss: 12.2195 -- time: 4.3526 sec.\n",
      "Step(520) loss: 6.0031 -- time: 4.3456 sec.\n",
      "Step(530) loss: 7.5338 -- time: 4.3461 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1577.6753 - val_loss: 0.0000\n",
      "time: 79.1282 sec.\n",
      "time_left: 127.9239 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4/100\n",
      "----------------------------------------------------------------------\n",
      "Step(540) loss: 12.3358 -- time: 1.2010 sec.\n",
      "Step(550) loss: 10.1850 -- time: 4.2438 sec.\n",
      "Step(560) loss: 6.0473 -- time: 4.4619 sec.\n",
      "Step(570) loss: 8.5743 -- time: 4.3865 sec.\n",
      "Step(580) loss: 9.5365 -- time: 4.2567 sec.\n",
      "Step(590) loss: 7.6778 -- time: 4.3243 sec.\n",
      "Step(600) loss: 7.6219 -- time: 4.3346 sec.\n",
      "Step(610) loss: 6.1752 -- time: 4.2618 sec.\n",
      "Step(620) loss: 8.9136 -- time: 4.1986 sec.\n",
      "Step(630) loss: 9.2944 -- time: 4.3050 sec.\n",
      "Step(640) loss: 6.9582 -- time: 4.2512 sec.\n",
      "Step(650) loss: 10.8265 -- time: 4.2323 sec.\n",
      "Step(660) loss: 6.2481 -- time: 4.2703 sec.\n",
      "Step(670) loss: 10.5245 -- time: 4.2838 sec.\n",
      "Step(680) loss: 12.2096 -- time: 4.3136 sec.\n",
      "Step(690) loss: 8.1911 -- time: 4.1796 sec.\n",
      "Step(700) loss: 6.8905 -- time: 4.2509 sec.\n",
      "Step(710) loss: 10.2565 -- time: 4.3108 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1628.4714 - val_loss: 0.0000\n",
      "time: 78.4289 sec.\n",
      "time_left: 125.4863 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5/100\n",
      "----------------------------------------------------------------------\n",
      "Step(720) loss: 18.7158 -- time: 1.6246 sec.\n",
      "Step(730) loss: 14.2830 -- time: 4.1605 sec.\n",
      "Step(740) loss: 10.7910 -- time: 4.3052 sec.\n",
      "Step(750) loss: 7.6715 -- time: 4.2856 sec.\n",
      "Step(760) loss: 7.9555 -- time: 4.2441 sec.\n",
      "Step(770) loss: 8.9369 -- time: 4.2760 sec.\n",
      "Step(780) loss: 11.3712 -- time: 4.1928 sec.\n",
      "Step(790) loss: 10.7167 -- time: 4.2979 sec.\n",
      "Step(800) loss: 5.6394 -- time: 4.3272 sec.\n",
      "Step(810) loss: 5.0399 -- time: 4.4764 sec.\n",
      "Step(820) loss: 9.5917 -- time: 4.3681 sec.\n",
      "Step(830) loss: 9.8020 -- time: 4.2035 sec.\n",
      "Step(840) loss: 9.6707 -- time: 4.3648 sec.\n",
      "Step(850) loss: 8.4766 -- time: 4.3511 sec.\n",
      "Step(860) loss: 6.8350 -- time: 4.2461 sec.\n",
      "Step(870) loss: 10.9499 -- time: 4.2856 sec.\n",
      "Step(880) loss: 8.8309 -- time: 4.2980 sec.\n",
      "Step(890) loss: 12.6409 -- time: 4.2003 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1608.5066 - val_loss: 0.0000\n",
      "time: 78.3888 sec.\n",
      "time_left: 124.1156 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6/100\n",
      "----------------------------------------------------------------------\n",
      "Step(900) loss: 9.0198 -- time: 2.0928 sec.\n",
      "Step(910) loss: 10.7614 -- time: 4.2714 sec.\n",
      "Step(920) loss: 8.5928 -- time: 4.2183 sec.\n",
      "Step(930) loss: 8.5389 -- time: 4.3695 sec.\n",
      "Step(940) loss: 6.9085 -- time: 4.2907 sec.\n",
      "Step(950) loss: 15.4095 -- time: 4.3937 sec.\n",
      "Step(960) loss: 6.8065 -- time: 4.2684 sec.\n",
      "Step(970) loss: 7.9992 -- time: 4.3927 sec.\n",
      "Step(980) loss: 9.3596 -- time: 4.3724 sec.\n",
      "Step(990) loss: 3.6557 -- time: 4.2754 sec.\n",
      "Step(1000) loss: 8.4069 -- time: 4.1204 sec.\n",
      "Step(1010) loss: 7.8299 -- time: 4.3005 sec.\n",
      "Step(1020) loss: 6.3889 -- time: 4.3072 sec.\n",
      "Step(1030) loss: 7.3830 -- time: 4.4607 sec.\n",
      "Step(1040) loss: 6.4845 -- time: 4.2334 sec.\n",
      "Step(1050) loss: 7.5587 -- time: 4.2155 sec.\n",
      "Step(1060) loss: 6.6842 -- time: 4.2979 sec.\n",
      "Step(1070) loss: 7.5145 -- time: 4.3562 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1403.4659 - val_loss: 0.0000\n",
      "time: 78.7182 sec.\n",
      "time_left: 123.3251 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7/100\n",
      "----------------------------------------------------------------------\n",
      "Step(1080) loss: 7.8613 -- time: 2.5901 sec.\n",
      "Step(1090) loss: 7.4409 -- time: 4.2771 sec.\n",
      "Step(1100) loss: 6.6629 -- time: 4.3845 sec.\n",
      "Step(1110) loss: 6.8480 -- time: 4.2932 sec.\n",
      "Step(1120) loss: 6.9724 -- time: 4.2488 sec.\n",
      "Step(1130) loss: 11.8108 -- time: 4.3388 sec.\n",
      "Step(1140) loss: 7.0719 -- time: 4.4535 sec.\n",
      "Step(1150) loss: 8.7923 -- time: 4.2990 sec.\n",
      "Step(1160) loss: 7.6786 -- time: 4.2487 sec.\n",
      "Step(1170) loss: 7.6514 -- time: 4.2931 sec.\n",
      "Step(1180) loss: 13.6055 -- time: 4.3464 sec.\n",
      "Step(1190) loss: 5.4329 -- time: 4.3033 sec.\n",
      "Step(1200) loss: 5.2645 -- time: 4.3547 sec.\n",
      "Step(1210) loss: 13.5162 -- time: 4.3009 sec.\n",
      "Step(1220) loss: 7.5012 -- time: 4.2283 sec.\n",
      "Step(1230) loss: 8.5675 -- time: 4.3574 sec.\n",
      "Step(1240) loss: 7.8826 -- time: 4.2572 sec.\n",
      "Step(1250) loss: 7.6730 -- time: 4.3684 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1534.6933 - val_loss: 0.0000\n",
      "time: 78.9815 sec.\n",
      "time_left: 122.4213 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8/100\n",
      "----------------------------------------------------------------------\n",
      "Step(1260) loss: 9.9858 -- time: 3.0126 sec.\n",
      "Step(1270) loss: 4.4116 -- time: 4.2659 sec.\n",
      "Step(1280) loss: 9.3695 -- time: 4.4299 sec.\n",
      "Step(1290) loss: 6.8198 -- time: 4.3574 sec.\n",
      "Step(1300) loss: 10.7614 -- time: 4.2238 sec.\n",
      "Step(1310) loss: 10.0057 -- time: 4.2341 sec.\n",
      "Step(1320) loss: 9.1707 -- time: 4.2884 sec.\n",
      "Step(1330) loss: 8.5306 -- time: 4.3074 sec.\n",
      "Step(1340) loss: 4.5574 -- time: 4.2714 sec.\n",
      "Step(1350) loss: 10.5884 -- time: 4.4564 sec.\n",
      "Step(1360) loss: 7.6011 -- time: 4.3206 sec.\n",
      "Step(1370) loss: 8.0721 -- time: 4.3663 sec.\n",
      "Step(1380) loss: 7.9169 -- time: 4.4311 sec.\n",
      "Step(1390) loss: 8.3735 -- time: 4.3331 sec.\n",
      "Step(1400) loss: 7.8311 -- time: 4.2636 sec.\n",
      "Step(1410) loss: 7.6060 -- time: 4.3350 sec.\n",
      "Step(1420) loss: 8.9050 -- time: 4.1617 sec.\n",
      "Step(1430) loss: 10.5001 -- time: 4.3735 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1477.8367 - val_loss: 0.0000\n",
      "time: 79.0796 sec.\n",
      "time_left: 121.2554 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 9/100\n",
      "----------------------------------------------------------------------\n",
      "Step(1440) loss: 11.3263 -- time: 3.3246 sec.\n",
      "Step(1450) loss: 8.0975 -- time: 4.2333 sec.\n",
      "Step(1460) loss: 8.4167 -- time: 4.3677 sec.\n",
      "Step(1470) loss: 7.4199 -- time: 4.1847 sec.\n",
      "Step(1480) loss: 6.7300 -- time: 4.3633 sec.\n",
      "Step(1490) loss: 5.1307 -- time: 4.2804 sec.\n",
      "Step(1500) loss: 9.1381 -- time: 4.1904 sec.\n",
      "Step(1510) loss: 11.4291 -- time: 4.2191 sec.\n",
      "Step(1520) loss: 6.8994 -- time: 4.2999 sec.\n",
      "Step(1530) loss: 4.8047 -- time: 4.2582 sec.\n",
      "Step(1540) loss: 6.2333 -- time: 4.1489 sec.\n",
      "Step(1550) loss: 8.6005 -- time: 4.2583 sec.\n",
      "Step(1560) loss: 11.5962 -- time: 4.3933 sec.\n",
      "Step(1570) loss: 6.9512 -- time: 4.4070 sec.\n",
      "Step(1580) loss: 6.4866 -- time: 4.3742 sec.\n",
      "Step(1590) loss: 12.1577 -- time: 4.3492 sec.\n",
      "Step(1600) loss: 4.3649 -- time: 4.2859 sec.\n",
      "Step(1610) loss: 4.1304 -- time: 4.2754 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1436.1806 - val_loss: 0.0000\n",
      "time: 78.3952 sec.\n",
      "time_left: 118.8994 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 10/100\n",
      "----------------------------------------------------------------------\n",
      "Step(1620) loss: 9.2580 -- time: 3.8354 sec.\n",
      "Step(1630) loss: 4.2242 -- time: 4.4021 sec.\n",
      "Step(1640) loss: 8.2918 -- time: 4.3747 sec.\n",
      "Step(1650) loss: 6.9001 -- time: 4.3139 sec.\n",
      "Step(1660) loss: 9.1169 -- time: 4.3604 sec.\n",
      "Step(1670) loss: 8.9002 -- time: 4.2756 sec.\n",
      "Step(1680) loss: 8.6773 -- time: 4.3090 sec.\n",
      "Step(1690) loss: 7.7806 -- time: 4.2680 sec.\n",
      "Step(1700) loss: 7.8121 -- time: 4.3128 sec.\n",
      "Step(1710) loss: 6.4670 -- time: 4.3266 sec.\n",
      "Step(1720) loss: 8.3934 -- time: 4.3557 sec.\n",
      "Step(1730) loss: 5.7640 -- time: 4.2396 sec.\n",
      "Step(1740) loss: 7.0448 -- time: 4.3431 sec.\n",
      "Step(1750) loss: 8.3749 -- time: 4.2916 sec.\n",
      "Step(1760) loss: 7.8092 -- time: 4.3188 sec.\n",
      "Step(1770) loss: 6.3367 -- time: 4.1356 sec.\n",
      "Step(1780) loss: 20.4058 -- time: 4.2622 sec.\n",
      "Step(1790) loss: 9.4442 -- time: 4.1728 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1433.6564 - val_loss: 1424.2591\n",
      "time: 129.2238 sec.\n",
      "time_left: 193.8357 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 11/100\n",
      "----------------------------------------------------------------------\n",
      "Step(1800) loss: 4.7734 -- time: 4.4836 sec.\n",
      "Step(1810) loss: 4.6115 -- time: 4.3699 sec.\n",
      "Step(1820) loss: 8.8840 -- time: 4.2817 sec.\n",
      "Step(1830) loss: 9.4921 -- time: 4.2427 sec.\n",
      "Step(1840) loss: 5.9507 -- time: 4.3857 sec.\n",
      "Step(1850) loss: 9.6611 -- time: 4.3962 sec.\n",
      "Step(1860) loss: 6.2584 -- time: 4.4421 sec.\n",
      "Step(1870) loss: 15.7805 -- time: 4.2522 sec.\n",
      "Step(1880) loss: 10.2840 -- time: 4.2493 sec.\n",
      "Step(1890) loss: 7.3391 -- time: 4.2779 sec.\n",
      "Step(1900) loss: 11.1974 -- time: 4.2170 sec.\n",
      "Step(1910) loss: 6.6688 -- time: 4.3384 sec.\n",
      "Step(1920) loss: 9.5964 -- time: 4.3203 sec.\n",
      "Step(1930) loss: 8.4945 -- time: 4.2729 sec.\n",
      "Step(1940) loss: 8.6334 -- time: 4.2185 sec.\n",
      "Step(1950) loss: 10.4263 -- time: 4.4467 sec.\n",
      "Step(1960) loss: 11.3392 -- time: 4.3035 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1418.2360 - val_loss: 0.0000\n",
      "time: 79.1339 sec.\n",
      "time_left: 117.3820 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 12/100\n",
      "----------------------------------------------------------------------\n",
      "Step(1970) loss: 6.3180 -- time: 0.3295 sec.\n",
      "Step(1980) loss: 6.9460 -- time: 4.1715 sec.\n",
      "Step(1990) loss: 5.5941 -- time: 4.2697 sec.\n",
      "Step(2000) loss: 4.7171 -- time: 4.3153 sec.\n",
      "Step(2010) loss: 7.4562 -- time: 4.2363 sec.\n",
      "Step(2020) loss: 5.5220 -- time: 4.2445 sec.\n",
      "Step(2030) loss: 15.0886 -- time: 4.3015 sec.\n",
      "Step(2040) loss: 7.9879 -- time: 4.4338 sec.\n",
      "Step(2050) loss: 7.6596 -- time: 4.3531 sec.\n",
      "Step(2060) loss: 6.9329 -- time: 4.3447 sec.\n",
      "Step(2070) loss: 9.3704 -- time: 4.2205 sec.\n",
      "Step(2080) loss: 7.8199 -- time: 4.3598 sec.\n",
      "Step(2090) loss: 8.6907 -- time: 4.3467 sec.\n",
      "Step(2100) loss: 8.6468 -- time: 4.2640 sec.\n",
      "Step(2110) loss: 6.6635 -- time: 4.2009 sec.\n",
      "Step(2120) loss: 7.3825 -- time: 4.1679 sec.\n",
      "Step(2130) loss: 8.0935 -- time: 4.2736 sec.\n",
      "Step(2140) loss: 7.1816 -- time: 4.3585 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1421.7530 - val_loss: 0.0000\n",
      "time: 78.4129 sec.\n",
      "time_left: 115.0056 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 13/100\n",
      "----------------------------------------------------------------------\n",
      "Step(2150) loss: 12.4820 -- time: 0.7168 sec.\n",
      "Step(2160) loss: 6.8169 -- time: 4.3451 sec.\n",
      "Step(2170) loss: 7.8503 -- time: 4.2806 sec.\n",
      "Step(2180) loss: 6.8859 -- time: 4.4079 sec.\n",
      "Step(2190) loss: 8.4569 -- time: 4.2307 sec.\n",
      "Step(2200) loss: 8.1966 -- time: 4.3002 sec.\n",
      "Step(2210) loss: 7.4223 -- time: 4.1873 sec.\n",
      "Step(2220) loss: 8.3428 -- time: 4.2457 sec.\n",
      "Step(2230) loss: 8.1959 -- time: 4.4021 sec.\n",
      "Step(2240) loss: 7.3594 -- time: 4.2492 sec.\n",
      "Step(2250) loss: 5.4481 -- time: 4.2398 sec.\n",
      "Step(2260) loss: 8.8444 -- time: 4.3983 sec.\n",
      "Step(2270) loss: 8.5335 -- time: 4.2878 sec.\n",
      "Step(2280) loss: 7.0011 -- time: 4.1847 sec.\n",
      "Step(2290) loss: 4.1237 -- time: 4.2784 sec.\n",
      "Step(2300) loss: 9.4418 -- time: 4.2537 sec.\n",
      "Step(2310) loss: 8.9155 -- time: 4.4659 sec.\n",
      "Step(2320) loss: 6.3270 -- time: 4.4838 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1382.6411 - val_loss: 0.0000\n",
      "time: 78.8895 sec.\n",
      "time_left: 114.3898 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 14/100\n",
      "----------------------------------------------------------------------\n",
      "Step(2330) loss: 7.1102 -- time: 1.2401 sec.\n",
      "Step(2340) loss: 4.0830 -- time: 4.3598 sec.\n",
      "Step(2350) loss: 6.9857 -- time: 4.3843 sec.\n",
      "Step(2360) loss: 6.3352 -- time: 4.3356 sec.\n",
      "Step(2370) loss: 6.3311 -- time: 4.3279 sec.\n",
      "Step(2380) loss: 12.5275 -- time: 4.3372 sec.\n",
      "Step(2390) loss: 9.3202 -- time: 4.1975 sec.\n",
      "Step(2400) loss: 7.2498 -- time: 4.2896 sec.\n",
      "Step(2410) loss: 10.1340 -- time: 4.3704 sec.\n",
      "Step(2420) loss: 8.3743 -- time: 4.2573 sec.\n",
      "Step(2430) loss: 9.5061 -- time: 4.3146 sec.\n",
      "Step(2440) loss: 9.1760 -- time: 4.2815 sec.\n",
      "Step(2450) loss: 7.9490 -- time: 4.4272 sec.\n",
      "Step(2460) loss: 7.1883 -- time: 4.1687 sec.\n",
      "Step(2470) loss: 4.9101 -- time: 4.2768 sec.\n",
      "Step(2480) loss: 5.9409 -- time: 4.2689 sec.\n",
      "Step(2490) loss: 6.0373 -- time: 4.3393 sec.\n",
      "Step(2500) loss: 8.4062 -- time: 4.1534 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1527.1470 - val_loss: 0.0000\n",
      "time: 78.6590 sec.\n",
      "time_left: 112.7445 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 15/100\n",
      "----------------------------------------------------------------------\n",
      "Step(2510) loss: 7.7251 -- time: 1.5810 sec.\n",
      "Step(2520) loss: 9.9612 -- time: 4.4148 sec.\n",
      "Step(2530) loss: 8.9501 -- time: 4.2341 sec.\n",
      "Step(2540) loss: 9.1337 -- time: 4.3438 sec.\n",
      "Step(2550) loss: 9.2460 -- time: 4.2299 sec.\n",
      "Step(2560) loss: 8.8595 -- time: 4.3057 sec.\n",
      "Step(2570) loss: 6.6693 -- time: 4.3694 sec.\n",
      "Step(2580) loss: 9.6914 -- time: 4.2269 sec.\n",
      "Step(2590) loss: 12.6102 -- time: 4.3343 sec.\n",
      "Step(2600) loss: 8.3589 -- time: 4.3412 sec.\n",
      "Step(2610) loss: 6.3420 -- time: 4.2898 sec.\n",
      "Step(2620) loss: 6.2803 -- time: 4.2846 sec.\n",
      "Step(2630) loss: 7.3457 -- time: 4.2035 sec.\n",
      "Step(2640) loss: 7.9385 -- time: 4.1755 sec.\n",
      "Step(2650) loss: 8.1033 -- time: 4.2230 sec.\n",
      "Step(2660) loss: 8.6041 -- time: 4.3004 sec.\n",
      "Step(2670) loss: 8.2523 -- time: 4.1318 sec.\n",
      "Step(2680) loss: 6.8286 -- time: 4.2685 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1415.0307 - val_loss: 0.0000\n",
      "time: 78.1806 sec.\n",
      "time_left: 110.7559 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 16/100\n",
      "----------------------------------------------------------------------\n",
      "Step(2690) loss: 7.5339 -- time: 2.1168 sec.\n",
      "Step(2700) loss: 4.4541 -- time: 4.4318 sec.\n",
      "Step(2710) loss: 4.2295 -- time: 4.1638 sec.\n",
      "Step(2720) loss: 9.5971 -- time: 4.3255 sec.\n",
      "Step(2730) loss: 4.1388 -- time: 4.2820 sec.\n",
      "Step(2740) loss: 4.6146 -- time: 4.2600 sec.\n",
      "Step(2750) loss: 9.0461 -- time: 4.2498 sec.\n",
      "Step(2760) loss: 6.9846 -- time: 4.4159 sec.\n",
      "Step(2770) loss: 8.9605 -- time: 4.3254 sec.\n",
      "Step(2780) loss: 6.4695 -- time: 4.2273 sec.\n",
      "Step(2790) loss: 13.0218 -- time: 4.3590 sec.\n",
      "Step(2800) loss: 10.8016 -- time: 4.3205 sec.\n",
      "Step(2810) loss: 8.6648 -- time: 4.2879 sec.\n",
      "Step(2820) loss: 7.7633 -- time: 4.2459 sec.\n",
      "Step(2830) loss: 7.4066 -- time: 4.3908 sec.\n",
      "Step(2840) loss: 7.6294 -- time: 4.3162 sec.\n",
      "Step(2850) loss: 6.3202 -- time: 4.1693 sec.\n",
      "Step(2860) loss: 7.4660 -- time: 4.3527 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1372.6852 - val_loss: 0.0000\n",
      "time: 78.7439 sec.\n",
      "time_left: 110.2415 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 17/100\n",
      "----------------------------------------------------------------------\n",
      "Step(2870) loss: 7.9812 -- time: 2.4916 sec.\n",
      "Step(2880) loss: 7.3117 -- time: 4.3147 sec.\n",
      "Step(2890) loss: 8.2428 -- time: 4.2167 sec.\n",
      "Step(2900) loss: 8.0392 -- time: 4.3594 sec.\n",
      "Step(2910) loss: 6.8357 -- time: 4.3221 sec.\n",
      "Step(2920) loss: 9.1464 -- time: 4.2164 sec.\n",
      "Step(2930) loss: 9.5716 -- time: 4.3399 sec.\n",
      "Step(2940) loss: 8.9309 -- time: 4.3679 sec.\n",
      "Step(2950) loss: 8.0998 -- time: 4.3613 sec.\n",
      "Step(2960) loss: 6.8647 -- time: 4.2498 sec.\n",
      "Step(2970) loss: 5.7737 -- time: 4.2120 sec.\n",
      "Step(2980) loss: 8.4698 -- time: 4.3735 sec.\n",
      "Step(2990) loss: 6.7026 -- time: 4.3509 sec.\n",
      "Step(3000) loss: 8.2717 -- time: 4.3179 sec.\n",
      "Step(3010) loss: 7.0113 -- time: 4.1728 sec.\n",
      "Step(3020) loss: 7.4339 -- time: 4.0982 sec.\n",
      "Step(3030) loss: 7.4850 -- time: 4.2831 sec.\n",
      "Step(3040) loss: 6.4584 -- time: 4.2933 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1426.4017 - val_loss: 0.0000\n",
      "time: 78.4147 sec.\n",
      "time_left: 108.4737 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 18/100\n",
      "----------------------------------------------------------------------\n",
      "Step(3050) loss: 8.4071 -- time: 2.9840 sec.\n",
      "Step(3060) loss: 6.4457 -- time: 4.3489 sec.\n",
      "Step(3070) loss: 7.8853 -- time: 4.2225 sec.\n",
      "Step(3080) loss: 8.9004 -- time: 4.2438 sec.\n",
      "Step(3090) loss: 7.4740 -- time: 4.3253 sec.\n",
      "Step(3100) loss: 7.4621 -- time: 4.1684 sec.\n",
      "Step(3110) loss: 6.4206 -- time: 4.1726 sec.\n",
      "Step(3120) loss: 5.6110 -- time: 4.2392 sec.\n",
      "Step(3130) loss: 5.6089 -- time: 4.2319 sec.\n",
      "Step(3140) loss: 4.9453 -- time: 4.3169 sec.\n",
      "Step(3150) loss: 6.2094 -- time: 4.2997 sec.\n",
      "Step(3160) loss: 7.0143 -- time: 4.0902 sec.\n",
      "Step(3170) loss: 4.7345 -- time: 4.2239 sec.\n",
      "Step(3180) loss: 8.7110 -- time: 4.3521 sec.\n",
      "Step(3190) loss: 9.2421 -- time: 4.2094 sec.\n",
      "Step(3200) loss: 7.8301 -- time: 4.2739 sec.\n",
      "Step(3210) loss: 4.8940 -- time: 4.2174 sec.\n",
      "Step(3220) loss: 7.6391 -- time: 4.2855 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1389.4966 - val_loss: 0.0000\n",
      "time: 77.7751 sec.\n",
      "time_left: 106.2927 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 19/100\n",
      "----------------------------------------------------------------------\n",
      "Step(3230) loss: 7.4306 -- time: 3.4812 sec.\n",
      "Step(3240) loss: 4.9598 -- time: 4.3613 sec.\n",
      "Step(3250) loss: 3.4110 -- time: 4.3041 sec.\n",
      "Step(3260) loss: 7.8818 -- time: 4.2231 sec.\n",
      "Step(3270) loss: 4.2042 -- time: 4.4303 sec.\n",
      "Step(3280) loss: 8.0784 -- time: 4.2506 sec.\n",
      "Step(3290) loss: 5.3771 -- time: 4.3099 sec.\n",
      "Step(3300) loss: 8.1236 -- time: 4.1421 sec.\n",
      "Step(3310) loss: 11.8158 -- time: 4.2436 sec.\n",
      "Step(3320) loss: 8.3527 -- time: 4.2444 sec.\n",
      "Step(3330) loss: 7.3617 -- time: 4.4286 sec.\n",
      "Step(3340) loss: 9.3341 -- time: 4.3923 sec.\n",
      "Step(3350) loss: 10.3620 -- time: 4.2124 sec.\n",
      "Step(3360) loss: 7.8214 -- time: 4.3604 sec.\n",
      "Step(3370) loss: 7.5781 -- time: 4.2740 sec.\n",
      "Step(3380) loss: 7.0621 -- time: 4.3475 sec.\n",
      "Step(3390) loss: 7.2457 -- time: 4.2955 sec.\n",
      "Step(3400) loss: 8.2180 -- time: 4.3477 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1345.0104 - val_loss: 0.0000\n",
      "time: 78.8233 sec.\n",
      "time_left: 106.4115 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 20/100\n",
      "----------------------------------------------------------------------\n",
      "Step(3410) loss: 8.2892 -- time: 3.8540 sec.\n",
      "Step(3420) loss: 5.1886 -- time: 4.2693 sec.\n",
      "Step(3430) loss: 4.1515 -- time: 4.2550 sec.\n",
      "Step(3440) loss: 6.9421 -- time: 4.3069 sec.\n",
      "Step(3450) loss: 7.8190 -- time: 4.2875 sec.\n",
      "Step(3460) loss: 7.6276 -- time: 4.3007 sec.\n",
      "Step(3470) loss: 5.2307 -- time: 4.1569 sec.\n",
      "Step(3480) loss: 19.5855 -- time: 4.2813 sec.\n",
      "Step(3490) loss: 6.7803 -- time: 4.1440 sec.\n",
      "Step(3500) loss: 7.9334 -- time: 4.3199 sec.\n",
      "Step(3510) loss: 7.7435 -- time: 4.3018 sec.\n",
      "Step(3520) loss: 7.7866 -- time: 4.2734 sec.\n",
      "Step(3530) loss: 6.2140 -- time: 4.4402 sec.\n",
      "Step(3540) loss: 10.6337 -- time: 4.3261 sec.\n",
      "Step(3550) loss: 5.6095 -- time: 4.1947 sec.\n",
      "Step(3560) loss: 8.7547 -- time: 4.3654 sec.\n",
      "Step(3570) loss: 7.2677 -- time: 4.2664 sec.\n",
      "Step(3580) loss: 6.6170 -- time: 4.1755 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1452.1975 - val_loss: 1956.3049\n",
      "time: 110.9618 sec.\n",
      "time_left: 147.9490 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 21/100\n",
      "----------------------------------------------------------------------\n",
      "Step(3590) loss: 7.8429 -- time: 4.4235 sec.\n",
      "Step(3600) loss: 12.5415 -- time: 4.4164 sec.\n",
      "Step(3610) loss: 9.6769 -- time: 4.3191 sec.\n",
      "Step(3620) loss: 8.6129 -- time: 4.2874 sec.\n",
      "Step(3630) loss: 14.2121 -- time: 4.2590 sec.\n",
      "Step(3640) loss: 9.0438 -- time: 4.4211 sec.\n",
      "Step(3650) loss: 9.5256 -- time: 4.4268 sec.\n",
      "Step(3660) loss: 7.2898 -- time: 4.4087 sec.\n",
      "Step(3670) loss: 13.9923 -- time: 4.3968 sec.\n",
      "Step(3680) loss: 8.8805 -- time: 4.3061 sec.\n",
      "Step(3690) loss: 9.1307 -- time: 4.1847 sec.\n",
      "Step(3700) loss: 13.4005 -- time: 4.2739 sec.\n",
      "Step(3710) loss: 6.8497 -- time: 4.2441 sec.\n",
      "Step(3720) loss: 9.4596 -- time: 4.3545 sec.\n",
      "Step(3730) loss: 6.9652 -- time: 4.2891 sec.\n",
      "Step(3740) loss: 8.1103 -- time: 4.4559 sec.\n",
      "Step(3750) loss: 7.0329 -- time: 4.3483 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1789.7742 - val_loss: 0.0000\n",
      "time: 79.5655 sec.\n",
      "time_left: 104.7613 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 22/100\n",
      "----------------------------------------------------------------------\n",
      "Step(3760) loss: 7.4132 -- time: 0.3352 sec.\n",
      "Step(3770) loss: 7.3736 -- time: 4.3376 sec.\n",
      "Step(3780) loss: 4.3024 -- time: 4.3592 sec.\n",
      "Step(3790) loss: 15.7056 -- time: 4.3578 sec.\n",
      "Step(3800) loss: 9.4653 -- time: 4.3612 sec.\n",
      "Step(3810) loss: 6.1431 -- time: 4.4668 sec.\n",
      "Step(3820) loss: 8.6317 -- time: 4.3730 sec.\n",
      "Step(3830) loss: 10.7850 -- time: 4.3433 sec.\n",
      "Step(3840) loss: 6.3027 -- time: 4.4504 sec.\n",
      "Step(3850) loss: 5.6934 -- time: 4.2967 sec.\n",
      "Step(3860) loss: 8.7835 -- time: 4.3520 sec.\n",
      "Step(3870) loss: 7.7334 -- time: 4.3741 sec.\n",
      "Step(3880) loss: 7.8023 -- time: 4.3358 sec.\n",
      "Step(3890) loss: 7.2958 -- time: 4.4430 sec.\n",
      "Step(3900) loss: 7.6843 -- time: 4.5498 sec.\n",
      "Step(3910) loss: 7.4410 -- time: 4.4665 sec.\n",
      "Step(3920) loss: 8.6750 -- time: 4.3174 sec.\n",
      "Step(3930) loss: 5.0917 -- time: 4.4173 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1413.6788 - val_loss: 0.0000\n",
      "time: 80.2893 sec.\n",
      "time_left: 104.3761 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 23/100\n",
      "----------------------------------------------------------------------\n",
      "Step(3940) loss: 8.9712 -- time: 0.8061 sec.\n",
      "Step(3950) loss: 11.1165 -- time: 4.4852 sec.\n",
      "Step(3960) loss: 7.5458 -- time: 4.3137 sec.\n",
      "Step(3970) loss: 7.9130 -- time: 4.5206 sec.\n",
      "Step(3980) loss: 9.1785 -- time: 4.2619 sec.\n",
      "Step(3990) loss: 4.8896 -- time: 4.2701 sec.\n",
      "Step(4000) loss: 9.0908 -- time: 4.3233 sec.\n",
      "Step(4010) loss: 8.8246 -- time: 4.3543 sec.\n",
      "Step(4020) loss: 9.8097 -- time: 4.3851 sec.\n",
      "Step(4030) loss: 7.7566 -- time: 4.4205 sec.\n",
      "Step(4040) loss: 8.6297 -- time: 4.3239 sec.\n",
      "Step(4050) loss: 6.2598 -- time: 4.4257 sec.\n",
      "Step(4060) loss: 6.4791 -- time: 4.3138 sec.\n",
      "Step(4070) loss: 8.3784 -- time: 4.3610 sec.\n",
      "Step(4080) loss: 6.9364 -- time: 4.4563 sec.\n",
      "Step(4090) loss: 7.2721 -- time: 4.3578 sec.\n",
      "Step(4100) loss: 8.7902 -- time: 4.3957 sec.\n",
      "Step(4110) loss: 6.6350 -- time: 4.4874 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1432.8489 - val_loss: 0.0000\n",
      "time: 80.2909 sec.\n",
      "time_left: 103.0400 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 24/100\n",
      "----------------------------------------------------------------------\n",
      "Step(4120) loss: 7.1027 -- time: 1.2463 sec.\n",
      "Step(4130) loss: 7.7944 -- time: 4.4021 sec.\n",
      "Step(4140) loss: 6.6033 -- time: 4.3084 sec.\n",
      "Step(4150) loss: 8.9396 -- time: 4.4645 sec.\n",
      "Step(4160) loss: 8.6731 -- time: 4.3832 sec.\n",
      "Step(4170) loss: 9.3490 -- time: 4.2751 sec.\n",
      "Step(4180) loss: 7.9132 -- time: 4.4559 sec.\n",
      "Step(4190) loss: 6.9898 -- time: 4.3912 sec.\n",
      "Step(4200) loss: 7.5640 -- time: 4.4652 sec.\n",
      "Step(4210) loss: 7.6820 -- time: 4.3631 sec.\n",
      "Step(4220) loss: 8.8996 -- time: 4.4364 sec.\n",
      "Step(4230) loss: 8.7006 -- time: 4.4430 sec.\n",
      "Step(4240) loss: 6.2909 -- time: 4.5482 sec.\n",
      "Step(4250) loss: 4.4869 -- time: 4.4028 sec.\n",
      "Step(4260) loss: 7.2238 -- time: 4.4961 sec.\n",
      "Step(4270) loss: 6.7305 -- time: 4.2854 sec.\n",
      "Step(4280) loss: 7.0347 -- time: 4.4304 sec.\n",
      "Step(4290) loss: 10.9667 -- time: 4.4432 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1378.9577 - val_loss: 0.0000\n",
      "time: 80.5824 sec.\n",
      "time_left: 102.0710 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 25/100\n",
      "----------------------------------------------------------------------\n",
      "Step(4300) loss: 5.3745 -- time: 1.7516 sec.\n",
      "Step(4310) loss: 7.5307 -- time: 4.4290 sec.\n",
      "Step(4320) loss: 7.8265 -- time: 4.4828 sec.\n",
      "Step(4330) loss: 7.8326 -- time: 4.4397 sec.\n",
      "Step(4340) loss: 7.1667 -- time: 4.3395 sec.\n",
      "Step(4350) loss: 7.3948 -- time: 4.4743 sec.\n",
      "Step(4360) loss: 7.7958 -- time: 4.3376 sec.\n",
      "Step(4370) loss: 8.2848 -- time: 4.3399 sec.\n",
      "Step(4380) loss: 7.9901 -- time: 4.3271 sec.\n",
      "Step(4390) loss: 4.8098 -- time: 4.5646 sec.\n",
      "Step(4400) loss: 8.6901 -- time: 4.3444 sec.\n",
      "Step(4410) loss: 4.7310 -- time: 4.3541 sec.\n",
      "Step(4420) loss: 8.3068 -- time: 4.3925 sec.\n",
      "Step(4430) loss: 7.2199 -- time: 4.3820 sec.\n",
      "Step(4440) loss: 8.6004 -- time: 4.4142 sec.\n",
      "Step(4450) loss: 7.7069 -- time: 4.3513 sec.\n",
      "Step(4460) loss: 8.3236 -- time: 4.4294 sec.\n",
      "Step(4470) loss: 7.8205 -- time: 4.3705 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1468.6952 - val_loss: 0.0000\n",
      "time: 80.4979 sec.\n",
      "time_left: 100.6223 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 26/100\n",
      "----------------------------------------------------------------------\n",
      "Step(4480) loss: 7.2288 -- time: 2.1231 sec.\n",
      "Step(4490) loss: 4.8534 -- time: 4.3571 sec.\n",
      "Step(4500) loss: 7.4383 -- time: 4.2768 sec.\n",
      "Step(4510) loss: 6.6564 -- time: 4.2306 sec.\n",
      "Step(4520) loss: 3.8952 -- time: 4.3091 sec.\n",
      "Step(4530) loss: 7.1331 -- time: 4.3543 sec.\n",
      "Step(4540) loss: 7.3598 -- time: 4.3943 sec.\n",
      "Step(4550) loss: 8.1458 -- time: 4.2215 sec.\n",
      "Step(4560) loss: 6.5349 -- time: 4.3045 sec.\n",
      "Step(4570) loss: 6.1728 -- time: 4.3019 sec.\n",
      "Step(4580) loss: 7.3855 -- time: 4.2671 sec.\n",
      "Step(4590) loss: 8.0310 -- time: 4.3285 sec.\n",
      "Step(4600) loss: 4.7926 -- time: 4.2634 sec.\n",
      "Step(4610) loss: 8.9028 -- time: 4.1780 sec.\n",
      "Step(4620) loss: 9.1701 -- time: 4.2633 sec.\n",
      "Step(4630) loss: 7.6884 -- time: 4.3427 sec.\n",
      "Step(4640) loss: 8.0820 -- time: 4.3583 sec.\n",
      "Step(4650) loss: 9.3058 -- time: 4.4631 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1355.9316 - val_loss: 0.0000\n",
      "time: 78.9493 sec.\n",
      "time_left: 97.3709 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 27/100\n",
      "----------------------------------------------------------------------\n",
      "Step(4660) loss: 8.1464 -- time: 2.5969 sec.\n",
      "Step(4670) loss: 8.6858 -- time: 4.2838 sec.\n",
      "Step(4680) loss: 4.0498 -- time: 4.2877 sec.\n",
      "Step(4690) loss: 9.0466 -- time: 4.4069 sec.\n",
      "Step(4700) loss: 6.4642 -- time: 4.3628 sec.\n",
      "Step(4710) loss: 6.9527 -- time: 4.3327 sec.\n",
      "Step(4720) loss: 8.7890 -- time: 4.4899 sec.\n",
      "Step(4730) loss: 7.3672 -- time: 4.3841 sec.\n",
      "Step(4740) loss: 8.4317 -- time: 4.4644 sec.\n",
      "Step(4750) loss: 6.9910 -- time: 4.3186 sec.\n",
      "Step(4760) loss: 5.8997 -- time: 4.3864 sec.\n",
      "Step(4770) loss: 6.9207 -- time: 4.2830 sec.\n",
      "Step(4780) loss: 7.8185 -- time: 4.2958 sec.\n",
      "Step(4790) loss: 4.1497 -- time: 4.2157 sec.\n",
      "Step(4800) loss: 5.0453 -- time: 4.3449 sec.\n",
      "Step(4810) loss: 7.6441 -- time: 4.3550 sec.\n",
      "Step(4820) loss: 5.7002 -- time: 4.3335 sec.\n",
      "Step(4830) loss: 13.8142 -- time: 4.3339 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1422.2350 - val_loss: 0.0000\n",
      "time: 79.5646 sec.\n",
      "time_left: 96.8035 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 28/100\n",
      "----------------------------------------------------------------------\n",
      "Step(4840) loss: 16.7382 -- time: 2.9872 sec.\n",
      "Step(4850) loss: 8.7974 -- time: 4.2848 sec.\n",
      "Step(4860) loss: 9.5291 -- time: 4.2894 sec.\n",
      "Step(4870) loss: 11.6104 -- time: 4.2855 sec.\n",
      "Step(4880) loss: 7.2723 -- time: 4.2233 sec.\n",
      "Step(4890) loss: 7.1527 -- time: 4.2438 sec.\n",
      "Step(4900) loss: 8.0707 -- time: 4.2558 sec.\n",
      "Step(4910) loss: 7.2548 -- time: 4.4152 sec.\n",
      "Step(4920) loss: 8.8454 -- time: 4.3879 sec.\n",
      "Step(4930) loss: 5.1210 -- time: 4.2785 sec.\n",
      "Step(4940) loss: 7.1575 -- time: 4.3135 sec.\n",
      "Step(4950) loss: 7.5708 -- time: 4.4366 sec.\n",
      "Step(4960) loss: 5.9088 -- time: 4.3328 sec.\n",
      "Step(4970) loss: 8.5638 -- time: 4.3395 sec.\n",
      "Step(4980) loss: 7.7477 -- time: 4.3596 sec.\n",
      "Step(4990) loss: 6.0886 -- time: 4.1531 sec.\n",
      "Step(5000) loss: 6.9539 -- time: 4.4857 sec.\n",
      "Step(5010) loss: 7.7639 -- time: 4.2105 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1441.7342 - val_loss: 0.0000\n",
      "time: 78.9745 sec.\n",
      "time_left: 94.7694 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 29/100\n",
      "----------------------------------------------------------------------\n",
      "Step(5020) loss: 9.7786 -- time: 3.5497 sec.\n",
      "Step(5030) loss: 6.7129 -- time: 4.2488 sec.\n",
      "Step(5040) loss: 11.3448 -- time: 4.2148 sec.\n",
      "Step(5050) loss: 11.5627 -- time: 4.2306 sec.\n",
      "Step(5060) loss: 6.9888 -- time: 4.4124 sec.\n",
      "Step(5070) loss: 7.8458 -- time: 4.3506 sec.\n",
      "Step(5080) loss: 6.7516 -- time: 4.3699 sec.\n",
      "Step(5090) loss: 4.1778 -- time: 4.3279 sec.\n",
      "Step(5100) loss: 8.1622 -- time: 4.3680 sec.\n",
      "Step(5110) loss: 6.2465 -- time: 4.3491 sec.\n",
      "Step(5120) loss: 11.5813 -- time: 4.4406 sec.\n",
      "Step(5130) loss: 10.0761 -- time: 4.3413 sec.\n",
      "Step(5140) loss: 8.4664 -- time: 4.5260 sec.\n",
      "Step(5150) loss: 8.1433 -- time: 4.3181 sec.\n",
      "Step(5160) loss: 7.0443 -- time: 4.3704 sec.\n",
      "Step(5170) loss: 8.6380 -- time: 4.6442 sec.\n",
      "Step(5180) loss: 4.0162 -- time: 4.4545 sec.\n",
      "Step(5190) loss: 6.9132 -- time: 4.4892 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1378.5607 - val_loss: 0.0000\n",
      "time: 80.2247 sec.\n",
      "time_left: 94.9326 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 30/100\n",
      "----------------------------------------------------------------------\n",
      "Step(5200) loss: 10.6955 -- time: 4.0315 sec.\n",
      "Step(5210) loss: 7.8054 -- time: 4.3692 sec.\n",
      "Step(5220) loss: 7.9029 -- time: 4.4062 sec.\n",
      "Step(5230) loss: 7.4693 -- time: 4.4221 sec.\n",
      "Step(5240) loss: 9.1393 -- time: 4.5714 sec.\n",
      "Step(5250) loss: 4.3352 -- time: 4.3634 sec.\n",
      "Step(5260) loss: 6.6289 -- time: 4.5058 sec.\n",
      "Step(5270) loss: 5.4773 -- time: 4.6454 sec.\n",
      "Step(5280) loss: 7.8011 -- time: 4.3736 sec.\n",
      "Step(5290) loss: 6.4132 -- time: 4.1657 sec.\n",
      "Step(5300) loss: 7.4040 -- time: 4.3301 sec.\n",
      "Step(5310) loss: 9.3396 -- time: 4.4086 sec.\n",
      "Step(5320) loss: 9.5469 -- time: 4.2745 sec.\n",
      "Step(5330) loss: 5.9468 -- time: 4.4145 sec.\n",
      "Step(5340) loss: 7.5058 -- time: 4.3568 sec.\n",
      "Step(5350) loss: 8.1855 -- time: 4.3187 sec.\n",
      "Step(5360) loss: 7.1216 -- time: 4.2993 sec.\n",
      "Step(5370) loss: 6.7259 -- time: 4.1991 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1377.0628 - val_loss: 1367.3387\n",
      "time: 113.6141 sec.\n",
      "time_left: 132.5497 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 31/100\n",
      "----------------------------------------------------------------------\n",
      "Step(5380) loss: 7.4990 -- time: 4.3310 sec.\n",
      "Step(5390) loss: 9.7655 -- time: 4.4863 sec.\n",
      "Step(5400) loss: 8.1069 -- time: 4.3798 sec.\n",
      "Step(5410) loss: 7.2142 -- time: 4.4294 sec.\n",
      "Step(5420) loss: 9.3714 -- time: 4.2292 sec.\n",
      "Step(5430) loss: 9.0578 -- time: 4.2785 sec.\n",
      "Step(5440) loss: 8.4201 -- time: 4.3685 sec.\n",
      "Step(5450) loss: 8.3677 -- time: 4.3923 sec.\n",
      "Step(5460) loss: 7.3703 -- time: 4.2674 sec.\n",
      "Step(5470) loss: 8.0634 -- time: 4.3625 sec.\n",
      "Step(5480) loss: 9.0182 -- time: 4.2951 sec.\n",
      "Step(5490) loss: 6.5712 -- time: 4.3354 sec.\n",
      "Step(5500) loss: 6.5925 -- time: 4.4366 sec.\n",
      "Step(5510) loss: 11.3769 -- time: 4.3825 sec.\n",
      "Step(5520) loss: 13.0994 -- time: 4.2869 sec.\n",
      "Step(5530) loss: 6.2831 -- time: 4.4056 sec.\n",
      "Step(5540) loss: 9.9560 -- time: 4.3273 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1411.5149 - val_loss: 0.0000\n",
      "time: 79.6658 sec.\n",
      "time_left: 91.6157 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 32/100\n",
      "----------------------------------------------------------------------\n",
      "Step(5550) loss: 10.3952 -- time: 0.3362 sec.\n",
      "Step(5560) loss: 9.1423 -- time: 4.3202 sec.\n",
      "Step(5570) loss: 7.5759 -- time: 4.3573 sec.\n",
      "Step(5580) loss: 8.3365 -- time: 4.3718 sec.\n",
      "Step(5590) loss: 8.5138 -- time: 4.4409 sec.\n",
      "Step(5600) loss: 13.4035 -- time: 4.2313 sec.\n",
      "Step(5610) loss: 4.8875 -- time: 4.4605 sec.\n",
      "Step(5620) loss: 7.8409 -- time: 4.3754 sec.\n",
      "Step(5630) loss: 8.3496 -- time: 4.3185 sec.\n",
      "Step(5640) loss: 7.5240 -- time: 4.3889 sec.\n",
      "Step(5650) loss: 12.1215 -- time: 4.4921 sec.\n",
      "Step(5660) loss: 8.1102 -- time: 4.4152 sec.\n",
      "Step(5670) loss: 8.4520 -- time: 4.3656 sec.\n",
      "Step(5680) loss: 6.9715 -- time: 4.3568 sec.\n",
      "Step(5690) loss: 6.1805 -- time: 4.3621 sec.\n",
      "Step(5700) loss: 6.9380 -- time: 4.5617 sec.\n",
      "Step(5710) loss: 9.5264 -- time: 4.3972 sec.\n",
      "Step(5720) loss: 4.2150 -- time: 4.3379 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1406.7221 - val_loss: 0.0000\n",
      "time: 80.2598 sec.\n",
      "time_left: 90.9612 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 33/100\n",
      "----------------------------------------------------------------------\n",
      "Step(5730) loss: 9.6470 -- time: 0.7675 sec.\n",
      "Step(5740) loss: 5.3600 -- time: 4.4178 sec.\n",
      "Step(5750) loss: 8.1784 -- time: 4.4565 sec.\n",
      "Step(5760) loss: 8.5876 -- time: 4.5319 sec.\n",
      "Step(5770) loss: 11.4744 -- time: 4.3176 sec.\n",
      "Step(5780) loss: 9.2512 -- time: 4.4063 sec.\n",
      "Step(5790) loss: 7.2627 -- time: 4.4016 sec.\n",
      "Step(5800) loss: 11.2951 -- time: 4.3625 sec.\n",
      "Step(5810) loss: 8.6889 -- time: 4.4968 sec.\n",
      "Step(5820) loss: 8.6989 -- time: 4.3479 sec.\n",
      "Step(5830) loss: 7.6148 -- time: 4.3596 sec.\n",
      "Step(5840) loss: 6.2631 -- time: 4.3472 sec.\n",
      "Step(5850) loss: 8.3924 -- time: 4.4028 sec.\n",
      "Step(5860) loss: 9.8803 -- time: 4.3050 sec.\n",
      "Step(5870) loss: 4.6842 -- time: 4.5302 sec.\n",
      "Step(5880) loss: 4.9004 -- time: 4.3596 sec.\n",
      "Step(5890) loss: 10.8010 -- time: 4.5883 sec.\n",
      "Step(5900) loss: 6.2153 -- time: 4.3145 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1405.0563 - val_loss: 0.0000\n",
      "time: 80.7343 sec.\n",
      "time_left: 90.1533 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 34/100\n",
      "----------------------------------------------------------------------\n",
      "Step(5910) loss: 7.6522 -- time: 1.2512 sec.\n",
      "Step(5920) loss: 7.4647 -- time: 4.3854 sec.\n",
      "Step(5930) loss: 9.0677 -- time: 4.3080 sec.\n",
      "Step(5940) loss: 7.2519 -- time: 4.2798 sec.\n",
      "Step(5950) loss: 6.8892 -- time: 4.5552 sec.\n",
      "Step(5960) loss: 7.8440 -- time: 4.2855 sec.\n",
      "Step(5970) loss: 8.6555 -- time: 4.4488 sec.\n",
      "Step(5980) loss: 7.0460 -- time: 4.4587 sec.\n",
      "Step(5990) loss: 9.1935 -- time: 4.3583 sec.\n",
      "Step(6000) loss: 8.5517 -- time: 4.4122 sec.\n",
      "Step(6010) loss: 8.0007 -- time: 4.4271 sec.\n",
      "Step(6020) loss: 9.1650 -- time: 4.5208 sec.\n",
      "Step(6030) loss: 6.0429 -- time: 4.2386 sec.\n",
      "Step(6040) loss: 4.0496 -- time: 4.3125 sec.\n",
      "Step(6050) loss: 9.3503 -- time: 4.3874 sec.\n",
      "Step(6060) loss: 4.8564 -- time: 4.3992 sec.\n",
      "Step(6070) loss: 9.7778 -- time: 4.3659 sec.\n",
      "Step(6080) loss: 7.3644 -- time: 4.2901 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1365.9038 - val_loss: 0.0000\n",
      "time: 80.0827 sec.\n",
      "time_left: 88.0910 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 35/100\n",
      "----------------------------------------------------------------------\n",
      "Step(6090) loss: 7.2922 -- time: 1.6281 sec.\n",
      "Step(6100) loss: 7.3504 -- time: 4.2584 sec.\n",
      "Step(6110) loss: 7.1296 -- time: 4.4580 sec.\n",
      "Step(6120) loss: 5.3553 -- time: 4.3671 sec.\n",
      "Step(6130) loss: 6.7137 -- time: 4.3293 sec.\n",
      "Step(6140) loss: 9.9529 -- time: 4.3836 sec.\n",
      "Step(6150) loss: 6.6069 -- time: 4.4150 sec.\n",
      "Step(6160) loss: 6.6078 -- time: 4.3721 sec.\n",
      "Step(6170) loss: 6.7004 -- time: 4.2892 sec.\n",
      "Step(6180) loss: 5.0292 -- time: 4.4691 sec.\n",
      "Step(6190) loss: 7.7346 -- time: 4.2966 sec.\n",
      "Step(6200) loss: 8.1431 -- time: 4.4342 sec.\n",
      "Step(6210) loss: 7.6659 -- time: 4.4623 sec.\n",
      "Step(6220) loss: 8.3120 -- time: 4.5372 sec.\n",
      "Step(6230) loss: 8.3975 -- time: 4.3331 sec.\n",
      "Step(6240) loss: 6.8283 -- time: 4.4068 sec.\n",
      "Step(6250) loss: 5.9328 -- time: 4.3845 sec.\n",
      "Step(6260) loss: 5.7544 -- time: 4.4511 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1369.8695 - val_loss: 0.0000\n",
      "time: 80.2408 sec.\n",
      "time_left: 86.9275 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 36/100\n",
      "----------------------------------------------------------------------\n",
      "Step(6270) loss: 5.2761 -- time: 2.0630 sec.\n",
      "Step(6280) loss: 8.1081 -- time: 4.4491 sec.\n",
      "Step(6290) loss: 9.5847 -- time: 4.4342 sec.\n",
      "Step(6300) loss: 7.2115 -- time: 4.3980 sec.\n",
      "Step(6310) loss: 5.9783 -- time: 4.4469 sec.\n",
      "Step(6320) loss: 6.6142 -- time: 4.3603 sec.\n",
      "Step(6330) loss: 7.4567 -- time: 4.3630 sec.\n",
      "Step(6340) loss: 6.8628 -- time: 4.5017 sec.\n",
      "Step(6350) loss: 8.0388 -- time: 4.3210 sec.\n",
      "Step(6360) loss: 9.0213 -- time: 4.4781 sec.\n",
      "Step(6370) loss: 11.7348 -- time: 4.4208 sec.\n",
      "Step(6380) loss: 7.5690 -- time: 4.3515 sec.\n",
      "Step(6390) loss: 7.7812 -- time: 4.4545 sec.\n",
      "Step(6400) loss: 7.9144 -- time: 4.2855 sec.\n",
      "Step(6410) loss: 6.3171 -- time: 4.2672 sec.\n",
      "Step(6420) loss: 6.6439 -- time: 4.4040 sec.\n",
      "Step(6430) loss: 8.6227 -- time: 4.2800 sec.\n",
      "Step(6440) loss: 7.4835 -- time: 4.5308 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1368.2474 - val_loss: 0.0000\n",
      "time: 80.3684 sec.\n",
      "time_left: 85.7263 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 37/100\n",
      "----------------------------------------------------------------------\n",
      "Step(6450) loss: 9.9073 -- time: 2.5933 sec.\n",
      "Step(6460) loss: 4.3929 -- time: 4.2156 sec.\n",
      "Step(6470) loss: 8.4121 -- time: 4.3919 sec.\n",
      "Step(6480) loss: 8.6083 -- time: 4.5015 sec.\n",
      "Step(6490) loss: 5.4307 -- time: 4.4115 sec.\n",
      "Step(6500) loss: 8.4365 -- time: 4.5924 sec.\n",
      "Step(6510) loss: 12.4334 -- time: 4.4772 sec.\n",
      "Step(6520) loss: 4.7540 -- time: 4.4204 sec.\n",
      "Step(6530) loss: 7.1419 -- time: 4.4676 sec.\n",
      "Step(6540) loss: 9.5270 -- time: 4.4468 sec.\n",
      "Step(6550) loss: 8.0562 -- time: 4.5039 sec.\n",
      "Step(6560) loss: 7.6426 -- time: 4.5403 sec.\n",
      "Step(6570) loss: 7.2500 -- time: 4.4098 sec.\n",
      "Step(6580) loss: 4.6040 -- time: 4.3328 sec.\n",
      "Step(6590) loss: 7.4230 -- time: 4.3694 sec.\n",
      "Step(6600) loss: 7.8239 -- time: 4.3830 sec.\n",
      "Step(6610) loss: 4.7813 -- time: 4.3777 sec.\n",
      "Step(6620) loss: 6.7320 -- time: 4.3731 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1338.5363 - val_loss: 0.0000\n",
      "time: 80.9014 sec.\n",
      "time_left: 84.9465 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 38/100\n",
      "----------------------------------------------------------------------\n",
      "Step(6630) loss: 8.0422 -- time: 3.0338 sec.\n",
      "Step(6640) loss: 6.1236 -- time: 4.3839 sec.\n",
      "Step(6650) loss: 8.7538 -- time: 4.5752 sec.\n",
      "Step(6660) loss: 12.5003 -- time: 4.4984 sec.\n",
      "Step(6670) loss: 8.1117 -- time: 4.5924 sec.\n",
      "Step(6680) loss: 7.7846 -- time: 4.5188 sec.\n",
      "Step(6690) loss: 7.3002 -- time: 4.4420 sec.\n",
      "Step(6700) loss: 7.0245 -- time: 4.5328 sec.\n",
      "Step(6710) loss: 7.2818 -- time: 4.4223 sec.\n",
      "Step(6720) loss: 7.6584 -- time: 4.5072 sec.\n",
      "Step(6730) loss: 7.0620 -- time: 4.3411 sec.\n",
      "Step(6740) loss: 8.3700 -- time: 4.4329 sec.\n",
      "Step(6750) loss: 5.6311 -- time: 4.5207 sec.\n",
      "Step(6760) loss: 5.1522 -- time: 4.5297 sec.\n",
      "Step(6770) loss: 3.9533 -- time: 4.4759 sec.\n",
      "Step(6780) loss: 7.1491 -- time: 4.4239 sec.\n",
      "Step(6790) loss: 9.5683 -- time: 4.4848 sec.\n",
      "Step(6800) loss: 6.2914 -- time: 4.3789 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1370.5654 - val_loss: 0.0000\n",
      "time: 81.8141 sec.\n",
      "time_left: 84.5413 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 39/100\n",
      "----------------------------------------------------------------------\n",
      "Step(6810) loss: 5.8034 -- time: 3.5760 sec.\n",
      "Step(6820) loss: 6.8709 -- time: 4.3365 sec.\n",
      "Step(6830) loss: 7.9965 -- time: 4.5302 sec.\n",
      "Step(6840) loss: 6.6428 -- time: 4.5433 sec.\n",
      "Step(6850) loss: 4.7555 -- time: 4.4642 sec.\n",
      "Step(6860) loss: 7.8880 -- time: 4.5266 sec.\n",
      "Step(6870) loss: 5.7705 -- time: 4.4978 sec.\n",
      "Step(6880) loss: 6.8377 -- time: 4.4204 sec.\n",
      "Step(6890) loss: 4.4492 -- time: 4.3375 sec.\n",
      "Step(6900) loss: 8.5740 -- time: 4.2561 sec.\n",
      "Step(6910) loss: 7.5039 -- time: 4.3963 sec.\n",
      "Step(6920) loss: 7.3556 -- time: 4.3792 sec.\n",
      "Step(6930) loss: 10.4354 -- time: 4.3845 sec.\n",
      "Step(6940) loss: 5.1401 -- time: 4.3870 sec.\n",
      "Step(6950) loss: 6.1745 -- time: 4.2719 sec.\n",
      "Step(6960) loss: 8.3480 -- time: 4.1765 sec.\n",
      "Step(6970) loss: 5.7822 -- time: 4.4714 sec.\n",
      "Step(6980) loss: 8.2527 -- time: 4.2942 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1310.2205 - val_loss: 0.0000\n",
      "time: 80.4612 sec.\n",
      "time_left: 81.8022 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 40/100\n",
      "----------------------------------------------------------------------\n",
      "Step(6990) loss: 7.9121 -- time: 3.8149 sec.\n",
      "Step(7000) loss: 6.9806 -- time: 4.2236 sec.\n",
      "Step(7010) loss: 10.1578 -- time: 4.2433 sec.\n",
      "Step(7020) loss: 9.0994 -- time: 4.3530 sec.\n",
      "Step(7030) loss: 6.7219 -- time: 4.3686 sec.\n",
      "Step(7040) loss: 7.8805 -- time: 4.4637 sec.\n",
      "Step(7050) loss: 6.3346 -- time: 4.1783 sec.\n",
      "Step(7060) loss: 5.3915 -- time: 4.4220 sec.\n",
      "Step(7070) loss: 9.7748 -- time: 4.4350 sec.\n",
      "Step(7080) loss: 14.8651 -- time: 4.2514 sec.\n",
      "Step(7090) loss: 7.6356 -- time: 4.3463 sec.\n",
      "Step(7100) loss: 6.1605 -- time: 4.4221 sec.\n",
      "Step(7110) loss: 8.5760 -- time: 4.3143 sec.\n",
      "Step(7120) loss: 11.5807 -- time: 4.3214 sec.\n",
      "Step(7130) loss: 7.8766 -- time: 4.3705 sec.\n",
      "Step(7140) loss: 7.4878 -- time: 4.3448 sec.\n",
      "Step(7150) loss: 7.3125 -- time: 4.4250 sec.\n",
      "Step(7160) loss: 7.7570 -- time: 4.2045 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1435.2677 - val_loss: 1391.1942\n",
      "time: 112.6705 sec.\n",
      "time_left: 112.6705 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 41/100\n",
      "----------------------------------------------------------------------\n",
      "Step(7170) loss: 7.3535 -- time: 4.3560 sec.\n",
      "Step(7180) loss: 13.5306 -- time: 4.4895 sec.\n",
      "Step(7190) loss: 7.4586 -- time: 4.4489 sec.\n",
      "Step(7200) loss: 9.1437 -- time: 4.3571 sec.\n",
      "Step(7210) loss: 11.1629 -- time: 4.4094 sec.\n",
      "Step(7220) loss: 6.8395 -- time: 4.4986 sec.\n",
      "Step(7230) loss: 8.0747 -- time: 4.2793 sec.\n",
      "Step(7240) loss: 9.0691 -- time: 4.3241 sec.\n",
      "Step(7250) loss: 7.3207 -- time: 4.3507 sec.\n",
      "Step(7260) loss: 7.6997 -- time: 4.3441 sec.\n",
      "Step(7270) loss: 5.3588 -- time: 4.2716 sec.\n",
      "Step(7280) loss: 8.7050 -- time: 4.4404 sec.\n",
      "Step(7290) loss: 5.0285 -- time: 4.3156 sec.\n",
      "Step(7300) loss: 8.2411 -- time: 4.4834 sec.\n",
      "Step(7310) loss: 10.3552 -- time: 4.4740 sec.\n",
      "Step(7320) loss: 7.2142 -- time: 4.4073 sec.\n",
      "Step(7330) loss: 6.3446 -- time: 4.2407 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1376.4970 - val_loss: 0.0000\n",
      "time: 80.2736 sec.\n",
      "time_left: 78.9357 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 42/100\n",
      "----------------------------------------------------------------------\n",
      "Step(7340) loss: 10.6619 -- time: 0.3267 sec.\n",
      "Step(7350) loss: 7.3338 -- time: 4.3573 sec.\n",
      "Step(7360) loss: 7.4375 -- time: 4.3241 sec.\n",
      "Step(7370) loss: 7.7978 -- time: 4.4149 sec.\n",
      "Step(7380) loss: 5.9078 -- time: 4.3190 sec.\n",
      "Step(7390) loss: 7.9849 -- time: 4.5339 sec.\n",
      "Step(7400) loss: 6.2280 -- time: 4.3347 sec.\n",
      "Step(7410) loss: 9.6431 -- time: 4.4616 sec.\n",
      "Step(7420) loss: 6.3877 -- time: 4.4070 sec.\n",
      "Step(7430) loss: 4.8585 -- time: 4.5333 sec.\n",
      "Step(7440) loss: 17.0177 -- time: 4.3141 sec.\n",
      "Step(7450) loss: 7.8505 -- time: 4.3949 sec.\n",
      "Step(7460) loss: 7.8309 -- time: 4.3367 sec.\n",
      "Step(7470) loss: 6.7764 -- time: 4.3371 sec.\n",
      "Step(7480) loss: 6.2163 -- time: 4.3474 sec.\n",
      "Step(7490) loss: 8.8653 -- time: 4.4256 sec.\n",
      "Step(7500) loss: 8.0244 -- time: 4.3934 sec.\n",
      "Step(7510) loss: 7.6095 -- time: 4.3058 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1397.4767 - val_loss: 0.0000\n",
      "time: 80.3116 sec.\n",
      "time_left: 77.6345 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 43/100\n",
      "----------------------------------------------------------------------\n",
      "Step(7520) loss: 7.0972 -- time: 0.8356 sec.\n",
      "Step(7530) loss: 7.6966 -- time: 4.4573 sec.\n",
      "Step(7540) loss: 6.1587 -- time: 4.2531 sec.\n",
      "Step(7550) loss: 8.6982 -- time: 4.4907 sec.\n",
      "Step(7560) loss: 8.1177 -- time: 4.4262 sec.\n",
      "Step(7570) loss: 8.9600 -- time: 4.4462 sec.\n",
      "Step(7580) loss: 7.0794 -- time: 4.3103 sec.\n",
      "Step(7590) loss: 8.4289 -- time: 4.3591 sec.\n",
      "Step(7600) loss: 6.4491 -- time: 4.2200 sec.\n",
      "Step(7610) loss: 7.1384 -- time: 4.3231 sec.\n",
      "Step(7620) loss: 9.2263 -- time: 4.3147 sec.\n",
      "Step(7630) loss: 10.2304 -- time: 4.3479 sec.\n",
      "Step(7640) loss: 10.3137 -- time: 4.3546 sec.\n",
      "Step(7650) loss: 4.2700 -- time: 4.3410 sec.\n",
      "Step(7660) loss: 6.9280 -- time: 4.2869 sec.\n",
      "Step(7670) loss: 7.5026 -- time: 4.3893 sec.\n",
      "Step(7680) loss: 9.4863 -- time: 4.3175 sec.\n",
      "Step(7690) loss: 8.0223 -- time: 4.3809 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1407.4192 - val_loss: 0.0000\n",
      "time: 79.8312 sec.\n",
      "time_left: 75.8396 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 44/100\n",
      "----------------------------------------------------------------------\n",
      "Step(7700) loss: 7.4564 -- time: 1.2037 sec.\n",
      "Step(7710) loss: 6.2842 -- time: 4.4875 sec.\n",
      "Step(7720) loss: 9.1628 -- time: 4.2153 sec.\n",
      "Step(7730) loss: 7.8484 -- time: 4.3690 sec.\n",
      "Step(7740) loss: 7.8205 -- time: 4.4494 sec.\n",
      "Step(7750) loss: 4.9314 -- time: 4.3448 sec.\n",
      "Step(7760) loss: 7.0402 -- time: 4.2504 sec.\n",
      "Step(7770) loss: 9.4640 -- time: 4.4249 sec.\n",
      "Step(7780) loss: 9.7940 -- time: 4.3708 sec.\n",
      "Step(7790) loss: 22.8505 -- time: 4.3785 sec.\n",
      "Step(7800) loss: 13.0770 -- time: 4.4489 sec.\n",
      "Step(7810) loss: 8.8953 -- time: 4.2857 sec.\n",
      "Step(7820) loss: 7.0669 -- time: 4.4550 sec.\n",
      "Step(7830) loss: 6.9174 -- time: 4.3189 sec.\n",
      "Step(7840) loss: 6.6854 -- time: 4.3393 sec.\n",
      "Step(7850) loss: 3.9958 -- time: 4.3066 sec.\n",
      "Step(7860) loss: 4.7971 -- time: 4.3082 sec.\n",
      "Step(7870) loss: 7.4386 -- time: 4.3603 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1412.2629 - val_loss: 0.0000\n",
      "time: 79.7479 sec.\n",
      "time_left: 74.4314 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 45/100\n",
      "----------------------------------------------------------------------\n",
      "Step(7880) loss: 9.1225 -- time: 1.6716 sec.\n",
      "Step(7890) loss: 7.0990 -- time: 4.3221 sec.\n",
      "Step(7900) loss: 8.6086 -- time: 4.3436 sec.\n",
      "Step(7910) loss: 6.3903 -- time: 4.3789 sec.\n",
      "Step(7920) loss: 6.8746 -- time: 4.3510 sec.\n",
      "Step(7930) loss: 14.4487 -- time: 4.4044 sec.\n",
      "Step(7940) loss: 4.0611 -- time: 4.3643 sec.\n",
      "Step(7950) loss: 3.8471 -- time: 4.3193 sec.\n",
      "Step(7960) loss: 8.4320 -- time: 4.4332 sec.\n",
      "Step(7970) loss: 7.2074 -- time: 4.2277 sec.\n",
      "Step(7980) loss: 5.8181 -- time: 4.2759 sec.\n",
      "Step(7990) loss: 6.4770 -- time: 4.1794 sec.\n",
      "Step(8000) loss: 4.0281 -- time: 4.2689 sec.\n",
      "Step(8010) loss: 7.9478 -- time: 4.4603 sec.\n",
      "Step(8020) loss: 6.7672 -- time: 4.3925 sec.\n",
      "Step(8030) loss: 6.5384 -- time: 4.2244 sec.\n",
      "Step(8040) loss: 5.1066 -- time: 4.3645 sec.\n",
      "Step(8050) loss: 8.8758 -- time: 4.3175 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1346.5694 - val_loss: 0.0000\n",
      "time: 79.2613 sec.\n",
      "time_left: 72.6562 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 46/100\n",
      "----------------------------------------------------------------------\n",
      "Step(8060) loss: 7.7245 -- time: 2.1381 sec.\n",
      "Step(8070) loss: 7.4266 -- time: 4.4006 sec.\n",
      "Step(8080) loss: 8.9101 -- time: 4.2497 sec.\n",
      "Step(8090) loss: 6.8866 -- time: 4.2995 sec.\n",
      "Step(8100) loss: 10.4190 -- time: 4.2377 sec.\n",
      "Step(8110) loss: 10.4793 -- time: 4.4001 sec.\n",
      "Step(8120) loss: 8.2189 -- time: 4.4464 sec.\n",
      "Step(8130) loss: 9.2227 -- time: 4.3932 sec.\n",
      "Step(8140) loss: 6.5895 -- time: 4.3963 sec.\n",
      "Step(8150) loss: 6.5000 -- time: 4.3613 sec.\n",
      "Step(8160) loss: 7.9639 -- time: 4.3337 sec.\n",
      "Step(8170) loss: 4.4319 -- time: 4.3752 sec.\n",
      "Step(8180) loss: 6.9912 -- time: 4.3453 sec.\n",
      "Step(8190) loss: 8.0132 -- time: 4.3080 sec.\n",
      "Step(8200) loss: 7.8204 -- time: 4.3429 sec.\n",
      "Step(8210) loss: 6.3228 -- time: 4.4998 sec.\n",
      "Step(8220) loss: 7.2567 -- time: 4.4042 sec.\n",
      "Step(8230) loss: 10.3431 -- time: 4.4886 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1414.6074 - val_loss: 0.0000\n",
      "time: 80.0353 sec.\n",
      "time_left: 72.0317 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 47/100\n",
      "----------------------------------------------------------------------\n",
      "Step(8240) loss: 7.0307 -- time: 2.6938 sec.\n",
      "Step(8250) loss: 7.7033 -- time: 4.3363 sec.\n",
      "Step(8260) loss: 9.1188 -- time: 4.3250 sec.\n",
      "Step(8270) loss: 7.6997 -- time: 4.3678 sec.\n",
      "Step(8280) loss: 6.5125 -- time: 4.3309 sec.\n",
      "Step(8290) loss: 5.9465 -- time: 4.2894 sec.\n",
      "Step(8300) loss: 9.5096 -- time: 4.3783 sec.\n",
      "Step(8310) loss: 10.4860 -- time: 4.5232 sec.\n",
      "Step(8320) loss: 7.6976 -- time: 4.4295 sec.\n",
      "Step(8330) loss: 9.1213 -- time: 4.3995 sec.\n",
      "Step(8340) loss: 8.9558 -- time: 4.4190 sec.\n",
      "Step(8350) loss: 6.9973 -- time: 4.3077 sec.\n",
      "Step(8360) loss: 6.9326 -- time: 4.2845 sec.\n",
      "Step(8370) loss: 7.1383 -- time: 4.4456 sec.\n",
      "Step(8380) loss: 6.9651 -- time: 4.4446 sec.\n",
      "Step(8390) loss: 6.9013 -- time: 4.3519 sec.\n",
      "Step(8400) loss: 4.4665 -- time: 4.3155 sec.\n",
      "Step(8410) loss: 4.8853 -- time: 4.2915 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1367.4451 - val_loss: 0.0000\n",
      "time: 80.0875 sec.\n",
      "time_left: 70.7439 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 48/100\n",
      "----------------------------------------------------------------------\n",
      "Step(8420) loss: 8.0126 -- time: 3.0790 sec.\n",
      "Step(8430) loss: 11.7142 -- time: 4.3993 sec.\n",
      "Step(8440) loss: 5.7876 -- time: 4.3497 sec.\n",
      "Step(8450) loss: 8.5981 -- time: 4.5244 sec.\n",
      "Step(8460) loss: 8.7357 -- time: 4.2403 sec.\n",
      "Step(8470) loss: 8.8941 -- time: 4.5194 sec.\n",
      "Step(8480) loss: 13.3149 -- time: 4.3636 sec.\n",
      "Step(8490) loss: 8.0485 -- time: 4.3869 sec.\n",
      "Step(8500) loss: 10.8968 -- time: 4.2958 sec.\n",
      "Step(8510) loss: 9.7876 -- time: 4.3274 sec.\n",
      "Step(8520) loss: 8.2242 -- time: 4.4542 sec.\n",
      "Step(8530) loss: 8.5626 -- time: 4.3747 sec.\n",
      "Step(8540) loss: 6.9622 -- time: 4.3505 sec.\n",
      "Step(8550) loss: 6.4231 -- time: 4.3693 sec.\n",
      "Step(8560) loss: 6.0109 -- time: 4.4751 sec.\n",
      "Step(8570) loss: 7.7161 -- time: 4.3337 sec.\n",
      "Step(8580) loss: 7.4146 -- time: 4.3608 sec.\n",
      "Step(8590) loss: 5.8606 -- time: 4.3552 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1377.4515 - val_loss: 0.0000\n",
      "time: 80.2125 sec.\n",
      "time_left: 69.5175 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 49/100\n",
      "----------------------------------------------------------------------\n",
      "Step(8600) loss: 9.5952 -- time: 3.4602 sec.\n",
      "Step(8610) loss: 5.9910 -- time: 4.2687 sec.\n",
      "Step(8620) loss: 5.8438 -- time: 4.4154 sec.\n",
      "Step(8630) loss: 7.6414 -- time: 4.3613 sec.\n",
      "Step(8640) loss: 6.1534 -- time: 4.3651 sec.\n",
      "Step(8650) loss: 7.8738 -- time: 4.3756 sec.\n",
      "Step(8660) loss: 8.0085 -- time: 4.3898 sec.\n",
      "Step(8670) loss: 6.6901 -- time: 4.2479 sec.\n",
      "Step(8680) loss: 6.8841 -- time: 4.3787 sec.\n",
      "Step(8690) loss: 6.1087 -- time: 4.3982 sec.\n",
      "Step(8700) loss: 7.5735 -- time: 4.2661 sec.\n",
      "Step(8710) loss: 6.7091 -- time: 4.2240 sec.\n",
      "Step(8720) loss: 6.8495 -- time: 4.3581 sec.\n",
      "Step(8730) loss: 4.7551 -- time: 4.3148 sec.\n",
      "Step(8740) loss: 8.1068 -- time: 4.3284 sec.\n",
      "Step(8750) loss: 6.2336 -- time: 4.4056 sec.\n",
      "Step(8760) loss: 7.1217 -- time: 4.3652 sec.\n",
      "Step(8770) loss: 6.4356 -- time: 4.3452 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1396.8527 - val_loss: 0.0000\n",
      "time: 79.4624 sec.\n",
      "time_left: 67.5430 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 50/100\n",
      "----------------------------------------------------------------------\n",
      "Step(8780) loss: 8.2239 -- time: 3.8246 sec.\n",
      "Step(8790) loss: 17.2470 -- time: 4.3339 sec.\n",
      "Step(8800) loss: 7.7375 -- time: 4.3612 sec.\n",
      "Step(8810) loss: 7.8334 -- time: 4.4024 sec.\n",
      "Step(8820) loss: 5.3929 -- time: 4.4653 sec.\n",
      "Step(8830) loss: 7.6075 -- time: 4.3928 sec.\n",
      "Step(8840) loss: 6.9805 -- time: 4.3717 sec.\n",
      "Step(8850) loss: 5.2196 -- time: 4.3531 sec.\n",
      "Step(8860) loss: 4.2525 -- time: 4.3010 sec.\n",
      "Step(8870) loss: 5.6047 -- time: 4.4665 sec.\n",
      "Step(8880) loss: 8.4498 -- time: 4.2860 sec.\n",
      "Step(8890) loss: 23.3694 -- time: 4.3327 sec.\n",
      "Step(8900) loss: 7.6183 -- time: 4.4339 sec.\n",
      "Step(8910) loss: 6.5214 -- time: 4.3765 sec.\n",
      "Step(8920) loss: 13.2526 -- time: 4.2762 sec.\n",
      "Step(8930) loss: 8.7426 -- time: 4.3456 sec.\n",
      "Step(8940) loss: 6.1498 -- time: 4.2128 sec.\n",
      "Step(8950) loss: 8.9727 -- time: 4.2104 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1401.1809 - val_loss: 1356.6176\n",
      "time: 112.8040 sec.\n",
      "time_left: 94.0033 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 51/100\n",
      "----------------------------------------------------------------------\n",
      "Step(8960) loss: 6.7637 -- time: 4.4279 sec.\n",
      "Step(8970) loss: 8.1411 -- time: 4.3746 sec.\n",
      "Step(8980) loss: 7.5001 -- time: 4.2806 sec.\n",
      "Step(8990) loss: 8.3904 -- time: 4.4010 sec.\n",
      "Step(9000) loss: 5.4131 -- time: 4.4766 sec.\n",
      "Step(9010) loss: 7.5321 -- time: 4.3086 sec.\n",
      "Step(9020) loss: 6.1023 -- time: 4.4821 sec.\n",
      "Step(9030) loss: 7.7885 -- time: 4.5493 sec.\n",
      "Step(9040) loss: 6.1665 -- time: 4.4618 sec.\n",
      "Step(9050) loss: 8.0156 -- time: 4.4842 sec.\n",
      "Step(9060) loss: 10.5639 -- time: 4.4303 sec.\n",
      "Step(9070) loss: 7.2790 -- time: 4.4502 sec.\n",
      "Step(9080) loss: 7.3777 -- time: 4.4405 sec.\n",
      "Step(9090) loss: 9.6857 -- time: 4.2728 sec.\n",
      "Step(9100) loss: 7.9013 -- time: 4.3645 sec.\n",
      "Step(9110) loss: 8.9608 -- time: 4.4178 sec.\n",
      "Step(9120) loss: 6.7085 -- time: 4.3483 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1467.6185 - val_loss: 0.0000\n",
      "time: 80.6020 sec.\n",
      "time_left: 65.8249 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 52/100\n",
      "----------------------------------------------------------------------\n",
      "Step(9130) loss: 11.6629 -- time: 0.3249 sec.\n",
      "Step(9140) loss: 7.4827 -- time: 4.4517 sec.\n",
      "Step(9150) loss: 7.1865 -- time: 4.3492 sec.\n",
      "Step(9160) loss: 6.7483 -- time: 4.2713 sec.\n",
      "Step(9170) loss: 7.6112 -- time: 4.4646 sec.\n",
      "Step(9180) loss: 8.0038 -- time: 4.3193 sec.\n",
      "Step(9190) loss: 8.9996 -- time: 4.2266 sec.\n",
      "Step(9200) loss: 5.9513 -- time: 4.3644 sec.\n",
      "Step(9210) loss: 6.3380 -- time: 4.3296 sec.\n",
      "Step(9220) loss: 8.6193 -- time: 4.3246 sec.\n",
      "Step(9230) loss: 6.9207 -- time: 4.3532 sec.\n",
      "Step(9240) loss: 8.0634 -- time: 4.3685 sec.\n",
      "Step(9250) loss: 6.7379 -- time: 4.3532 sec.\n",
      "Step(9260) loss: 6.5719 -- time: 4.2994 sec.\n",
      "Step(9270) loss: 5.8437 -- time: 4.3261 sec.\n",
      "Step(9280) loss: 6.6955 -- time: 4.3147 sec.\n",
      "Step(9290) loss: 6.8539 -- time: 4.3313 sec.\n",
      "Step(9300) loss: 8.6231 -- time: 4.4041 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1360.9058 - val_loss: 0.0000\n",
      "time: 79.4264 sec.\n",
      "time_left: 63.5411 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 53/100\n",
      "----------------------------------------------------------------------\n",
      "Step(9310) loss: 6.2018 -- time: 0.7620 sec.\n",
      "Step(9320) loss: 5.7301 -- time: 4.2139 sec.\n",
      "Step(9330) loss: 7.4403 -- time: 4.2770 sec.\n",
      "Step(9340) loss: 12.2384 -- time: 4.3640 sec.\n",
      "Step(9350) loss: 7.6898 -- time: 4.3243 sec.\n",
      "Step(9360) loss: 7.4592 -- time: 4.3899 sec.\n",
      "Step(9370) loss: 8.8542 -- time: 4.4054 sec.\n",
      "Step(9380) loss: 6.8328 -- time: 4.5689 sec.\n",
      "Step(9390) loss: 8.8385 -- time: 4.5059 sec.\n",
      "Step(9400) loss: 5.9250 -- time: 4.2866 sec.\n",
      "Step(9410) loss: 6.7117 -- time: 4.4039 sec.\n",
      "Step(9420) loss: 8.1056 -- time: 4.5137 sec.\n",
      "Step(9430) loss: 9.0107 -- time: 4.3330 sec.\n",
      "Step(9440) loss: 8.1372 -- time: 4.4146 sec.\n",
      "Step(9450) loss: 4.1944 -- time: 4.2917 sec.\n",
      "Step(9460) loss: 4.7848 -- time: 4.3498 sec.\n",
      "Step(9470) loss: 6.6911 -- time: 4.2783 sec.\n",
      "Step(9480) loss: 4.4986 -- time: 4.1641 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1342.5529 - val_loss: 0.0000\n",
      "time: 79.7279 sec.\n",
      "time_left: 62.4535 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 54/100\n",
      "----------------------------------------------------------------------\n",
      "Step(9490) loss: 7.4842 -- time: 1.2630 sec.\n",
      "Step(9500) loss: 8.5105 -- time: 4.4240 sec.\n",
      "Step(9510) loss: 7.2621 -- time: 4.3643 sec.\n",
      "Step(9520) loss: 7.0575 -- time: 4.3838 sec.\n",
      "Step(9530) loss: 8.0802 -- time: 4.3908 sec.\n",
      "Step(9540) loss: 8.7221 -- time: 4.3197 sec.\n",
      "Step(9550) loss: 9.1481 -- time: 4.4718 sec.\n",
      "Step(9560) loss: 5.9421 -- time: 4.4430 sec.\n",
      "Step(9570) loss: 4.2410 -- time: 4.4303 sec.\n",
      "Step(9580) loss: 8.2034 -- time: 4.3277 sec.\n",
      "Step(9590) loss: 6.8348 -- time: 4.2684 sec.\n",
      "Step(9600) loss: 15.4367 -- time: 4.2609 sec.\n",
      "Step(9610) loss: 8.0337 -- time: 4.3194 sec.\n",
      "Step(9620) loss: 10.8765 -- time: 4.3171 sec.\n",
      "Step(9630) loss: 9.5275 -- time: 4.4566 sec.\n",
      "Step(9640) loss: 7.0358 -- time: 4.4154 sec.\n",
      "Step(9650) loss: 9.8544 -- time: 4.3501 sec.\n",
      "Step(9660) loss: 6.2121 -- time: 4.4527 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1396.6194 - val_loss: 0.0000\n",
      "time: 80.1839 sec.\n",
      "time_left: 61.4743 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 55/100\n",
      "----------------------------------------------------------------------\n",
      "Step(9670) loss: 9.9181 -- time: 1.8054 sec.\n",
      "Step(9680) loss: 7.1685 -- time: 4.3951 sec.\n",
      "Step(9690) loss: 5.9291 -- time: 4.3885 sec.\n",
      "Step(9700) loss: 5.0424 -- time: 4.4173 sec.\n",
      "Step(9710) loss: 6.1752 -- time: 4.4466 sec.\n",
      "Step(9720) loss: 5.8650 -- time: 4.3701 sec.\n",
      "Step(9730) loss: 7.5756 -- time: 4.2967 sec.\n",
      "Step(9740) loss: 6.1709 -- time: 4.3034 sec.\n",
      "Step(9750) loss: 9.7183 -- time: 4.3499 sec.\n",
      "Step(9760) loss: 8.0774 -- time: 4.3210 sec.\n",
      "Step(9770) loss: 5.4960 -- time: 4.3960 sec.\n",
      "Step(9780) loss: 5.5852 -- time: 4.4621 sec.\n",
      "Step(9790) loss: 6.4764 -- time: 4.3775 sec.\n",
      "Step(9800) loss: 6.2605 -- time: 4.3678 sec.\n",
      "Step(9810) loss: 7.3425 -- time: 4.4161 sec.\n",
      "Step(9820) loss: 5.8665 -- time: 4.3336 sec.\n",
      "Step(9830) loss: 6.7268 -- time: 4.2482 sec.\n",
      "Step(9840) loss: 6.3370 -- time: 4.4534 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1384.2046 - val_loss: 0.0000\n",
      "time: 80.1447 sec.\n",
      "time_left: 60.1085 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 56/100\n",
      "----------------------------------------------------------------------\n",
      "Step(9850) loss: 7.9046 -- time: 2.2059 sec.\n",
      "Step(9860) loss: 7.1459 -- time: 4.4582 sec.\n",
      "Step(9870) loss: 6.1450 -- time: 4.2699 sec.\n",
      "Step(9880) loss: 7.6861 -- time: 4.2896 sec.\n",
      "Step(9890) loss: 8.7745 -- time: 4.4285 sec.\n",
      "Step(9900) loss: 8.8543 -- time: 4.4235 sec.\n",
      "Step(9910) loss: 6.0979 -- time: 4.2326 sec.\n",
      "Step(9920) loss: 6.3978 -- time: 4.2584 sec.\n",
      "Step(9930) loss: 5.9892 -- time: 4.3556 sec.\n",
      "Step(9940) loss: 9.2862 -- time: 4.2041 sec.\n",
      "Step(9950) loss: 8.4911 -- time: 4.4623 sec.\n",
      "Step(9960) loss: 7.5408 -- time: 4.4606 sec.\n",
      "Step(9970) loss: 8.0917 -- time: 4.1814 sec.\n",
      "Step(9980) loss: 7.5348 -- time: 4.2758 sec.\n",
      "Step(9990) loss: 8.2232 -- time: 4.3165 sec.\n",
      "Step(10000) loss: 10.0293 -- time: 4.4314 sec.\n",
      "Step(10010) loss: 22.9274 -- time: 4.3812 sec.\n",
      "Step(10020) loss: 7.6949 -- time: 4.3454 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1393.0590 - val_loss: 0.0000\n",
      "time: 79.4752 sec.\n",
      "time_left: 58.2818 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 57/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10030) loss: 6.5506 -- time: 2.7223 sec.\n",
      "Step(10040) loss: 6.3562 -- time: 4.2889 sec.\n",
      "Step(10050) loss: 10.0537 -- time: 4.2918 sec.\n",
      "Step(10060) loss: 8.4006 -- time: 4.4018 sec.\n",
      "Step(10070) loss: 8.5155 -- time: 4.2961 sec.\n",
      "Step(10080) loss: 4.3389 -- time: 4.1872 sec.\n",
      "Step(10090) loss: 7.1715 -- time: 4.3201 sec.\n",
      "Step(10100) loss: 7.7633 -- time: 4.3498 sec.\n",
      "Step(10110) loss: 8.0801 -- time: 4.2808 sec.\n",
      "Step(10120) loss: 8.1135 -- time: 4.3676 sec.\n",
      "Step(10130) loss: 6.4817 -- time: 4.3359 sec.\n",
      "Step(10140) loss: 7.1817 -- time: 4.4653 sec.\n",
      "Step(10150) loss: 4.5522 -- time: 4.2058 sec.\n",
      "Step(10160) loss: 6.1740 -- time: 4.2302 sec.\n",
      "Step(10170) loss: 6.2488 -- time: 4.3669 sec.\n",
      "Step(10180) loss: 5.7184 -- time: 4.4136 sec.\n",
      "Step(10190) loss: 4.5808 -- time: 4.2277 sec.\n",
      "Step(10200) loss: 8.8032 -- time: 4.2457 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1351.2663 - val_loss: 0.0000\n",
      "time: 79.1224 sec.\n",
      "time_left: 56.7044 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 58/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10210) loss: 9.7468 -- time: 3.0856 sec.\n",
      "Step(10220) loss: 7.3828 -- time: 4.4276 sec.\n",
      "Step(10230) loss: 8.4412 -- time: 4.4771 sec.\n",
      "Step(10240) loss: 7.2797 -- time: 4.3662 sec.\n",
      "Step(10250) loss: 6.2757 -- time: 4.3265 sec.\n",
      "Step(10260) loss: 9.1582 -- time: 4.4280 sec.\n",
      "Step(10270) loss: 20.8441 -- time: 4.4424 sec.\n",
      "Step(10280) loss: 8.8451 -- time: 4.3637 sec.\n",
      "Step(10290) loss: 8.1042 -- time: 4.2316 sec.\n",
      "Step(10300) loss: 6.7804 -- time: 4.3486 sec.\n",
      "Step(10310) loss: 7.0770 -- time: 4.4577 sec.\n",
      "Step(10320) loss: 4.8370 -- time: 4.3514 sec.\n",
      "Step(10330) loss: 6.6142 -- time: 4.3090 sec.\n",
      "Step(10340) loss: 9.2342 -- time: 4.3099 sec.\n",
      "Step(10350) loss: 6.7526 -- time: 4.4077 sec.\n",
      "Step(10360) loss: 7.7199 -- time: 4.4634 sec.\n",
      "Step(10370) loss: 8.0303 -- time: 4.2738 sec.\n",
      "Step(10380) loss: 7.4329 -- time: 4.2581 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1311.7392 - val_loss: 0.0000\n",
      "time: 80.0393 sec.\n",
      "time_left: 56.0275 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 59/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10390) loss: 6.4226 -- time: 3.3920 sec.\n",
      "Step(10400) loss: 7.1720 -- time: 4.3324 sec.\n",
      "Step(10410) loss: 7.7175 -- time: 4.0939 sec.\n",
      "Step(10420) loss: 5.9681 -- time: 4.2968 sec.\n",
      "Step(10430) loss: 8.5214 -- time: 4.3761 sec.\n",
      "Step(10440) loss: 6.3629 -- time: 4.2870 sec.\n",
      "Step(10450) loss: 9.1420 -- time: 4.3772 sec.\n",
      "Step(10460) loss: 3.9458 -- time: 4.5413 sec.\n",
      "Step(10470) loss: 9.9300 -- time: 4.3718 sec.\n",
      "Step(10480) loss: 7.9388 -- time: 4.3538 sec.\n",
      "Step(10490) loss: 4.0763 -- time: 4.3727 sec.\n",
      "Step(10500) loss: 5.3796 -- time: 4.2909 sec.\n",
      "Step(10510) loss: 8.5038 -- time: 4.2834 sec.\n",
      "Step(10520) loss: 7.7772 -- time: 4.3900 sec.\n",
      "Step(10530) loss: 8.5852 -- time: 4.5257 sec.\n",
      "Step(10540) loss: 6.1945 -- time: 4.3560 sec.\n",
      "Step(10550) loss: 10.7226 -- time: 4.4583 sec.\n",
      "Step(10560) loss: 7.9054 -- time: 4.3790 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1365.1285 - val_loss: 0.0000\n",
      "time: 79.7340 sec.\n",
      "time_left: 54.4849 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 60/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10570) loss: 3.2852 -- time: 3.9043 sec.\n",
      "Step(10580) loss: 8.5204 -- time: 4.4054 sec.\n",
      "Step(10590) loss: 10.2500 -- time: 4.4012 sec.\n",
      "Step(10600) loss: 7.9468 -- time: 4.3041 sec.\n",
      "Step(10610) loss: 7.1353 -- time: 4.1920 sec.\n",
      "Step(10620) loss: 5.5898 -- time: 4.3075 sec.\n",
      "Step(10630) loss: 7.3786 -- time: 4.3768 sec.\n",
      "Step(10640) loss: 8.2622 -- time: 4.3586 sec.\n",
      "Step(10650) loss: 8.2404 -- time: 4.3953 sec.\n",
      "Step(10660) loss: 8.7208 -- time: 4.4501 sec.\n",
      "Step(10670) loss: 8.2143 -- time: 4.2475 sec.\n",
      "Step(10680) loss: 5.8723 -- time: 4.2520 sec.\n",
      "Step(10690) loss: 8.2593 -- time: 4.1686 sec.\n",
      "Step(10700) loss: 19.0279 -- time: 4.5073 sec.\n",
      "Step(10710) loss: 7.8307 -- time: 4.3124 sec.\n",
      "Step(10720) loss: 8.5662 -- time: 4.3674 sec.\n",
      "Step(10730) loss: 8.0231 -- time: 4.4289 sec.\n",
      "Step(10740) loss: 5.9091 -- time: 4.1618 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1361.7632 - val_loss: 1351.4719\n",
      "time: 112.8336 sec.\n",
      "time_left: 75.2224 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 61/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10750) loss: 7.5165 -- time: 4.3826 sec.\n",
      "Step(10760) loss: 8.6062 -- time: 4.4263 sec.\n",
      "Step(10770) loss: 7.8891 -- time: 4.2413 sec.\n",
      "Step(10780) loss: 6.1193 -- time: 4.4750 sec.\n",
      "Step(10790) loss: 7.6645 -- time: 4.4171 sec.\n",
      "Step(10800) loss: 7.1803 -- time: 4.2896 sec.\n",
      "Step(10810) loss: 5.9500 -- time: 4.4594 sec.\n",
      "Step(10820) loss: 7.5935 -- time: 4.4186 sec.\n",
      "Step(10830) loss: 9.9699 -- time: 4.3713 sec.\n",
      "Step(10840) loss: 7.0424 -- time: 4.3917 sec.\n",
      "Step(10850) loss: 7.6123 -- time: 4.4271 sec.\n",
      "Step(10860) loss: 8.2259 -- time: 4.3822 sec.\n",
      "Step(10870) loss: 3.9909 -- time: 4.2538 sec.\n",
      "Step(10880) loss: 8.8931 -- time: 4.3680 sec.\n",
      "Step(10890) loss: 6.6009 -- time: 4.3694 sec.\n",
      "Step(10900) loss: 8.6816 -- time: 4.4288 sec.\n",
      "Step(10910) loss: 6.5277 -- time: 4.3359 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1333.8117 - val_loss: 0.0000\n",
      "time: 80.1751 sec.\n",
      "time_left: 52.1138 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 62/100\n",
      "----------------------------------------------------------------------\n",
      "Step(10920) loss: 7.6356 -- time: 0.3555 sec.\n",
      "Step(10930) loss: 6.2396 -- time: 4.4321 sec.\n",
      "Step(10940) loss: 7.6246 -- time: 4.2151 sec.\n",
      "Step(10950) loss: 6.4416 -- time: 4.2291 sec.\n",
      "Step(10960) loss: 10.1934 -- time: 4.4698 sec.\n",
      "Step(10970) loss: 7.1412 -- time: 4.3667 sec.\n",
      "Step(10980) loss: 5.5659 -- time: 4.3799 sec.\n",
      "Step(10990) loss: 7.3783 -- time: 4.3456 sec.\n",
      "Step(11000) loss: 7.1447 -- time: 4.4359 sec.\n",
      "Step(11010) loss: 6.1133 -- time: 4.3982 sec.\n",
      "Step(11020) loss: 6.8133 -- time: 4.4052 sec.\n",
      "Step(11030) loss: 8.5777 -- time: 4.3492 sec.\n",
      "Step(11040) loss: 7.6911 -- time: 4.4401 sec.\n",
      "Step(11050) loss: 8.3614 -- time: 4.3256 sec.\n",
      "Step(11060) loss: 9.0345 -- time: 4.5254 sec.\n",
      "Step(11070) loss: 7.0914 -- time: 4.3491 sec.\n",
      "Step(11080) loss: 7.3335 -- time: 4.5080 sec.\n",
      "Step(11090) loss: 8.0584 -- time: 4.4246 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1370.5464 - val_loss: 0.0000\n",
      "time: 80.3297 sec.\n",
      "time_left: 50.8755 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 63/100\n",
      "----------------------------------------------------------------------\n",
      "Step(11100) loss: 8.8503 -- time: 0.8803 sec.\n",
      "Step(11110) loss: 9.1855 -- time: 4.5599 sec.\n",
      "Step(11120) loss: 7.8135 -- time: 4.5279 sec.\n",
      "Step(11130) loss: 8.7279 -- time: 4.4538 sec.\n",
      "Step(11140) loss: 7.0232 -- time: 4.4872 sec.\n",
      "Step(11150) loss: 6.7776 -- time: 4.5592 sec.\n",
      "Step(11160) loss: 6.7050 -- time: 4.4493 sec.\n",
      "Step(11170) loss: 5.9817 -- time: 4.5519 sec.\n",
      "Step(11180) loss: 8.1166 -- time: 4.2991 sec.\n",
      "Step(11190) loss: 7.3180 -- time: 4.4054 sec.\n",
      "Step(11200) loss: 8.5072 -- time: 4.5688 sec.\n",
      "Step(11210) loss: 7.0718 -- time: 4.3623 sec.\n",
      "Step(11220) loss: 9.4249 -- time: 4.5355 sec.\n",
      "Step(11230) loss: 7.2477 -- time: 4.4467 sec.\n",
      "Step(11240) loss: 8.0714 -- time: 4.5431 sec.\n",
      "Step(11250) loss: 6.2127 -- time: 4.4116 sec.\n",
      "Step(11260) loss: 6.1802 -- time: 4.3537 sec.\n",
      "Step(11270) loss: 4.2771 -- time: 4.4619 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1372.8056 - val_loss: 0.0000\n",
      "time: 81.7776 sec.\n",
      "time_left: 50.4295 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 64/100\n",
      "----------------------------------------------------------------------\n",
      "Step(11280) loss: 6.7467 -- time: 1.2591 sec.\n",
      "Step(11290) loss: 7.6731 -- time: 4.4376 sec.\n",
      "Step(11300) loss: 6.0346 -- time: 4.4206 sec.\n",
      "Step(11310) loss: 7.0321 -- time: 4.3622 sec.\n",
      "Step(11320) loss: 8.4534 -- time: 4.3359 sec.\n",
      "Step(11330) loss: 4.5627 -- time: 4.4356 sec.\n",
      "Step(11340) loss: 6.2119 -- time: 4.4196 sec.\n",
      "Step(11350) loss: 8.1858 -- time: 4.4701 sec.\n",
      "Step(11360) loss: 7.6584 -- time: 4.4290 sec.\n",
      "Step(11370) loss: 10.2240 -- time: 4.4981 sec.\n",
      "Step(11380) loss: 8.7326 -- time: 4.5061 sec.\n",
      "Step(11390) loss: 9.2152 -- time: 4.4637 sec.\n",
      "Step(11400) loss: 7.5918 -- time: 4.3911 sec.\n",
      "Step(11410) loss: 7.3942 -- time: 4.4956 sec.\n",
      "Step(11420) loss: 4.1344 -- time: 4.5706 sec.\n",
      "Step(11430) loss: 7.9368 -- time: 4.4902 sec.\n",
      "Step(11440) loss: 7.1666 -- time: 4.3000 sec.\n",
      "Step(11450) loss: 9.5219 -- time: 4.3957 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1323.6628 - val_loss: 0.0000\n",
      "time: 81.1587 sec.\n",
      "time_left: 48.6952 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 65/100\n",
      "----------------------------------------------------------------------\n",
      "Step(11460) loss: 6.0506 -- time: 1.7593 sec.\n",
      "Step(11470) loss: 7.2548 -- time: 4.4209 sec.\n",
      "Step(11480) loss: 7.9341 -- time: 4.3971 sec.\n",
      "Step(11490) loss: 8.7853 -- time: 4.3631 sec.\n",
      "Step(11500) loss: 6.9593 -- time: 4.5687 sec.\n",
      "Step(11510) loss: 7.7706 -- time: 4.3962 sec.\n",
      "Step(11520) loss: 5.8986 -- time: 4.3792 sec.\n",
      "Step(11530) loss: 8.8494 -- time: 4.5483 sec.\n",
      "Step(11540) loss: 5.8064 -- time: 4.6293 sec.\n",
      "Step(11550) loss: 8.6802 -- time: 4.3885 sec.\n",
      "Step(11560) loss: 4.1296 -- time: 4.6237 sec.\n",
      "Step(11570) loss: 4.5039 -- time: 4.3928 sec.\n",
      "Step(11580) loss: 5.9861 -- time: 4.4391 sec.\n",
      "Step(11590) loss: 5.2928 -- time: 4.3062 sec.\n",
      "Step(11600) loss: 8.8033 -- time: 4.3739 sec.\n",
      "Step(11610) loss: 6.3771 -- time: 4.4139 sec.\n",
      "Step(11620) loss: 8.6549 -- time: 4.5383 sec.\n",
      "Step(11630) loss: 6.9795 -- time: 4.4294 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1354.6893 - val_loss: 0.0000\n",
      "time: 81.4448 sec.\n",
      "time_left: 47.5094 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 66/100\n",
      "----------------------------------------------------------------------\n",
      "Step(11640) loss: 5.6733 -- time: 2.2524 sec.\n",
      "Step(11650) loss: 9.0733 -- time: 4.4779 sec.\n",
      "Step(11660) loss: 6.5104 -- time: 4.4758 sec.\n",
      "Step(11670) loss: 5.5459 -- time: 4.3682 sec.\n",
      "Step(11680) loss: 7.7851 -- time: 4.3503 sec.\n",
      "Step(11690) loss: 5.1856 -- time: 4.4672 sec.\n",
      "Step(11700) loss: 7.6041 -- time: 4.3532 sec.\n",
      "Step(11710) loss: 6.5318 -- time: 4.3557 sec.\n",
      "Step(11720) loss: 6.6681 -- time: 4.5404 sec.\n",
      "Step(11730) loss: 8.1974 -- time: 4.3923 sec.\n",
      "Step(11740) loss: 7.2799 -- time: 4.3689 sec.\n",
      "Step(11750) loss: 9.6195 -- time: 4.3075 sec.\n",
      "Step(11760) loss: 8.1808 -- time: 4.3605 sec.\n",
      "Step(11770) loss: 7.4446 -- time: 4.5071 sec.\n",
      "Step(11780) loss: 4.0600 -- time: 4.4191 sec.\n",
      "Step(11790) loss: 7.2738 -- time: 4.5532 sec.\n",
      "Step(11800) loss: 8.5482 -- time: 4.6005 sec.\n",
      "Step(11810) loss: 8.2762 -- time: 4.4564 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1324.4912 - val_loss: 0.0000\n",
      "time: 81.2526 sec.\n",
      "time_left: 46.0432 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 67/100\n",
      "----------------------------------------------------------------------\n",
      "Step(11820) loss: 7.3056 -- time: 2.7410 sec.\n",
      "Step(11830) loss: 8.0985 -- time: 4.4498 sec.\n",
      "Step(11840) loss: 8.6301 -- time: 4.4211 sec.\n",
      "Step(11850) loss: 4.3549 -- time: 4.5463 sec.\n",
      "Step(11860) loss: 5.0626 -- time: 4.4221 sec.\n",
      "Step(11870) loss: 7.7393 -- time: 4.3561 sec.\n",
      "Step(11880) loss: 8.3418 -- time: 4.4365 sec.\n",
      "Step(11890) loss: 8.1939 -- time: 4.4775 sec.\n",
      "Step(11900) loss: 5.9149 -- time: 4.3727 sec.\n",
      "Step(11910) loss: 6.1929 -- time: 4.3097 sec.\n",
      "Step(11920) loss: 11.5515 -- time: 4.4781 sec.\n",
      "Step(11930) loss: 5.4003 -- time: 4.4141 sec.\n",
      "Step(11940) loss: 6.2903 -- time: 4.2852 sec.\n",
      "Step(11950) loss: 5.6425 -- time: 4.3650 sec.\n",
      "Step(11960) loss: 4.7853 -- time: 4.3951 sec.\n",
      "Step(11970) loss: 9.3133 -- time: 4.4291 sec.\n",
      "Step(11980) loss: 3.7151 -- time: 4.4006 sec.\n",
      "Step(11990) loss: 6.6898 -- time: 4.2775 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1280.0422 - val_loss: 0.0000\n",
      "time: 80.7318 sec.\n",
      "time_left: 44.4025 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 68/100\n",
      "----------------------------------------------------------------------\n",
      "Step(12000) loss: 8.4569 -- time: 2.9528 sec.\n",
      "Step(12010) loss: 5.2013 -- time: 4.2960 sec.\n",
      "Step(12020) loss: 7.0773 -- time: 4.3070 sec.\n",
      "Step(12030) loss: 6.8212 -- time: 4.4268 sec.\n",
      "Step(12040) loss: 9.8563 -- time: 4.3005 sec.\n",
      "Step(12050) loss: 4.7566 -- time: 4.3535 sec.\n",
      "Step(12060) loss: 8.4654 -- time: 4.5272 sec.\n",
      "Step(12070) loss: 6.7512 -- time: 4.3273 sec.\n",
      "Step(12080) loss: 11.0686 -- time: 4.4314 sec.\n",
      "Step(12090) loss: 3.9448 -- time: 4.3442 sec.\n",
      "Step(12100) loss: 8.8049 -- time: 4.5075 sec.\n",
      "Step(12110) loss: 7.6056 -- time: 4.2260 sec.\n",
      "Step(12120) loss: 9.2792 -- time: 4.3270 sec.\n",
      "Step(12130) loss: 6.3387 -- time: 4.4360 sec.\n",
      "Step(12140) loss: 7.2567 -- time: 4.5039 sec.\n",
      "Step(12150) loss: 7.1857 -- time: 4.3500 sec.\n",
      "Step(12160) loss: 7.8639 -- time: 4.3154 sec.\n",
      "Step(12170) loss: 8.2526 -- time: 4.4054 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1372.8227 - val_loss: 0.0000\n",
      "time: 80.0047 sec.\n",
      "time_left: 42.6692 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 69/100\n",
      "----------------------------------------------------------------------\n",
      "Step(12180) loss: 8.7750 -- time: 3.5636 sec.\n",
      "Step(12190) loss: 8.4771 -- time: 4.3026 sec.\n",
      "Step(12200) loss: 11.0730 -- time: 4.5522 sec.\n",
      "Step(12210) loss: 7.7873 -- time: 4.3342 sec.\n",
      "Step(12220) loss: 8.0530 -- time: 4.3416 sec.\n",
      "Step(12230) loss: 6.8814 -- time: 4.4291 sec.\n",
      "Step(12240) loss: 5.0881 -- time: 4.4122 sec.\n",
      "Step(12250) loss: 6.5209 -- time: 4.3155 sec.\n",
      "Step(12260) loss: 6.5487 -- time: 4.4187 sec.\n",
      "Step(12270) loss: 6.7361 -- time: 4.3529 sec.\n",
      "Step(12280) loss: 7.8042 -- time: 4.3048 sec.\n",
      "Step(12290) loss: 7.0915 -- time: 4.3443 sec.\n",
      "Step(12300) loss: 5.8847 -- time: 4.4721 sec.\n",
      "Step(12310) loss: 5.5781 -- time: 4.2672 sec.\n",
      "Step(12320) loss: 6.2716 -- time: 4.2430 sec.\n",
      "Step(12330) loss: 15.8545 -- time: 4.2967 sec.\n",
      "Step(12340) loss: 15.6329 -- time: 4.3543 sec.\n",
      "Step(12350) loss: 7.8708 -- time: 4.3588 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1320.5894 - val_loss: 0.0000\n",
      "time: 79.8911 sec.\n",
      "time_left: 41.2771 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 70/100\n",
      "----------------------------------------------------------------------\n",
      "Step(12360) loss: 7.4497 -- time: 3.8474 sec.\n",
      "Step(12370) loss: 8.0362 -- time: 4.2469 sec.\n",
      "Step(12380) loss: 7.7847 -- time: 4.3470 sec.\n",
      "Step(12390) loss: 11.4627 -- time: 4.2638 sec.\n",
      "Step(12400) loss: 7.8443 -- time: 4.5731 sec.\n",
      "Step(12410) loss: 6.9345 -- time: 4.3825 sec.\n",
      "Step(12420) loss: 8.8705 -- time: 4.2615 sec.\n",
      "Step(12430) loss: 6.4521 -- time: 4.4075 sec.\n",
      "Step(12440) loss: 9.4977 -- time: 4.3325 sec.\n",
      "Step(12450) loss: 7.7957 -- time: 4.4118 sec.\n",
      "Step(12460) loss: 7.0995 -- time: 4.2368 sec.\n",
      "Step(12470) loss: 8.0170 -- time: 4.4112 sec.\n",
      "Step(12480) loss: 5.5470 -- time: 4.2449 sec.\n",
      "Step(12490) loss: 8.3629 -- time: 4.4045 sec.\n",
      "Step(12500) loss: 5.7997 -- time: 4.2661 sec.\n",
      "Step(12510) loss: 5.8453 -- time: 4.2264 sec.\n",
      "Step(12520) loss: 6.4831 -- time: 4.2517 sec.\n",
      "Step(12530) loss: 9.5047 -- time: 4.1591 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1375.1588 - val_loss: 1337.9267\n",
      "time: 112.3991 sec.\n",
      "time_left: 56.1995 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 71/100\n",
      "----------------------------------------------------------------------\n",
      "Step(12540) loss: 7.5735 -- time: 4.4982 sec.\n",
      "Step(12550) loss: 4.1967 -- time: 4.4217 sec.\n",
      "Step(12560) loss: 8.1997 -- time: 4.5037 sec.\n",
      "Step(12570) loss: 5.5415 -- time: 4.4999 sec.\n",
      "Step(12580) loss: 5.5874 -- time: 4.5017 sec.\n",
      "Step(12590) loss: 6.9928 -- time: 4.4890 sec.\n",
      "Step(12600) loss: 7.2521 -- time: 4.6252 sec.\n",
      "Step(12610) loss: 8.7126 -- time: 4.4436 sec.\n",
      "Step(12620) loss: 7.1583 -- time: 4.4100 sec.\n",
      "Step(12630) loss: 8.3008 -- time: 4.4366 sec.\n",
      "Step(12640) loss: 8.5160 -- time: 4.4523 sec.\n",
      "Step(12650) loss: 8.0488 -- time: 4.5404 sec.\n",
      "Step(12660) loss: 7.2833 -- time: 4.5686 sec.\n",
      "Step(12670) loss: 8.1557 -- time: 4.5849 sec.\n",
      "Step(12680) loss: 8.5518 -- time: 4.4840 sec.\n",
      "Step(12690) loss: 6.7557 -- time: 4.3520 sec.\n",
      "Step(12700) loss: 4.9572 -- time: 4.4065 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1293.4319 - val_loss: 0.0000\n",
      "time: 82.0215 sec.\n",
      "time_left: 39.6437 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 72/100\n",
      "----------------------------------------------------------------------\n",
      "Step(12710) loss: 8.4261 -- time: 0.3725 sec.\n",
      "Step(12720) loss: 7.0647 -- time: 4.5928 sec.\n",
      "Step(12730) loss: 7.6145 -- time: 4.5256 sec.\n",
      "Step(12740) loss: 7.3896 -- time: 4.5355 sec.\n",
      "Step(12750) loss: 3.9026 -- time: 4.6232 sec.\n",
      "Step(12760) loss: 8.6618 -- time: 4.4494 sec.\n",
      "Step(12770) loss: 6.9383 -- time: 4.4681 sec.\n",
      "Step(12780) loss: 7.2835 -- time: 4.4298 sec.\n",
      "Step(12790) loss: 7.8505 -- time: 4.4682 sec.\n",
      "Step(12800) loss: 8.9064 -- time: 4.6149 sec.\n",
      "Step(12810) loss: 7.8339 -- time: 4.6985 sec.\n",
      "Step(12820) loss: 7.6840 -- time: 4.5285 sec.\n",
      "Step(12830) loss: 5.4834 -- time: 4.4688 sec.\n",
      "Step(12840) loss: 7.3955 -- time: 4.4556 sec.\n",
      "Step(12850) loss: 7.0176 -- time: 4.5488 sec.\n",
      "Step(12860) loss: 6.0201 -- time: 4.4981 sec.\n",
      "Step(12870) loss: 8.1485 -- time: 4.4987 sec.\n",
      "Step(12880) loss: 6.7712 -- time: 4.5164 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1308.7856 - val_loss: 0.0000\n",
      "time: 82.7324 sec.\n",
      "time_left: 38.6084 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 73/100\n",
      "----------------------------------------------------------------------\n",
      "Step(12890) loss: 5.0709 -- time: 0.7769 sec.\n",
      "Step(12900) loss: 8.5075 -- time: 4.5722 sec.\n",
      "Step(12910) loss: 7.2810 -- time: 4.4834 sec.\n",
      "Step(12920) loss: 8.2105 -- time: 4.5848 sec.\n",
      "Step(12930) loss: 8.5835 -- time: 4.3644 sec.\n",
      "Step(12940) loss: 7.2241 -- time: 4.3596 sec.\n",
      "Step(12950) loss: 8.7093 -- time: 4.4496 sec.\n",
      "Step(12960) loss: 6.8923 -- time: 4.4355 sec.\n",
      "Step(12970) loss: 5.8475 -- time: 4.3068 sec.\n",
      "Step(12980) loss: 3.7679 -- time: 4.3195 sec.\n",
      "Step(12990) loss: 5.4638 -- time: 4.2364 sec.\n",
      "Step(13000) loss: 8.6420 -- time: 4.5802 sec.\n",
      "Step(13010) loss: 7.7360 -- time: 4.2766 sec.\n",
      "Step(13020) loss: 6.7113 -- time: 4.4042 sec.\n",
      "Step(13030) loss: 7.3130 -- time: 4.2947 sec.\n",
      "Step(13040) loss: 8.7059 -- time: 4.3386 sec.\n",
      "Step(13050) loss: 8.5041 -- time: 4.4704 sec.\n",
      "Step(13060) loss: 7.5139 -- time: 4.3322 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1289.2713 - val_loss: 0.0000\n",
      "time: 80.5535 sec.\n",
      "time_left: 36.2491 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 74/100\n",
      "----------------------------------------------------------------------\n",
      "Step(13070) loss: 6.5306 -- time: 1.3172 sec.\n",
      "Step(13080) loss: 6.4710 -- time: 4.4478 sec.\n",
      "Step(13090) loss: 7.3642 -- time: 4.3827 sec.\n",
      "Step(13100) loss: 4.5934 -- time: 4.1764 sec.\n",
      "Step(13110) loss: 7.1379 -- time: 4.2175 sec.\n",
      "Step(13120) loss: 6.8306 -- time: 4.4934 sec.\n",
      "Step(13130) loss: 8.7489 -- time: 4.2890 sec.\n",
      "Step(13140) loss: 7.2475 -- time: 4.4924 sec.\n",
      "Step(13150) loss: 8.7243 -- time: 4.4195 sec.\n",
      "Step(13160) loss: 6.6031 -- time: 4.3082 sec.\n",
      "Step(13170) loss: 5.3172 -- time: 4.4443 sec.\n",
      "Step(13180) loss: 6.5293 -- time: 4.3503 sec.\n",
      "Step(13190) loss: 6.6705 -- time: 4.4245 sec.\n",
      "Step(13200) loss: 5.9365 -- time: 4.3646 sec.\n",
      "Step(13210) loss: 3.8259 -- time: 4.3522 sec.\n",
      "Step(13220) loss: 7.6600 -- time: 4.1958 sec.\n",
      "Step(13230) loss: 7.5586 -- time: 4.3024 sec.\n",
      "Step(13240) loss: 7.9823 -- time: 4.3918 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1319.7951 - val_loss: 0.0000\n",
      "time: 79.7906 sec.\n",
      "time_left: 34.5759 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 75/100\n",
      "----------------------------------------------------------------------\n",
      "Step(13250) loss: 7.6714 -- time: 1.7040 sec.\n",
      "Step(13260) loss: 7.2963 -- time: 4.3680 sec.\n",
      "Step(13270) loss: 5.0611 -- time: 4.3210 sec.\n",
      "Step(13280) loss: 8.8345 -- time: 4.3658 sec.\n",
      "Step(13290) loss: 6.2236 -- time: 4.3800 sec.\n",
      "Step(13300) loss: 6.1021 -- time: 4.3066 sec.\n",
      "Step(13310) loss: 6.5788 -- time: 4.4164 sec.\n",
      "Step(13320) loss: 10.8178 -- time: 4.4361 sec.\n",
      "Step(13330) loss: 5.8393 -- time: 4.3422 sec.\n",
      "Step(13340) loss: 5.3861 -- time: 4.1706 sec.\n",
      "Step(13350) loss: 4.0479 -- time: 4.4136 sec.\n",
      "Step(13360) loss: 5.8763 -- time: 4.2571 sec.\n",
      "Step(13370) loss: 6.9963 -- time: 4.3750 sec.\n",
      "Step(13380) loss: 4.3279 -- time: 4.3159 sec.\n",
      "Step(13390) loss: 7.9279 -- time: 4.3195 sec.\n",
      "Step(13400) loss: 8.1519 -- time: 4.3044 sec.\n",
      "Step(13410) loss: 9.5019 -- time: 4.3267 sec.\n",
      "Step(13420) loss: 7.8904 -- time: 4.4317 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1331.2690 - val_loss: 0.0000\n",
      "time: 79.5859 sec.\n",
      "time_left: 33.1608 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 76/100\n",
      "----------------------------------------------------------------------\n",
      "Step(13430) loss: 7.7242 -- time: 2.0433 sec.\n",
      "Step(13440) loss: 6.4282 -- time: 4.3767 sec.\n",
      "Step(13450) loss: 4.9716 -- time: 4.4262 sec.\n",
      "Step(13460) loss: 7.1362 -- time: 4.2804 sec.\n",
      "Step(13470) loss: 3.8856 -- time: 4.4084 sec.\n",
      "Step(13480) loss: 8.1231 -- time: 4.1903 sec.\n",
      "Step(13490) loss: 16.4469 -- time: 4.4447 sec.\n",
      "Step(13500) loss: 3.8888 -- time: 4.3765 sec.\n",
      "Step(13510) loss: 7.8178 -- time: 4.2724 sec.\n",
      "Step(13520) loss: 4.6198 -- time: 4.3447 sec.\n",
      "Step(13530) loss: 7.2321 -- time: 4.3117 sec.\n",
      "Step(13540) loss: 6.2639 -- time: 4.2624 sec.\n",
      "Step(13550) loss: 4.2032 -- time: 4.3475 sec.\n",
      "Step(13560) loss: 5.4701 -- time: 4.3830 sec.\n",
      "Step(13570) loss: 6.3891 -- time: 4.5529 sec.\n",
      "Step(13580) loss: 8.4871 -- time: 4.4155 sec.\n",
      "Step(13590) loss: 7.1238 -- time: 4.3465 sec.\n",
      "Step(13600) loss: 8.9169 -- time: 4.2704 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1333.4780 - val_loss: 0.0000\n",
      "time: 79.5971 sec.\n",
      "time_left: 31.8389 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 77/100\n",
      "----------------------------------------------------------------------\n",
      "Step(13610) loss: 7.7377 -- time: 2.6323 sec.\n",
      "Step(13620) loss: 8.4023 -- time: 4.4678 sec.\n",
      "Step(13630) loss: 7.7440 -- time: 4.5271 sec.\n",
      "Step(13640) loss: 9.5930 -- time: 4.4753 sec.\n",
      "Step(13650) loss: 8.0079 -- time: 4.2055 sec.\n",
      "Step(13660) loss: 5.3100 -- time: 4.3226 sec.\n",
      "Step(13670) loss: 4.2139 -- time: 4.3614 sec.\n",
      "Step(13680) loss: 9.7456 -- time: 4.3612 sec.\n",
      "Step(13690) loss: 9.7950 -- time: 4.4110 sec.\n",
      "Step(13700) loss: 7.7887 -- time: 4.4065 sec.\n",
      "Step(13710) loss: 8.3773 -- time: 4.2234 sec.\n",
      "Step(13720) loss: 7.1233 -- time: 4.2540 sec.\n",
      "Step(13730) loss: 5.1279 -- time: 4.2616 sec.\n",
      "Step(13740) loss: 6.8871 -- time: 4.2897 sec.\n",
      "Step(13750) loss: 8.2271 -- time: 4.3542 sec.\n",
      "Step(13760) loss: 8.8782 -- time: 4.4297 sec.\n",
      "Step(13770) loss: 7.5731 -- time: 4.3242 sec.\n",
      "Step(13780) loss: 10.5270 -- time: 4.4933 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1334.7209 - val_loss: 0.0000\n",
      "time: 79.9474 sec.\n",
      "time_left: 30.6465 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 78/100\n",
      "----------------------------------------------------------------------\n",
      "Step(13790) loss: 7.8960 -- time: 2.9565 sec.\n",
      "Step(13800) loss: 9.6929 -- time: 4.2683 sec.\n",
      "Step(13810) loss: 6.8977 -- time: 4.4119 sec.\n",
      "Step(13820) loss: 7.2397 -- time: 4.2058 sec.\n",
      "Step(13830) loss: 10.0682 -- time: 4.3794 sec.\n",
      "Step(13840) loss: 7.5850 -- time: 4.3514 sec.\n",
      "Step(13850) loss: 7.7436 -- time: 4.3907 sec.\n",
      "Step(13860) loss: 7.3597 -- time: 4.3224 sec.\n",
      "Step(13870) loss: 7.5403 -- time: 4.2966 sec.\n",
      "Step(13880) loss: 18.3644 -- time: 4.4632 sec.\n",
      "Step(13890) loss: 8.3498 -- time: 4.4000 sec.\n",
      "Step(13900) loss: 7.0857 -- time: 4.3296 sec.\n",
      "Step(13910) loss: 5.5573 -- time: 4.3798 sec.\n",
      "Step(13920) loss: 6.8847 -- time: 4.4422 sec.\n",
      "Step(13930) loss: 8.0754 -- time: 4.2732 sec.\n",
      "Step(13940) loss: 6.2916 -- time: 4.3705 sec.\n",
      "Step(13950) loss: 6.5630 -- time: 4.3133 sec.\n",
      "Step(13960) loss: 8.5928 -- time: 4.4352 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1361.8322 - val_loss: 0.0000\n",
      "time: 79.6814 sec.\n",
      "time_left: 29.2165 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 79/100\n",
      "----------------------------------------------------------------------\n",
      "Step(13970) loss: 9.3894 -- time: 3.4681 sec.\n",
      "Step(13980) loss: 6.4089 -- time: 4.2132 sec.\n",
      "Step(13990) loss: 9.7347 -- time: 4.1940 sec.\n",
      "Step(14000) loss: 8.7603 -- time: 4.3412 sec.\n",
      "Step(14010) loss: 8.6585 -- time: 4.3057 sec.\n",
      "Step(14020) loss: 6.8736 -- time: 4.4784 sec.\n",
      "Step(14030) loss: 8.3608 -- time: 4.3271 sec.\n",
      "Step(14040) loss: 6.7594 -- time: 4.2948 sec.\n",
      "Step(14050) loss: 6.2473 -- time: 4.5782 sec.\n",
      "Step(14060) loss: 8.7084 -- time: 4.4491 sec.\n",
      "Step(14070) loss: 7.0989 -- time: 4.3806 sec.\n",
      "Step(14080) loss: 4.8414 -- time: 4.3130 sec.\n",
      "Step(14090) loss: 8.7869 -- time: 4.3676 sec.\n",
      "Step(14100) loss: 7.9155 -- time: 4.4722 sec.\n",
      "Step(14110) loss: 8.0363 -- time: 4.3724 sec.\n",
      "Step(14120) loss: 8.1869 -- time: 4.4148 sec.\n",
      "Step(14130) loss: 8.5810 -- time: 4.3405 sec.\n",
      "Step(14140) loss: 9.1168 -- time: 4.1769 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1349.6982 - val_loss: 0.0000\n",
      "time: 79.6779 sec.\n",
      "time_left: 27.8873 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 80/100\n",
      "----------------------------------------------------------------------\n",
      "Step(14150) loss: 7.5822 -- time: 3.9493 sec.\n",
      "Step(14160) loss: 8.3554 -- time: 4.4046 sec.\n",
      "Step(14170) loss: 6.3372 -- time: 4.3063 sec.\n",
      "Step(14180) loss: 3.6778 -- time: 4.3651 sec.\n",
      "Step(14190) loss: 6.2722 -- time: 4.3335 sec.\n",
      "Step(14200) loss: 7.4447 -- time: 4.4817 sec.\n",
      "Step(14210) loss: 8.2636 -- time: 4.2775 sec.\n",
      "Step(14220) loss: 4.2992 -- time: 4.2268 sec.\n",
      "Step(14230) loss: 6.8744 -- time: 4.4124 sec.\n",
      "Step(14240) loss: 6.4399 -- time: 4.3730 sec.\n",
      "Step(14250) loss: 8.9851 -- time: 4.4655 sec.\n",
      "Step(14260) loss: 8.5383 -- time: 4.2455 sec.\n",
      "Step(14270) loss: 6.9145 -- time: 4.2986 sec.\n",
      "Step(14280) loss: 6.2854 -- time: 4.2609 sec.\n",
      "Step(14290) loss: 6.5387 -- time: 4.2618 sec.\n",
      "Step(14300) loss: 8.3569 -- time: 4.3877 sec.\n",
      "Step(14310) loss: 3.8741 -- time: 4.3678 sec.\n",
      "Step(14320) loss: 9.5179 -- time: 4.2924 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1245.7034 - val_loss: 1321.9591\n",
      "time: 112.7293 sec.\n",
      "time_left: 37.5764 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 81/100\n",
      "----------------------------------------------------------------------\n",
      "Step(14330) loss: 20.7972 -- time: 4.1955 sec.\n",
      "Step(14340) loss: 6.8551 -- time: 4.4178 sec.\n",
      "Step(14350) loss: 7.3750 -- time: 4.2419 sec.\n",
      "Step(14360) loss: 8.8844 -- time: 4.3616 sec.\n",
      "Step(14370) loss: 8.6775 -- time: 4.3886 sec.\n",
      "Step(14380) loss: 8.2772 -- time: 4.2078 sec.\n",
      "Step(14390) loss: 8.6094 -- time: 4.3471 sec.\n",
      "Step(14400) loss: 7.8034 -- time: 4.4667 sec.\n",
      "Step(14410) loss: 5.4549 -- time: 4.1766 sec.\n",
      "Step(14420) loss: 7.1119 -- time: 4.4023 sec.\n",
      "Step(14430) loss: 4.2617 -- time: 4.5012 sec.\n",
      "Step(14440) loss: 6.3536 -- time: 4.5245 sec.\n",
      "Step(14450) loss: 11.5701 -- time: 4.4386 sec.\n",
      "Step(14460) loss: 6.7154 -- time: 4.3198 sec.\n",
      "Step(14470) loss: 7.4366 -- time: 4.4206 sec.\n",
      "Step(14480) loss: 5.9880 -- time: 4.4004 sec.\n",
      "Step(14490) loss: 6.9646 -- time: 4.5603 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1368.9036 - val_loss: 0.0000\n",
      "time: 80.1199 sec.\n",
      "time_left: 25.3713 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 82/100\n",
      "----------------------------------------------------------------------\n",
      "Step(14500) loss: 8.2730 -- time: 0.3382 sec.\n",
      "Step(14510) loss: 8.2785 -- time: 4.4895 sec.\n",
      "Step(14520) loss: 6.9545 -- time: 4.4663 sec.\n",
      "Step(14530) loss: 8.2406 -- time: 4.4363 sec.\n",
      "Step(14540) loss: 4.7279 -- time: 4.1256 sec.\n",
      "Step(14550) loss: 7.7919 -- time: 4.2333 sec.\n",
      "Step(14560) loss: 7.6416 -- time: 4.2054 sec.\n",
      "Step(14570) loss: 6.7228 -- time: 4.3244 sec.\n",
      "Step(14580) loss: 5.2277 -- time: 4.2581 sec.\n",
      "Step(14590) loss: 7.8494 -- time: 4.1998 sec.\n",
      "Step(14600) loss: 5.9680 -- time: 4.1694 sec.\n",
      "Step(14610) loss: 7.8493 -- time: 4.1934 sec.\n",
      "Step(14620) loss: 8.0525 -- time: 4.2108 sec.\n",
      "Step(14630) loss: 7.3771 -- time: 4.3445 sec.\n",
      "Step(14640) loss: 8.1248 -- time: 4.1618 sec.\n",
      "Step(14650) loss: 6.3844 -- time: 4.1639 sec.\n",
      "Step(14660) loss: 7.9412 -- time: 4.2106 sec.\n",
      "Step(14670) loss: 5.4616 -- time: 4.2852 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1326.7432 - val_loss: 0.0000\n",
      "time: 77.8635 sec.\n",
      "time_left: 23.3591 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 83/100\n",
      "----------------------------------------------------------------------\n",
      "Step(14680) loss: 7.7979 -- time: 0.8034 sec.\n",
      "Step(14690) loss: 7.0662 -- time: 4.2072 sec.\n",
      "Step(14700) loss: 6.8624 -- time: 4.2315 sec.\n",
      "Step(14710) loss: 5.4085 -- time: 4.1953 sec.\n",
      "Step(14720) loss: 7.5214 -- time: 4.2371 sec.\n",
      "Step(14730) loss: 7.1463 -- time: 4.3542 sec.\n",
      "Step(14740) loss: 6.4068 -- time: 4.3791 sec.\n",
      "Step(14750) loss: 6.5133 -- time: 4.5031 sec.\n",
      "Step(14760) loss: 13.6127 -- time: 4.2452 sec.\n",
      "Step(14770) loss: 8.0079 -- time: 4.2708 sec.\n",
      "Step(14780) loss: 11.1524 -- time: 4.1212 sec.\n",
      "Step(14790) loss: 10.5882 -- time: 4.3051 sec.\n",
      "Step(14800) loss: 5.4760 -- time: 4.2291 sec.\n",
      "Step(14810) loss: 10.1654 -- time: 4.1592 sec.\n",
      "Step(14820) loss: 6.8012 -- time: 4.3477 sec.\n",
      "Step(14830) loss: 7.7956 -- time: 4.2489 sec.\n",
      "Step(14840) loss: 7.1987 -- time: 4.2490 sec.\n",
      "Step(14850) loss: 6.4871 -- time: 4.1481 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1388.1984 - val_loss: 0.0000\n",
      "time: 77.9791 sec.\n",
      "time_left: 22.0941 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 84/100\n",
      "----------------------------------------------------------------------\n",
      "Step(14860) loss: 7.3272 -- time: 1.2000 sec.\n",
      "Step(14870) loss: 7.0495 -- time: 4.2790 sec.\n",
      "Step(14880) loss: 8.2689 -- time: 4.1697 sec.\n",
      "Step(14890) loss: 7.0249 -- time: 4.2763 sec.\n",
      "Step(14900) loss: 6.7158 -- time: 4.1860 sec.\n",
      "Step(14910) loss: 8.5482 -- time: 4.1741 sec.\n",
      "Step(14920) loss: 7.4473 -- time: 4.2199 sec.\n",
      "Step(14930) loss: 10.1706 -- time: 4.2378 sec.\n",
      "Step(14940) loss: 6.1304 -- time: 4.3110 sec.\n",
      "Step(14950) loss: 7.0354 -- time: 4.1868 sec.\n",
      "Step(14960) loss: 7.4202 -- time: 4.2169 sec.\n",
      "Step(14970) loss: 5.3761 -- time: 4.3513 sec.\n",
      "Step(14980) loss: 6.4070 -- time: 4.3209 sec.\n",
      "Step(14990) loss: 7.5783 -- time: 4.1790 sec.\n",
      "Step(15000) loss: 7.9567 -- time: 4.1935 sec.\n",
      "Step(15010) loss: 7.7027 -- time: 4.3173 sec.\n",
      "Step(15020) loss: 6.2938 -- time: 4.1971 sec.\n",
      "Step(15030) loss: 4.6469 -- time: 4.2224 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1335.4224 - val_loss: 0.0000\n",
      "time: 77.5315 sec.\n",
      "time_left: 20.6751 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 85/100\n",
      "----------------------------------------------------------------------\n",
      "Step(15040) loss: 7.4655 -- time: 1.6309 sec.\n",
      "Step(15050) loss: 7.8389 -- time: 4.2437 sec.\n",
      "Step(15060) loss: 5.6926 -- time: 4.2065 sec.\n",
      "Step(15070) loss: 6.2641 -- time: 4.3202 sec.\n",
      "Step(15080) loss: 7.2060 -- time: 4.2176 sec.\n",
      "Step(15090) loss: 8.0298 -- time: 4.4575 sec.\n",
      "Step(15100) loss: 7.0565 -- time: 4.2031 sec.\n",
      "Step(15110) loss: 7.5489 -- time: 4.3232 sec.\n",
      "Step(15120) loss: 7.5170 -- time: 4.2780 sec.\n",
      "Step(15130) loss: 4.5805 -- time: 4.0747 sec.\n",
      "Step(15140) loss: 7.7499 -- time: 4.1866 sec.\n",
      "Step(15150) loss: 7.6364 -- time: 4.1957 sec.\n",
      "Step(15160) loss: 5.4344 -- time: 4.1731 sec.\n",
      "Step(15170) loss: 8.7771 -- time: 4.2315 sec.\n",
      "Step(15180) loss: 8.6618 -- time: 4.3252 sec.\n",
      "Step(15190) loss: 8.1280 -- time: 4.1842 sec.\n",
      "Step(15200) loss: 5.0654 -- time: 4.2192 sec.\n",
      "Step(15210) loss: 8.6680 -- time: 4.0714 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1349.2487 - val_loss: 0.0000\n",
      "time: 77.3916 sec.\n",
      "time_left: 19.3479 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 86/100\n",
      "----------------------------------------------------------------------\n",
      "Step(15220) loss: 7.9637 -- time: 2.0522 sec.\n",
      "Step(15230) loss: 8.6853 -- time: 4.2663 sec.\n",
      "Step(15240) loss: 6.6998 -- time: 4.3163 sec.\n",
      "Step(15250) loss: 9.5109 -- time: 4.2313 sec.\n",
      "Step(15260) loss: 7.5688 -- time: 4.3620 sec.\n",
      "Step(15270) loss: 5.7956 -- time: 4.2328 sec.\n",
      "Step(15280) loss: 7.1559 -- time: 4.1578 sec.\n",
      "Step(15290) loss: 7.3370 -- time: 4.3120 sec.\n",
      "Step(15300) loss: 8.9838 -- time: 4.3640 sec.\n",
      "Step(15310) loss: 4.3438 -- time: 4.1616 sec.\n",
      "Step(15320) loss: 6.1818 -- time: 4.2115 sec.\n",
      "Step(15330) loss: 5.3400 -- time: 4.2061 sec.\n",
      "Step(15340) loss: 7.6402 -- time: 4.2411 sec.\n",
      "Step(15350) loss: 5.6057 -- time: 4.2482 sec.\n",
      "Step(15360) loss: 8.3193 -- time: 4.2494 sec.\n",
      "Step(15370) loss: 9.5356 -- time: 4.2648 sec.\n",
      "Step(15380) loss: 8.0969 -- time: 4.4831 sec.\n",
      "Step(15390) loss: 7.8509 -- time: 4.2765 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1392.5571 - val_loss: 0.0000\n",
      "time: 78.1227 sec.\n",
      "time_left: 18.2286 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 87/100\n",
      "----------------------------------------------------------------------\n",
      "Step(15400) loss: 7.7677 -- time: 2.5615 sec.\n",
      "Step(15410) loss: 8.2971 -- time: 4.3581 sec.\n",
      "Step(15420) loss: 5.4445 -- time: 4.0930 sec.\n",
      "Step(15430) loss: 7.9059 -- time: 4.2401 sec.\n",
      "Step(15440) loss: 7.0701 -- time: 4.3151 sec.\n",
      "Step(15450) loss: 7.5578 -- time: 4.0505 sec.\n",
      "Step(15460) loss: 7.3994 -- time: 4.2929 sec.\n",
      "Step(15470) loss: 7.4582 -- time: 4.3982 sec.\n",
      "Step(15480) loss: 8.4152 -- time: 4.2227 sec.\n",
      "Step(15490) loss: 6.5507 -- time: 4.2734 sec.\n",
      "Step(15500) loss: 7.4304 -- time: 4.2804 sec.\n",
      "Step(15510) loss: 6.7424 -- time: 4.3483 sec.\n",
      "Step(15520) loss: 7.5900 -- time: 4.1632 sec.\n",
      "Step(15530) loss: 7.7702 -- time: 4.3253 sec.\n",
      "Step(15540) loss: 7.0003 -- time: 4.2060 sec.\n",
      "Step(15550) loss: 6.4987 -- time: 4.1709 sec.\n",
      "Step(15560) loss: 7.8362 -- time: 4.3631 sec.\n",
      "Step(15570) loss: 7.5636 -- time: 4.2231 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1329.0891 - val_loss: 0.0000\n",
      "time: 77.8936 sec.\n",
      "time_left: 16.8770 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 88/100\n",
      "----------------------------------------------------------------------\n",
      "Step(15580) loss: 6.7886 -- time: 2.9325 sec.\n",
      "Step(15590) loss: 5.9121 -- time: 4.2615 sec.\n",
      "Step(15600) loss: 8.3220 -- time: 4.1427 sec.\n",
      "Step(15610) loss: 11.2262 -- time: 4.1688 sec.\n",
      "Step(15620) loss: 5.9504 -- time: 4.4535 sec.\n",
      "Step(15630) loss: 7.9497 -- time: 4.2871 sec.\n",
      "Step(15640) loss: 6.3464 -- time: 4.1417 sec.\n",
      "Step(15650) loss: 6.8419 -- time: 4.0765 sec.\n",
      "Step(15660) loss: 7.9361 -- time: 4.2444 sec.\n",
      "Step(15670) loss: 5.3737 -- time: 4.2331 sec.\n",
      "Step(15680) loss: 7.5599 -- time: 4.2133 sec.\n",
      "Step(15690) loss: 8.7357 -- time: 4.2758 sec.\n",
      "Step(15700) loss: 4.4124 -- time: 4.2396 sec.\n",
      "Step(15710) loss: 7.7534 -- time: 4.2164 sec.\n",
      "Step(15720) loss: 7.6302 -- time: 4.2027 sec.\n",
      "Step(15730) loss: 5.1157 -- time: 4.2386 sec.\n",
      "Step(15740) loss: 6.8697 -- time: 4.3558 sec.\n",
      "Step(15750) loss: 7.0869 -- time: 4.2054 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1305.7226 - val_loss: 0.0000\n",
      "time: 77.3887 sec.\n",
      "time_left: 15.4777 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 89/100\n",
      "----------------------------------------------------------------------\n",
      "Step(15760) loss: 7.1689 -- time: 3.2620 sec.\n",
      "Step(15770) loss: 8.1703 -- time: 4.3012 sec.\n",
      "Step(15780) loss: 8.4341 -- time: 4.2574 sec.\n",
      "Step(15790) loss: 7.3572 -- time: 4.3347 sec.\n",
      "Step(15800) loss: 7.2497 -- time: 4.2436 sec.\n",
      "Step(15810) loss: 6.4050 -- time: 4.1055 sec.\n",
      "Step(15820) loss: 4.2247 -- time: 4.2660 sec.\n",
      "Step(15830) loss: 6.7073 -- time: 4.3156 sec.\n",
      "Step(15840) loss: 7.0991 -- time: 4.1818 sec.\n",
      "Step(15850) loss: 12.1723 -- time: 4.2242 sec.\n",
      "Step(15860) loss: 6.2763 -- time: 4.2433 sec.\n",
      "Step(15870) loss: 3.8476 -- time: 4.3202 sec.\n",
      "Step(15880) loss: 15.5340 -- time: 4.2516 sec.\n",
      "Step(15890) loss: 7.1762 -- time: 4.4037 sec.\n",
      "Step(15900) loss: 8.1588 -- time: 4.3484 sec.\n",
      "Step(15910) loss: 7.9637 -- time: 4.3339 sec.\n",
      "Step(15920) loss: 7.2561 -- time: 4.1754 sec.\n",
      "Step(15930) loss: 7.0421 -- time: 4.3158 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1335.8608 - val_loss: 0.0000\n",
      "time: 77.9743 sec.\n",
      "time_left: 14.2953 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 90/100\n",
      "----------------------------------------------------------------------\n",
      "Step(15940) loss: 5.8272 -- time: 3.7896 sec.\n",
      "Step(15950) loss: 7.0655 -- time: 4.1792 sec.\n",
      "Step(15960) loss: 7.5314 -- time: 4.2586 sec.\n",
      "Step(15970) loss: 7.4717 -- time: 4.1256 sec.\n",
      "Step(15980) loss: 11.1053 -- time: 4.1794 sec.\n",
      "Step(15990) loss: 6.1353 -- time: 4.2323 sec.\n",
      "Step(16000) loss: 8.1858 -- time: 4.2552 sec.\n",
      "Step(16010) loss: 8.5873 -- time: 4.1969 sec.\n",
      "Step(16020) loss: 7.7196 -- time: 4.1953 sec.\n",
      "Step(16030) loss: 8.4913 -- time: 4.1534 sec.\n",
      "Step(16040) loss: 7.6123 -- time: 4.2117 sec.\n",
      "Step(16050) loss: 8.2171 -- time: 4.2046 sec.\n",
      "Step(16060) loss: 8.5675 -- time: 4.1932 sec.\n",
      "Step(16070) loss: 7.4949 -- time: 4.2024 sec.\n",
      "Step(16080) loss: 8.2979 -- time: 4.2250 sec.\n",
      "Step(16090) loss: 8.5304 -- time: 4.1566 sec.\n",
      "Step(16100) loss: 9.1001 -- time: 4.2533 sec.\n",
      "Step(16110) loss: 7.7492 -- time: 4.1384 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1383.7047 - val_loss: 1346.1385\n",
      "time: 109.0827 sec.\n",
      "time_left: 18.1805 min\n",
      "--saved weights--\n",
      "----------------------------------------------------------------------\n",
      "Epoch 91/100\n",
      "----------------------------------------------------------------------\n",
      "Step(16120) loss: 8.3670 -- time: 4.2366 sec.\n",
      "Step(16130) loss: 6.7077 -- time: 4.3693 sec.\n",
      "Step(16140) loss: 7.0550 -- time: 4.2982 sec.\n",
      "Step(16150) loss: 7.6050 -- time: 4.2953 sec.\n",
      "Step(16160) loss: 8.8641 -- time: 4.1710 sec.\n",
      "Step(16170) loss: 11.2289 -- time: 4.3867 sec.\n",
      "Step(16180) loss: 7.7459 -- time: 4.3500 sec.\n",
      "Step(16190) loss: 7.8992 -- time: 4.3357 sec.\n",
      "Step(16200) loss: 9.9224 -- time: 4.2950 sec.\n",
      "Step(16210) loss: 5.8504 -- time: 4.1822 sec.\n",
      "Step(16220) loss: 7.6999 -- time: 4.2564 sec.\n",
      "Step(16230) loss: 8.3736 -- time: 4.3210 sec.\n",
      "Step(16240) loss: 8.5976 -- time: 4.3680 sec.\n",
      "Step(16250) loss: 7.7500 -- time: 4.2961 sec.\n",
      "Step(16260) loss: 6.5191 -- time: 4.2650 sec.\n",
      "Step(16270) loss: 8.4330 -- time: 4.3256 sec.\n",
      "Step(16280) loss: 8.1875 -- time: 4.3676 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1330.1207 - val_loss: 0.0000\n",
      "time: 78.7678 sec.\n",
      "time_left: 11.8152 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 92/100\n",
      "----------------------------------------------------------------------\n",
      "Step(16290) loss: 7.4269 -- time: 0.3557 sec.\n",
      "Step(16300) loss: 8.1192 -- time: 4.3744 sec.\n",
      "Step(16310) loss: 6.7449 -- time: 4.4013 sec.\n",
      "Step(16320) loss: 7.9211 -- time: 4.3727 sec.\n",
      "Step(16330) loss: 6.9334 -- time: 4.2682 sec.\n",
      "Step(16340) loss: 7.7162 -- time: 4.2405 sec.\n",
      "Step(16350) loss: 6.6953 -- time: 4.2732 sec.\n",
      "Step(16360) loss: 7.3130 -- time: 4.3539 sec.\n",
      "Step(16370) loss: 5.0314 -- time: 4.2018 sec.\n",
      "Step(16380) loss: 5.7559 -- time: 4.2770 sec.\n",
      "Step(16390) loss: 5.7147 -- time: 4.3252 sec.\n",
      "Step(16400) loss: 6.4474 -- time: 4.2702 sec.\n",
      "Step(16410) loss: 7.0251 -- time: 4.4344 sec.\n",
      "Step(16420) loss: 8.2888 -- time: 4.3359 sec.\n",
      "Step(16430) loss: 8.5976 -- time: 4.3494 sec.\n",
      "Step(16440) loss: 6.6558 -- time: 4.1830 sec.\n",
      "Step(16450) loss: 4.2989 -- time: 4.0873 sec.\n",
      "Step(16460) loss: 5.7877 -- time: 4.3574 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1316.5439 - val_loss: 0.0000\n",
      "time: 78.7194 sec.\n",
      "time_left: 10.4959 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 93/100\n",
      "----------------------------------------------------------------------\n",
      "Step(16470) loss: 7.5104 -- time: 0.7448 sec.\n",
      "Step(16480) loss: 7.4381 -- time: 4.2230 sec.\n",
      "Step(16490) loss: 8.2945 -- time: 4.2588 sec.\n",
      "Step(16500) loss: 8.7653 -- time: 4.2428 sec.\n",
      "Step(16510) loss: 7.0485 -- time: 4.2007 sec.\n",
      "Step(16520) loss: 9.2899 -- time: 4.3068 sec.\n",
      "Step(16530) loss: 6.8816 -- time: 4.1487 sec.\n",
      "Step(16540) loss: 5.1462 -- time: 4.2936 sec.\n",
      "Step(16550) loss: 4.9208 -- time: 4.2214 sec.\n",
      "Step(16560) loss: 22.9734 -- time: 4.3519 sec.\n",
      "Step(16570) loss: 7.9791 -- time: 4.4060 sec.\n",
      "Step(16580) loss: 4.0539 -- time: 4.2693 sec.\n",
      "Step(16590) loss: 7.4978 -- time: 4.1705 sec.\n",
      "Step(16600) loss: 7.6820 -- time: 4.3651 sec.\n",
      "Step(16610) loss: 7.9624 -- time: 4.2817 sec.\n",
      "Step(16620) loss: 6.7774 -- time: 4.4033 sec.\n",
      "Step(16630) loss: 6.7249 -- time: 4.3164 sec.\n",
      "Step(16640) loss: 8.8333 -- time: 4.4057 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1350.9893 - val_loss: 0.0000\n",
      "time: 78.4052 sec.\n",
      "time_left: 9.1473 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 94/100\n",
      "----------------------------------------------------------------------\n",
      "Step(16650) loss: 8.5913 -- time: 1.1789 sec.\n",
      "Step(16660) loss: 8.3902 -- time: 4.3795 sec.\n",
      "Step(16670) loss: 7.8207 -- time: 4.2836 sec.\n",
      "Step(16680) loss: 5.8299 -- time: 4.3809 sec.\n",
      "Step(16690) loss: 8.4071 -- time: 4.3036 sec.\n",
      "Step(16700) loss: 8.3357 -- time: 4.1850 sec.\n",
      "Step(16710) loss: 6.0092 -- time: 4.2599 sec.\n",
      "Step(16720) loss: 7.7039 -- time: 4.2921 sec.\n",
      "Step(16730) loss: 3.8231 -- time: 4.3482 sec.\n",
      "Step(16740) loss: 6.7426 -- time: 4.2942 sec.\n",
      "Step(16750) loss: 6.2998 -- time: 4.3433 sec.\n",
      "Step(16760) loss: 7.0749 -- time: 4.3445 sec.\n",
      "Step(16770) loss: 5.1956 -- time: 4.3936 sec.\n",
      "Step(16780) loss: 7.1591 -- time: 4.2199 sec.\n",
      "Step(16790) loss: 8.9011 -- time: 4.3348 sec.\n",
      "Step(16800) loss: 4.9723 -- time: 4.3458 sec.\n",
      "Step(16810) loss: 7.8454 -- time: 4.3015 sec.\n",
      "Step(16820) loss: 8.1047 -- time: 4.3154 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1307.2870 - val_loss: 0.0000\n",
      "time: 78.8538 sec.\n",
      "time_left: 7.8854 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 95/100\n",
      "----------------------------------------------------------------------\n",
      "Step(16830) loss: 7.2811 -- time: 1.7007 sec.\n",
      "Step(16840) loss: 7.5327 -- time: 4.2021 sec.\n",
      "Step(16850) loss: 8.1624 -- time: 4.1864 sec.\n",
      "Step(16860) loss: 6.5543 -- time: 4.3801 sec.\n",
      "Step(16870) loss: 6.8705 -- time: 4.3760 sec.\n",
      "Step(16880) loss: 6.9916 -- time: 4.2315 sec.\n",
      "Step(16890) loss: 7.4921 -- time: 4.4013 sec.\n",
      "Step(16900) loss: 7.3617 -- time: 4.3244 sec.\n",
      "Step(16910) loss: 5.4694 -- time: 4.2620 sec.\n",
      "Step(16920) loss: 6.4317 -- time: 4.2969 sec.\n",
      "Step(16930) loss: 9.1771 -- time: 4.2942 sec.\n",
      "Step(16940) loss: 7.8044 -- time: 4.2590 sec.\n",
      "Step(16950) loss: 7.3995 -- time: 4.3008 sec.\n",
      "Step(16960) loss: 6.7994 -- time: 4.2492 sec.\n",
      "Step(16970) loss: 9.4798 -- time: 4.2348 sec.\n",
      "Step(16980) loss: 7.7302 -- time: 4.1930 sec.\n",
      "Step(16990) loss: 5.2444 -- time: 4.3712 sec.\n",
      "Step(17000) loss: 6.3309 -- time: 4.2087 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1320.6360 - val_loss: 0.0000\n",
      "time: 78.4117 sec.\n",
      "time_left: 6.5343 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 96/100\n",
      "----------------------------------------------------------------------\n",
      "Step(17010) loss: 6.3162 -- time: 2.1532 sec.\n",
      "Step(17020) loss: 8.1507 -- time: 4.2897 sec.\n",
      "Step(17030) loss: 9.5725 -- time: 4.3807 sec.\n",
      "Step(17040) loss: 6.2602 -- time: 4.3570 sec.\n",
      "Step(17050) loss: 7.3049 -- time: 4.3495 sec.\n",
      "Step(17060) loss: 6.5499 -- time: 4.3001 sec.\n",
      "Step(17070) loss: 7.4918 -- time: 4.5347 sec.\n",
      "Step(17080) loss: 7.8715 -- time: 4.2689 sec.\n",
      "Step(17090) loss: 7.3676 -- time: 4.2036 sec.\n",
      "Step(17100) loss: 8.2549 -- time: 4.1967 sec.\n",
      "Step(17110) loss: 6.9574 -- time: 4.4057 sec.\n",
      "Step(17120) loss: 8.0427 -- time: 4.3054 sec.\n",
      "Step(17130) loss: 7.1666 -- time: 4.2483 sec.\n",
      "Step(17140) loss: 6.3858 -- time: 4.3292 sec.\n",
      "Step(17150) loss: 7.1823 -- time: 4.3767 sec.\n",
      "Step(17160) loss: 4.5532 -- time: 4.2325 sec.\n",
      "Step(17170) loss: 6.2238 -- time: 4.3312 sec.\n",
      "Step(17180) loss: 4.6218 -- time: 4.3494 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1320.7533 - val_loss: 0.0000\n",
      "time: 78.9395 sec.\n",
      "time_left: 5.2626 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 97/100\n",
      "----------------------------------------------------------------------\n",
      "Step(17190) loss: 7.5174 -- time: 2.5742 sec.\n",
      "Step(17200) loss: 6.7476 -- time: 4.3074 sec.\n",
      "Step(17210) loss: 8.3795 -- time: 4.3677 sec.\n",
      "Step(17220) loss: 7.5378 -- time: 4.3642 sec.\n",
      "Step(17230) loss: 8.5241 -- time: 4.3430 sec.\n",
      "Step(17240) loss: 7.7648 -- time: 4.4991 sec.\n",
      "Step(17250) loss: 6.0986 -- time: 4.3294 sec.\n",
      "Step(17260) loss: 8.4346 -- time: 4.3130 sec.\n",
      "Step(17270) loss: 6.7894 -- time: 4.3144 sec.\n",
      "Step(17280) loss: 8.5622 -- time: 4.2876 sec.\n",
      "Step(17290) loss: 8.0767 -- time: 4.2245 sec.\n",
      "Step(17300) loss: 7.4428 -- time: 4.2917 sec.\n",
      "Step(17310) loss: 6.2970 -- time: 4.1500 sec.\n",
      "Step(17320) loss: 5.6839 -- time: 4.2227 sec.\n",
      "Step(17330) loss: 8.2229 -- time: 4.2396 sec.\n",
      "Step(17340) loss: 8.5948 -- time: 4.2686 sec.\n",
      "Step(17350) loss: 8.9174 -- time: 4.2599 sec.\n",
      "Step(17360) loss: 7.4590 -- time: 4.3519 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1350.5593 - val_loss: 0.0000\n",
      "time: 78.7568 sec.\n",
      "time_left: 3.9378 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 98/100\n",
      "----------------------------------------------------------------------\n",
      "Step(17370) loss: 5.2301 -- time: 2.9482 sec.\n",
      "Step(17380) loss: 4.1080 -- time: 4.2985 sec.\n",
      "Step(17390) loss: 7.7919 -- time: 4.2034 sec.\n",
      "Step(17400) loss: 8.3951 -- time: 4.2917 sec.\n",
      "Step(17410) loss: 5.3997 -- time: 4.1998 sec.\n",
      "Step(17420) loss: 7.0879 -- time: 4.2802 sec.\n",
      "Step(17430) loss: 5.3349 -- time: 4.1953 sec.\n",
      "Step(17440) loss: 7.8829 -- time: 4.3282 sec.\n",
      "Step(17450) loss: 6.3402 -- time: 4.2076 sec.\n",
      "Step(17460) loss: 7.6208 -- time: 4.3063 sec.\n",
      "Step(17470) loss: 8.3470 -- time: 4.2460 sec.\n",
      "Step(17480) loss: 5.1770 -- time: 4.4126 sec.\n",
      "Step(17490) loss: 7.6915 -- time: 4.2692 sec.\n",
      "Step(17500) loss: 6.8616 -- time: 4.2337 sec.\n",
      "Step(17510) loss: 9.0172 -- time: 4.1558 sec.\n",
      "Step(17520) loss: 4.9515 -- time: 4.4856 sec.\n",
      "Step(17530) loss: 7.9055 -- time: 4.3179 sec.\n",
      "Step(17540) loss: 9.2204 -- time: 4.1846 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1349.9746 - val_loss: 0.0000\n",
      "time: 78.1150 sec.\n",
      "time_left: 2.6038 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 99/100\n",
      "----------------------------------------------------------------------\n",
      "Step(17550) loss: 8.4131 -- time: 3.5291 sec.\n",
      "Step(17560) loss: 9.1921 -- time: 4.3124 sec.\n",
      "Step(17570) loss: 6.2004 -- time: 4.2126 sec.\n",
      "Step(17580) loss: 7.5709 -- time: 4.2773 sec.\n",
      "Step(17590) loss: 7.9368 -- time: 4.2453 sec.\n",
      "Step(17600) loss: 7.8714 -- time: 4.3137 sec.\n",
      "Step(17610) loss: 7.5630 -- time: 4.1837 sec.\n",
      "Step(17620) loss: 5.2265 -- time: 4.2449 sec.\n",
      "Step(17630) loss: 7.7012 -- time: 4.3357 sec.\n",
      "Step(17640) loss: 9.6859 -- time: 4.2640 sec.\n",
      "Step(17650) loss: 8.9661 -- time: 4.4987 sec.\n",
      "Step(17660) loss: 4.8538 -- time: 4.4560 sec.\n",
      "Step(17670) loss: 9.0564 -- time: 4.2699 sec.\n",
      "Step(17680) loss: 6.5028 -- time: 4.2566 sec.\n",
      "Step(17690) loss: 8.1486 -- time: 4.3267 sec.\n",
      "Step(17700) loss: 7.5106 -- time: 4.2847 sec.\n",
      "Step(17710) loss: 5.4304 -- time: 4.2869 sec.\n",
      "Step(17720) loss: 6.5481 -- time: 4.2866 sec.\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1313.8123 - val_loss: 0.0000\n",
      "time: 78.6907 sec.\n",
      "time_left: 1.3115 min\n",
      "----------------------------------------------------------------------\n",
      "Epoch 100/100\n",
      "----------------------------------------------------------------------\n",
      "Step(17730) loss: 6.9509 -- time: 3.6960 sec.\n",
      "Step(17740) loss: 13.5195 -- time: 4.2884 sec.\n",
      "Step(17750) loss: 9.5760 -- time: 4.3549 sec.\n",
      "Step(17760) loss: 4.3407 -- time: 4.4002 sec.\n",
      "Step(17770) loss: 5.9214 -- time: 4.3151 sec.\n",
      "Step(17780) loss: 4.2785 -- time: 4.3016 sec.\n",
      "Step(17790) loss: 4.6996 -- time: 4.3486 sec.\n",
      "Step(17800) loss: 8.3245 -- time: 4.1864 sec.\n",
      "Step(17810) loss: 7.2853 -- time: 4.2272 sec.\n",
      "Step(17820) loss: 9.5238 -- time: 4.1693 sec.\n",
      "Step(17830) loss: 7.6387 -- time: 4.2071 sec.\n",
      "Step(17840) loss: 6.1280 -- time: 4.3318 sec.\n",
      "Step(17850) loss: 6.1011 -- time: 4.2695 sec.\n",
      "Step(17860) loss: 7.8211 -- time: 4.2945 sec.\n",
      "Step(17870) loss: 7.0716 -- time: 4.2109 sec.\n",
      "Step(17880) loss: 6.7993 -- time: 4.2492 sec.\n",
      "Step(17890) loss: 7.6995 -- time: 4.2572 sec.\n",
      "Step(17900) loss: 9.9267 -- time: 4.0532 sec.\n",
      "----------------------------------------------------------------------\n",
      "(validation)\n",
      "----------------------------------------------------------------------\n",
      "train_loss: 1345.2207 - val_loss: 1316.3276\n",
      "time: 110.6835 sec.\n",
      "time_left: 0.0000 min\n",
      "--saved weights--\n",
      "CPU times: total: 50min 25s\n",
      "Wall time: 2h 18min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "num_epochs = 100\n",
    "train(\n",
    "    net,\n",
    "    dataloaders_dict,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "# print(os.environ['CUDA_LAUNCH_BLOCKING'])\n",
    "# csvidx = os.listdir('loss_csv')\n",
    "# print(csvidx)\n",
    "# csvidx = [int(os.path.splitext(i)[0].split('_')[2]) for i in csvidx]\n",
    "# csvpath = '/Users/ShimaSef/object_detection/loss_csv/epoch_loss_{}.csv'.format(max(csvidx)+1)\n",
    "# print(csvpath)\n",
    "# weightidx = os.listdir('weights')\n",
    "# weightidx = [int(f.split('_')[2]) for f in weightidx if os.path.isdir(os.path.join('weights', f))]\n",
    "# if not os.path.exists('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1)):\n",
    "#   os.mkdir('/Users/ShimaSef/object_detection/weights/ssd_weights_{}/'.format(max(weightidx)+1))\n",
    "# max(csvidx)\n",
    "# print(csvidx)\n",
    "# weightidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
